>> Hello. In this lecture we're going to look at agent movement. Basically the idea of our game character that's controlled by AI moving around in the game environment. So we're going to look at a simple approach to movement and then in future lectures we'll look at more complicated movement. But we're going to have this material serve as a foundation for just understanding how a basic agent can move and then we can move on to exploring other topics like path planning and then come back to more complicated agent movement. First of all, let's consider agent representation for our movement. We really only want a representation for the elements of the game from an AI perspective to be as simple as possible, because that's going to make it easier to compute. Keeping in mind that AI has limited resources to calculate anything that needs to be done in terms of algorithms, you're having to budget what you're doing computationally for AI relative to graphics and audio and accessing the hard drive network and so on, depending on the type of game. So we want to keep things simple only model what is necessary to support the task at hand, which is moving around. So part of that is going to be defining, well, where can the agent move? And as the first thing let's look at is, what type of movement does our game have? One common type of movement that you see, especially with early video games. Like some of the first examples of video games, would be classified as discrete movement. This conceptually would be something similar to checkers or chess, where you have a grid and there's different discrete locations. They're unique locations for your agent to move. So there's not this smooth, gradual changing movement, which we'll see when we talk about continuous movement. But instead, these very clear locations for the agent to be placed. In this case, movement is very straightforward. It's easy to understand that you have these different locations and that to move from one to the next is probably going to be based on some rules regarding connections. Usually this is going to be adjacencies. So if you have a checkerboard, you can move from one grid cell to another adjacent cell. There's different types of adjacency and so on. We'll look at some of this in more detail when we talk about path planning. But in terms of discrete movement, you've probably seen, certainly board games, but probably also video games as well that use this movement. Mentioned before is also continuous movement is like the alternative to discrete movement. And in this case, rather than have different unique locations that are agent can be placed in, we now have the ability to move incrementally small amounts. This is very common in video games that have more of a real-time game play, arcade games, platforming games. So if you're moving Mario around in a Mario Brothers game, you can nudge Mario forward just a tiny bit or maybe make them walk rather than tip toe or run. Again, depending on which of the games in the series you're playing. But all of them I think, support continuous movement. So we have this discrete versus continuous movement that we can consider and we might have different approaches for how we deal with movement in the two scenarios. So in the case of running either a discrete movement game or continuous movement game. Something that you maybe just intuitively know it when you see it of thing. But if we look really carefully at the details, so you might say, well, wait a minute. In a continuous movement game you probably still have discrete locations that the character can move to. So if you think about how numbers are represented on a computer, if you're using integer or even a float, in neither case, there's a limited resolution based on the bit depth of the datatype. So even with a floating point, there's a fraction that you can't get any smaller than for moving the character slightly to the left or right if we're using numbers to represent positions. So you could say technically everything is discrete on a computer when you have fixed sized numerical representation. We maybe should think a little bit about, well, what do we really mean? It's hard to make a concrete, formal definition of discrete versus continuous in the context of video game movement. But we'll try to at least have some rules of thumb to identify this. So for discrete movement games, we'll say that they would have these distinct locations for the game objects to be placed and these GameObjects can move around from each of these places in a some human perceptually manageable number of locations. For instance, a chessboard. You can look at a chess board and you can clearly identify, well here's the different locations that are playing piece could be. You might even be able to call out grid coordinates, the historical records of famous chess matches. You can just see that the rows and columns listed to tell which pieces move. >> And also generally games that have this discrete movement, you can't skip past adjacent location. So if you want to go to the left, you're going to move your piece to the next most immediately left slot. You're not going to move some arbitrary number of pieces and you might have some different adjacency rules like in chess to the moving the night for instance. But it's still this well-defined adjacency information according to the rules of that blank piece. So you'll often also see discrete movement coupled with either turn-based time updates or slow automatic updates. So basically maybe the simulation might update and we'll take a look at how we might represent a simulation in a couple of slides here. But every time the simulation updates with a discrete movement where it's not turn-based, you might have something that is less than 10 frames a second. So if enemies are, for instance, moving around and you're moving the player around, it's very slow tick, tick, tick movement. And so that would be common of games, at least that I've seen that have this discrete movement and positioning. And so also games with this discrete movement usually the layout and representation of the world for the character to move in it's motivated by gameplay rules like board games style, understanding of movement and interactions of game objects is really just an abstraction that supports a particular type of gameplay, maybe like a strategy game, would be an example. Now in the case of continuous movement though, we have distinct locations for our game objects, most likely just based on the resolution of integers or the number of pixels in a screen, or the resolution of a float. But whatever the resulting granularity is of these different distinct locations, they're so numerous that a human game player that can't distinguish between one pixel and the next as they move their character around. So from their perspective its the same as moving an object around in the real-world, you can't really precisely say where something is. I mean, you can measure with a ruler or a tape measure or something like that, but there's always going to be some uncertainty in the placement of the object. And also, the movement that you see when an object is moving around and again with continuous movement from update to update might move a smaller or larger amount. And so this would be perceived as a velocity. So it moves this jumping multiple of these little tiny discrete locations, its jumping these large distances, [NOISE] then probably you going very fast and if it's smaller amounts, it'll be slower. And also this will be coupled with a high frame rates supporting animation. So you have to hit some like this critical threshold of 10 frames per second for a human to perceive animation. Course most games you want actually much more than 10 frames per second but at minimum 10. Yes, you can think in terms of round. You need at least a resolution of around the pixels on the screen, to be continuous movement. And then lastly, the movement is motivated by physical realism and probably leveraging physics that you learned in high school. So like particle dynamics type physics movement. [NOISE] So in either case, whether we have discrete or continuous movement, you're going to have some simulation loop that's running and that high-level, it'll look something like what I have here on this slide. This loop, it includes the player and so the player is observing screen based on observations of looking at the screen, maybe hearing things from the speakers, makes inputs presses buttons on joysticks. [NOISE] This is sent to the computer and an update process runs. So we're actually updating the simulation and then whatever the result is. So if you choose to move the character, that will happen. Now the update loop will also represent the AI processes. So any artificial intelligence updates for say, an agent that's moving, it's going to take place during that update and there'll be an internal measurement of how much time has elapsed and so we'll get the rendering. Then we finally have this sleep or synchronizing state, where maybe the computer just briefly waits before it begins the process over and over again. So for continuous games, we want this to be very quick running at greater than 10 frames per second. Usually at minimum shooting for 30 frames per second. So even a discrete game would run a loop, something like this if it's turn-based game there might be an interruption while we wait for an input and then that would initiate the next term. And in the case of turn-based or other discrete game play, you might actually have to synchronize a separate I/O loop that's just handling the user interface. That would be independent from your simulation loop because you still want to build a move the mouse cursor around, have feedback if it was a game with a mouse, you might want to be able to bring up in game menus and other things. So you'd actually have two separate loops in that case. But yes, you need to think in terms of at least at a high level, you're going to have a loop, something like this, where you're going to get little snapshots of time for your code to do what it needs to do for that moment. And then we'll go through the loop again and you'll get another opportunity. So that the code that you write to support your agents movement, path planning, when you're whatever activities your agents will be performing. You're only going to be able to think about the problem if you imagine your AI code is doing the thinking. You're only going to be able to work on it for just a fraction of a second. Aiming for something like 30 frames per second. You just have a fraction of a second to make a calculation and then let the system update and then you're going to have an entirely new state of the world. Hopefully it hasn't changed too much, but it'll have changed some. Then you have to make entirely new decisions based on whatever data arrives and that'll be influenced by the game player as they interact with whatever game objects they control. And also just the rest of the game world is going to change. Other agents are going to do things. There's physical changes occurring like if you have physics simulation. So everything happens through this loop and you need to make your agent code work with this. >> So let's think a little bit in a continuous world positioning now. Back to discrete. It's pretty straightforward. Each of the locations is labeled in some fashion, so they're all represented maybe as a graph data structure, would be probably most likely how you would represent. And you just keep track like a reference to where the agent is to this positions. But in the case of continuous positioning, what we want to do is leverage our understanding of geometry. And so we're going to use a position vector that's relative to an origin. So we're going to have a coordinate system. And most often we would be working with a 2D coordinate space or vector space for our representation of positions in our game world. And so that's how we would go about saying like an agent is at a particular xy location in 2D. And so this 2D space is going to be made up of real number representations, so probably like floating point numbers and two dimensions, x and y. And these are basically scalars for our basis vectors. So orthonormal basis vectors, just your typical graph layout where you have an x axis and a y axis. You'll actually find out it's more common to say x and z. We'll cover that in a few slides here. But that allows us to define locations, at least point locations. Now our agent is not point typically, but we'll also look at that in a second. So why are we using 2D? There's lots of games. The modern game is actually in 3D, and you have 3D models. Think of something like Mario 64, like in the picture shown here. So that's clearly a game with 3D. But in terms of modeling for the purpose of supporting our agents movement, so the AI movement, it actually makes sense to think in terms of 2D. And one of the reasons why you might want to do this is, well, everything in the real-world is, at least on Earth, is it's bound by gravity unless you're flying around, so maybe birds or airplanes. So in terms of any conceptual model for planning movement, it makes sense to just think in 2D, no point in complicating things. So we can actually get away with a 2D representation of positioning and in any case where we do need to consider the third dimension, that can be just some special case logic, for instance, jumping or falling or maybe cases where we have multiple levels. We can have some special case code do swap out 2D representations of multiple levels of floor plans of the building. So this works out pretty well to just stick with 2D if you can get away with it. Now, if you have a game that involves flying spaceships around, clearly, you would not force that to be 2D. So we would have to consider a different approach. So let's just assume we have 2D for now. So next step, we need a way to represent our agent. Now within the game from the player's perspective, the character that the agent represents is not going to be a single point. But as we've talked about before with using position vectors, that's a great way to talk about locations in our 2D vector space. So we can actually simplify our agent to be a point and then anything that's related to the agent's physical representation in the game, we can just synchronize that with this point. So as the agent makes decisions to move around the environment, we're just thinking about moving the point around the environment. When it comes time to consider something like does the agent collide with something, then in that case, we might consider an object centered on the point. And so we change our perspective based on what problem in the video game we're trying to solve. If we're trying to deal with moving an agent around, just the concerns of positioning, then we worked with a point. And then when we're concerned with collisions or other aspects of gameplay, we make those decisions in relation to this point location. So therefore, we can say that a GameObject or an agent is located at a point, and then we'll just carry along whatever metadata, whatever extra information we need, like a radius to know the overall size of the agent relative to the point. We'll just pass that information along and maybe a data structure. So let's consider a very simple movements scenario. We have an agent here that is seeking a target. In this case, we have a fish. So the agent needs to move towards the fish. In this case, we have a scenario with a continuous movement in a 2D game. So it's real-time game, I can think of like an arcade game. So we have this fish that's flopping out of water and we want the player to walk over to the fish. So how might we go about getting the agent to move in that direction? So we can assume we have a position vector, the origin. We know an offset in x and y that can place our agent. So probably I have something like this and we can do the same thing, placing our fish. So first of all, we're going to place points at the center of each of these different GameObjects, the agent and the fish. So that'll be at the center. And from there, we can figured out, well, where's the fish relative to the agent? We can just calculate a relative vector. So this is as simple as taking the difference of terms, so the x coefficients and y coefficients or for those relative vectors. You subtract where you're at from where you're going to if you want a directed vector. So in this case, the relative position vector A, where the fish is, you subtract from that, the relative position vector B. A minus B gives you the vector BA. So now we have a direction that the agent could go. So what we could do is, well, we could just add vector BA. So again, that's going to be two coefficients that tell us how to get from B to A. So we can just add that to the position vector B. So if we do that, that would mean that provided we update the game, like if we tell the GameObject that is the agent to now have this new coordinate, so that would be again the B plus vector BA. Then that would put the agent right on top of the fish. So that would instantly get the agent to the fish, but that probably wouldn't be what you want though except in certain games. >> So if you're not teleporting though, instead of going instantly, you will want to go in some incremental fashion relative to the update loop. You can think back to the loop I shared before where we were pulling user input, running the update process, rendering out to the screen and to the speakers, and then synchronizing and looping back again. So we need our algorithm to work in that framework. So one thing that we might do is say, well, we've got vector BA, what if instead of going the full length of BA, we go some fraction of it, maybe halfway down the vector? So perhaps could just divide the two coefficients in half and then add that to our B location, so that may've the agent halfway down. But if you do that, what you're going to end up with is that the next time we go through the loop, we've gone halfway along BA, and then we run through our update loop, and now our agents are in a new location so we have a new B location and the fish is still at the same spot. So we have a shorter BA the next time. So that means the next time you take half of BA is going to be a quarter of what you started with originally. And so you're going to keep taking halves of halves of halves of halves and your agent will be going more and more slowly towards the fish. And mathematically, you actually would never get there. Your agent would just keep going slower and slower and never quite getting there. Now in reality and in the game, especially if you have game logic related to say, the overall shape of the agent touching the fish, the collider radius of the two objects will probably overlap, fairly quickly. But you'd still have this problem of the agent because really fast when they're really far away and then slow down like slamming on the brakes and probably wouldn't be the gameplay that you want. So we're looking for some way to standardize or normalize the speed of the agent relative to the direction we want to go, again, in the context of this update loop that we're running. So keep in mind, that we're going to keep needing to sample these position vectors and calculate relative position vectors over and over, many times a second. So strategy that we should take on to improve our approach rather than going halfway down the vector BA, we want to decouple the direction aspect of BA from the length. So if you recall from your first look at linear algebra with vectors, we can perform different operations on vectors, such as normalizing or finding the magnitude of the vector. So that's a straightforward thing to do. We can take vector BA, which can be of some arbitrary length and we can normalize it, and so that will give us direction. And so to normalize, we actually first need the magnitude so we can use the Euclidean distance equation. So the square root of the sum of squares, and that works for 2D or 3D or even other dimensions. So for instance, we could take the x and y component from vector BA. So the x times x plus y times y, then the resulting sum, we take the square root of, that gives us a magnitude. Then we can take the vector BA and divide by that magnitude. What that gives us is normalize vector or a unit vector. So regardless of whatever direction that vector faces, imagine that the positioning of the agent and the fish change maybe the agent is below the fish or above left or right, whatever that is, we can calculate a direction vector that is always a length of one. [NOISE] So if we have that unit vector length of one, that means it's easy to multiply it by some scalar to come up with some new length of vector. This allows us to, regardless of how far or close the agent is to the fish, we can come up with a standardized new resulting vector that is directed appropriately but has the right amount of movement that we want. So again, thinking about the update loop that we've discussed so far for our video game, we want to be moving a constant amount every frame. Assuming our frame rate is running at exactly, say 30 frames per second, we want to move a certain amount down the length of BA, every frame. So the way that we can support this is to first figure out relative vector BA then we can normalize it, turn it into a unit vector, length of one. Now, we just need a little bit of information about our agent, that's how fast they go, so this is something that you just decide for gameplay. You want the agent to move at a certain speed. So we have a speed scalar, and we can multiply that times the unit vector direction, the normalized BA, so speed times BA. And this is because we can think of it as we have a direction, this decoupled from our speed. So if you multiply it together, then the result is a vector that includes both the direction and magnitude, and it will always be the right length or the right speed. Now one thing you need to watch out for when you do this, is that there's potential for and divide by zero when you're normalizing a vector. So if you're doing this all by hand, by writing out the equation or calculating the magnitude using Euclidean distance, you'd have a potential to get a zero. So this is something you need to be aware of and watch out for. When you're working with a game engine there are usually things built into help you avoid having these problems but again, you should always be aware. So this point, when we've got the normalized direction, unit vector, multiply it by the speed we have this agent velocity. If we're going to perform our update during our game loop, we need to actually come up with a new location, a new position vector for the agent, and then assign that value. So we'll refer again to our high-school level particle dynamics and we can use the equation, distance equals velocity times time. So we're trying to figure out the distance to travel offset from the current position B of the agent and we have a velocity that we just calculated. We don't have the t value though. So we just need to decide what is our t value and then we can figure out this offset from B and sine that, let the game loop run and then do it all over again. So where do we get the t from? >> So we could look at our simulations target frame rate. If we know that our game engine is designed to achieve 30 frames per second, then we could just use the equation for period relative to frequency. So period is one over frequency, 30 frames per second is our frequency. So therefore, the period or the frame interval is 130th of a second, or 0.033333, and so on seconds. So that is the value that we could use that for t. And in that case, the new B position, so B prime is equal to B plus the velocity of the agent that we calculated in the last couple of slides. So that V agent times t. So adding that to B because its a position relative to B, it's like B is a new origin, so we need to offset from there. So that'll give us our new B value and we will get our new position. But there is a concern here where we're relying on 30 frames per second being very precise, but it might not be. In fact you cannot always count on your simulation to run at exactly a desired frame rate. I have a unity demonstration. [NOISE] I'm not going to cut over to it during this video, I'm going to have it as separate resource so be sure to check that out. But what you will see in that video is, depending on what content you have in your game, there might be so much work to do in your simulation that it takes that update process in the loop that you might recall. If that update takes longer than the 0.033 or something slightly less, because we also need to leave time for the input polling and so on. If it takes too long, we might miss our schedule. And the work to do in a game loop varies according to what's happening in the game. So maybe if there's no enemies on the screen and the player hasn't fired a weapon that has lots of fancy projectile is going all over the place, maybe your frame rate is nice and steady. But as soon as 100 enemies come out of a zombie closet and you start firing missiles with lots of explosions and so on, the frame rate starts to drop. What that means is, if you were assuming that the frame rate was always the same and kept using that t value of 0.033, well, it could be incorrect. The end result is that any game object movement like our agent that's depending on that t value, will either speed up or slow down according to the frame rate. And that's not what you want, you want to be able to standardize movement to be the right amount. So for a constant velocity, you want to see the right amount of displacement as that t frame time changes. So a better approach would be to ask the game engine or just measure yourself if you're writing everything from scratch, you would measure the system clock time from whatever the previous frame was. That's the amount of time you're going to use as your measurement. And you're going to assume that that is the appropriate amount of time for rendering the next frame to appear. [NOISE] Like in the case of Unity, you can do time dot Delta time, I think it's Delta time. If not, there's a similar command that will give you the elapsed time since the previous frame. And so you're going to want to use that in your simulation. Now some gauge mentions including Unity, have what they call a fixed update and this is where there's various tricks. [NOISE] They have a very precise update loop that's actually independent of the rendering update loop. The rendering is usually where you see the most variation and resource utilization, where you can have the frame rate go up and down according to what's on the screen. But there's still possibilities that you can have similar varying load even in the update loop. So you have to start to worry about in order to maintain the schedule, maybe just dropping things off the schedule based on some priority like, well, we're just not going to update certain things [NOISE] because we can't hit our target. My recommendation is to always assume that time is varying. The trade-off though is that you introduce at least these two additional multiplies, because you could actually roll the Delta t into your speed. When we had our normalize BA vector times the speed of the agent, we could have just embedded a fixed t size into that precomputed and not have all these multiplies. This used to be a big deal on old classic computer platforms. Like games on 286 level computers in the late '80s just did not have the processing power to be able to easily have these extra multiplies for the Delta t. If you can get rid of even a few multiplies, it might mean the difference of an interactive game or not. So look for the video that will be posted separately with the Unity demonstration, we'll look a little bit more at this issue. So now we have an agent that has this ability to do this basic movement. One thing that I want to point out is that, we can think of the position of the player as this static information. In fact, in the game AI book, Melanchthon book refers to this as a statics. So the position would be one of the statics and we can also add orientation. We haven't talked about orientation, we're going to actually look at that in just the next slide. But those two, the position and orientation, we can refer to as statics. And those are things that can be updated by say, velocities or accelerations. In the case of orientation that the movement that's been presented so far, we don't need really to have orientation to support the movement, especially if our agents orientation is fixed. So for instance, if we have a 2D game and the agent just needs to always have the eyes at the top of the head and the mouth at the bottom of the head, we would just leave it in that orientation regardless of whether it's going left, right, up, down, and so on. So it might not be important to rotate. But in other games, it could be important. >> And in those cases, we might want the agent to face in the different directions. But most often, this is going to be facing the direction of travel. So if the agent happens to be going up, well, we're going to rotate, so that the forward direction of the agent is in line with the velocity of movement. And then of course, left and right, we'll just rotate to match. So what we're going to look at, how we're going to do that. But first, let's consider some more aspects of our coordinate system. So I mentioned before where we have this 2D vector space. We're probably going to be working with the coordinate system of the game engine, and then especially, the implications of the need for graphics rendering. So in 3D graphics, you tend to have x and z be the horizontal plane, and then y is up. Even though we're talking about a 2D coordinate system and it makes sense to have x and y be our coordinates, it's actually going to be x and z in most cases. And because it's a 3D coordinate system, we have this issue of left-hand or right-hand coordinate system. And that basically, just the orientation or the x, z, and y changes, depending on whether you're left or right hand coordinate. So you may, in some cases, have z positive before, or negative z is forward. And for a 2D game, or what we might call it a 2.5 D game, our agents or the 3D graphics model of our agents will be oriented such that the feet will be on the xz plane. And standing upright, the head will be in the y direction. And any rotations that the character makes, since it's bounded by gravity, it doesn't really make sense to rotate in a direction that would make the character tend to lay down, so we want to keep the character upright. So we're going to actually be rotating the character around the y-axis. We have just as one degree of freedom rotation that we're concerned about, and then our movement is in either the x or the z direction. So that tends to be the standard for thinking about how we're going to move an agent around. Even if it's a 3D game, we're jumping as possible, or falling off of cliffs and so on, we're still going to have this 2D representation for any decision-making. Now, in the case of our rotations, we do have to consider what are we using as forward, and so that will either be positive z or negative z direction usually. And we have a choice here, we can decide that we're measuring angles relative to the forward vector, or relative to the x-axis. If you look in a math book, you'll see rotations relative to x. That might change the terms. In terms of trigonometry, whether the x terms got the sine or the cosine versus the z can change. And then each game, if you're using game engines, they'll each vary on what the angles are measured from. Not that big a deal, you can usually just involve either flipping with sine and cosine, or in the case of left hand, right hand, is changing the negative or positive sign to work things out. Usually, if you just think back to your trigonometry and get out a piece of paper and draw out everything, if you don't know what the game engine uses, of course, you need to look at information up in a reference to know what coordinate systems you're working with, but something that you can sort out pretty quickly. So normally, in terms of the statics for your agent, you're going to store, again, position and orientation. Orientation, you probably will store as a unit vector is usually easier to work with unit vectors, but you could also store it as an angle. And you might also just pull it from the graphics representation. So for instance, in Unity, orientations are represented by quaternions, so you could possibly pull that information out from there. In Millington's book, he stores this information independently in statics. So one thing you might want to do is, if you are storing, the orientation is like a forward vector. So in x and y unit vector for the facing direction, or the orientation, you might want to go back to having an angle relative to whatever you're measuring from. And so this is also something you could just work out with the trig equations that you're familiar with. And you could certainly do that, but very common convenience function you find in many computer science-type libraries, APIs for graphics is this atan2 function. On atan2, rather than going ahead and dividing two terms that you had to come up with normally, you provide the numerator and denominator separately. And the reason you do that is because you can have negatives that cancel out. And those negatives would actually indicate to you what quadrant of the graph in the coordinate system, what quadrant the vector for the angles that your calculator, which way is it going. But if you cancel them out, it increases ambiguity. And therefore, you don't truly know which way the angle is facing in plus or minus 180 degrees. So atan2, since this preserves a negative for both a and b, not letting them cancel out, it allows some conditional code within the atan2 implementation, so like an if statement can determine, well, the resulting angle that we're reporting should have 90 degrees added in addition, or not. And so it is just a convenience function that you should be aware of as a game developer. So we can add orientation to movement now. And really, all we need to do is just use our normalized BA vector, and that will tell us the orientation to face. But that only works if BA was not zero length. So we actually need some fallback logic. What do we do if it is zero? So that would mean like, what if the agent has already gotten all the way to the fish? If that is the case, then our fall backwards could just be, well, recall that we have the statics or this metadata we're storing for our agent. And this is going to be preserved from frame to frame, so anytime you look at your statics, you know the information that was used from the previous frame, and so you just use the last known good orientation if that BA was zero length. >> So in this case, we just set the orientation in our game engine for the game object. And this is going to vary with the game engine, like in unity, there's lots and lots of high-level linear algebra functionality already built and just to makes things pretty straightforward. You can actually just grab the transform, this mathematically represents the overall pose of the game object. You can grab the transform and you can directly set the forward vector and it'll automatically do everything it needs to do once you provide the forward vector to rotate the object so that' its facing the correct direction. Otherwise, you might need to do this yourself. So you might have [NOISE] your standard 3D game. You're going to have these four-by-four matrices that represent your transforms for each game object, so this will be a homogeneous affine transform. So homogeneous representation is used because it's important for the projection process, putting the 3D information onto the 2D screen and affine transformations preserve lines and parallelism, which is usually something that you want when you are moving objects around in the world, translating, rotating, and if you have uniform scale. So those are all of the very common gameplay operations to perform. And so your typical game engine is going to provide a lot of that functionality for you and if you haven't been rolling your own though, you will have to concern yourself with the pose represented by this four-by-four matrix. But that can be done and you can apply the rotation that is based on facing that unit vector, that BA vector direction. We could have some slightly fancier rotation because if you think about what's happening here, we're picking the direction to go, we're figuring out a velocity, and then we're just always setting rotation immediately to the velocity. So this could create scenarios where if position is changed suddenly like a target position, you're going to have this over a single frame of the simulation you're going to just snap the orientation of the game object to immediately face a new direction. But we could add aesthetic animation that we calculate by hand in the rotation. So if we know from our statics, preserves our last known orientation, we could apply an angular velocity to rotate towards whatever our new direction to face is. So over several frames, if the overall angle exceeds our angular velocity's maximum speed, we're just going to rotate as quickly as we can in that direction. What that will do is it will make something that looks more realistic in terms of the game. You'll see the character might start to move in a particular direction, but it'll take a while to whip around and face where it should be facing. The downside to this though, is that it might look awkward in terms of sliding sideways, so your agent will not be turned all the way to face where they're going, and depending on what they look like, maybe if they have feet or some expectation on the part of the player, they think this agent should always walk in the direction they're looking, but then they're sliding to the side before they get turned all the way. That might be a little jarring, but that's the trade-off of using this approach. [NOISE] So we have just defined basics of kinematic movement, and in particular, we have an algorithm for seeking. So this is where an agent is seeking out a target. So a kinematic object knows its statics and again, that is the position and the orientation, and its position and orientation updated according to whatever the kinematic algorithm or strategy is, so like seeking will be coming up with a velocity and then that velocity is used to update position. And to find the new target orientation, we might have a secondary step of applying an angular velocity to orientation to then adjust the orientation, or am I just do the simpler approach and just snap orientation. You might even not even worry about orientation again, there's some games that the character is just always going to maintain a fixed orientation but still move around. Those will be much more simple 2D games, though most likely. And so a bit about implementation. So we've seen an algorithm represented in just a handful of simple equations. Of course, there'd be a bit more in terms of coding that would need to take place to implement this. And if we were to do so, one consideration that we might take is that we might decouple the calculation of our velocity. So say the case of seek, we come up with a velocity that takes our agent towards the target. We might just come up with the velocity and then assign that to an agent and then when it's time for the agent to update, well, they know their statics, which is position and orientation, and it knows this desired velocity. So it would apply, do its own update, thinking in an object-oriented since it would apply its own target velocity to its statics and then generate those new values, and then the agent would be drawn onto the screen with those new values. So I'm mentioning this because well, one is that the framework work for agent movement that is in millinewtons AI for games uses this approach, but also works well as we look at more complicated movements such as steering behaviors. It makes sense to decouple these desired movements where their velocities or accelerations and so on, decouple that from the actual final result. >> So let's consider a few other possibilities for movement within this framework that we've defined so far. So we've looked at seeking. But what about fleeing? What if the fish was dangerous and our agent wanted to get away from the fish? Well, in that case, this is a really straightforward one, it's almost for free, we can just flip the calculation of a relative position vector, so rather calculating from B-A, we are calculating from A-B. Everything else though is just the same. We're still going to be offsetting from B even though we did the relative vector from A-B, once we've done the normalizing and multiplied by the agent speed and so on, we add that still to the B position. So we're just flipping the subtraction part of the relative vector calculation. And that will give us a very simple kinematic fleeing behavior. [NOISE] We can also come up with a variation for arriving. So the difference here is that we want the agent to stop upon arriving. Now, this introduces a problem if we don't make some adjustments to the algorithm. So as the agent gets closer and closer to a target, so from B-A, that position is going to get smaller and smaller. And as you get smaller and smaller, we're taking a very tiny vector. In fact, it'll get shorter than length of one, and then we're normalizing it back to a unit vector. So we're dividing by the length and so on. It's going to get super tiny. And as it happens, related to various issues, maybe the agent doesn't move exactly along the pathway you expect if the agent gets bumped, or more likely just the numerical accuracy of your floating-point representation, that's going to start to introduce some noise. So the direction you're asking the agent to move is going to flutter around, aiming a little to the left or the right of the target position. And as it gets closer and closer, it might never actually land, and it might be impossible for it to land exactly on the point. And what happens is you still, when you try to do any comparison, say that vector A equals vector B, these two positions to be an exact match, they might just never match. And so you're going to keep having the agent zigging and zagging and wiggling, trying to move towards the goal at maximum speed all the time and just never getting there. So there's a couple of things we need to do in order to actually get an agent to arrive. So at minimum, we need a capture radius as large enough to wash out any of those rounding error type issues that you might run into. So rather than having the B be exactly A that say they arrived, you would say that some capture radius distance from A, if that is greater than the distance or the magnitude of vector BA, then we know that we've arrived and that can still be pretty small. Visually, the game player might not even notice the size. It'll depend on your game. The other thing that might be nice is to have the agent slow down upon arriving. So that will be reasonable behavior for arriving at a location not to just instantaneously slam on the brakes. [NOISE] So we could actually use both of those approaches. So in order to pull this off, we'll modify the seek algorithm that we have looked at so far and we'll do so in the following ways. First, we are going to check the magnitude of vector BA and see if it is less than or equal to the capture radius. If it is, then that's going to trigger an event that the agent has reached the target. So we probably have the agent stop moving and maybe there'll be some message or a flag gets flipped to denote that the agent has, in fact, finished the job of seeking. The other thing that we'll do is to have to slowdown for arrival. Again, think about how this takes place over multiple frames. So we're going to take our vector, BA, and we're going to divide that by time to target. So you can think about vector BA. We'd actually think of it as a velocity. It's the speed you would have to go in order to teleport from wherever you're at in one frame, how fast did you have to go in order to get there in the next frame? So it's not only a relative position vector, we can have different perspectives of this. So if we're dividing by this time, that's telling us, well, how fast, what do we have to go to get there in 0.25 seconds? So then, once you've figured out what's the velocity you have to go to get there in 0.25 seconds, and once we know that velocity, we can take the magnitude of it and compare that to whatever the agent speed is. So that's like a speed limit. We don't want the agent to start going faster than that. So if that resultant vector is less than the maximum speed allowed, that means we're slowing down to reach our target. And so, instead of the normal way of calculating our velocity, we'll just use that, the BA divided by the time constant. Well, assuming we keep using that, the 0.25 seconds, we'll go slower and slower. >> So usually, that's not an issue relative to the capture radius. But depending, you might actually want to adjust the time, but in practice that isn't necessary. You just keep using the 0.25 seconds in calculating. Otherwise, if that BA divided by the 0.25 gives a velocity is too fast, the magnitude is half faster than the speed of the agent, in that case, we'll just use our old strategy and calculate V_agent as before and just go full speed towards the target until we trigger that slowdown that's handled by the BA divided by time to target. Another algorithm we might want is to have, let's say, rather than seeking or arriving or evading, we just want an agent to aimlessly wander around, maybe a villager and non-player character in PC in a game, I just want them to wander around a bit. So a simple way to implement this would be to actually rely on the orientation rather than any particular target. And we don't have a target, in this case, to go. So instead, we're just going to refer to the orientation in the statics from the previous frame and we're going to just say, well, we're going to keep going in that direction except we're going to nudge the direction a little bit this way or that according to a random number generator. But we don't want it to be completely random, otherwise, the agent will just move in crazy zigzags tending to stay in the same place. And if we have rotation changes that are too extreme, it's going to look really disconcerting and certainly won't look right for most games. So instead, what we'll do is we'll take our orientation, we're going to add a little bit to the angle, either a little bit positive or a little bit negative. So we'll rotate more or less depending on this random number generation. So actually, what we would like is to generate a random value between negative 1 and one, but that tends more often than not to be at zero or around zero. And so there's different approaches you might take to this. You might think to use a normal distribution for instance, and then you calculate out all the terms and so on, set the standard deviation. But a simple trick you can do to get this zero biased random between negative 1 and one is assuming you have your standard random number library that gives you a value inclusively between zero and one, you just call that twice, you get two values, and subtract one from the other. So that'll give you something in the range of negative 1 to one. But the more likely value, most likely to occur is going to be around zero. So this is just a nice little trick you can use. And then you add that resulting value, that's between negative 1 and one, you add that. You might have to, depending on how your angles are represented, whether it's in radians or degrees, you're going to need to multiply it by an appropriate scalar to put the right amount of rotation. And then you can just add that to the orientation, and then that new orientation, that gives you your new direction to go in vector form. So if you have the orientation in vector form, so a sine and cosine or cosine and sine of the angle terms, then you can use that times the agent speed and that'll set the velocity as well. And so we get this nice wandering behavior over many frames. So another thing we might want to do is follow a path, so we can imagine having a series of waypoints and we want to visit the first one and the second, third, and so on. So in this case, we can just use seek for each waypoint. We probably want to not be slowing down for each individual waypoint, we want to go as quickly as possible. And we also might consider a special case of when we know we're on the last waypoint we'll use the arrive algorithm for the last waypoint, maybe to get a nice stop there. So even though it will be using secret probably, do you want to use the capture radius here? Especially if there's some game logic that says keep trying to go to the waypoint until it's been visited. You want to use a capture radius to define when visiting, the waypoint is complete, and so that'll avoid the wiggling or missing the waypoint and having to backtrack and so on. So one issue here is if your capture radius is big enough, this algorithm will mean that the agent is really never on the path completely. So hopefully, this image here gives you an idea of why that is, is that as your agents moving along, as soon as the condition for having met the capture radius is achieved, then you've initiated the next waypoint. So you've never actually gotten your agent all the way to the center and the agent makes no effort to get back on the line. They just go along adjacent to your line if there is a line segment implied by the sequence of waypoints. So if you intend for your agent to make a best effort to stay on a line, they're not going to curve their way over to the line. You need a more complicated algorithm. There are better approaches to this. We will revisit this when we look at steering behaviors. And speaking of steering behaviors, so far, this basic movement that we've covered with a kinematic movement is functional, it gets our agents moving, but it doesn't look very natural. So you can imagine our following waypoints is going to have a very awkward zigzaggy pattern to it because this instant change in velocity that occurs, we don't have any nice smoothing or accelerations. Even if we try to animate the orientation or the agents, is still going to have this moonwalking look in certain scenarios. Just generally, it's too aggressive turning too quickly. There's no sense of momentum that we might desire in our game. And so many of these issues are addressed in steering behaviors, which will be a future topic of more advanced agent movement. But this video, it sets a stage for just a basic understanding of character movement. We're going to actually look at other aspects of our agent moving around an environment especially related to path planning before we get back to steering behaviors. So I'm going to stop at this point. And if you have any questions, feel free to reach out.
