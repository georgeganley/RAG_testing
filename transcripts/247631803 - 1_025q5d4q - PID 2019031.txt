>> Hello. In this lecture, we are going to cover decision trees. So this is a form of reactive decision making and is one of the simpler forms. So here is example of a decision tree in the form of a flowchart and usually start off with an initial route decision to make. So this is just a little funny example from online but is for deciding how to deal with a problem like this. Does something move? And then if the answer is yes, should it? And if it's not supposed to move, you perform the action of applying the duct tape. Otherwise, there's no problem and then there's a similar path on the left side. So this is basically a decision tree. And so this is a way that we can make decisions about any reactive logic that say an agent needs to make in terms of gameplay in a game. And so I have a game example here shown in this flowchart form. So it looks very much the same as what we just saw in the WD-40 and duct tape flowchart. So in this case, we're trying to make decisions for an agent related to the presence of an enemy. So is the enemy visible? No. Is it audible? Yes. And then along that path you end up at the action which is at the leaf of this structure and that would be to creep, so to try to be careful not to be found by the enemy. But there's other possibilities like the enemy is visible and if it's close enough or not. And so you can see how you can represent a bunch of different strategies just cascading down through each of these different decision points. And this being basically a tree structure, but typically presented in this inverted flowchart form. So really all a decision tree is just an if statement nested inside of another if statement and so on. And so you can just work your way down and then the end result of the decisions is that some action is decided upon for the agent to perform. So this is really good for simple decision-making that you need to have your agent make and is great for especially simpler agents. As you try to add more and more possibilities, then things can become difficult to manage. So here is a visualization from the Millington book just showing the end result of a parse. So you can think of it as just working your way from the top to the bottom and zigzagging down through the decisions according to these decisions that are made. And you'll notice that at each of the decision points that there is some evaluation of game state information. So if the enemy is visible or the distance. And then in some cases, the information will just be already available with no processing but in other cases, there might be some processing necessary like computing a distance to an enemy, so there'd be some costs with that. And we'll revisit that in a bit, but keep that in mind. In terms of applications for decision trees most commonly you see it in character control. I think is probably more common with earlier games and also animation control. If you are familiar with unity, you've probably seen the use of a state machine rather than a decision tree but other game engines, and especially in internally developed game engines for say a particular company has their own in-house engine, this is pretty common to find animation control with a decision tree. You also find decision trees used fairly often in strategic or tactical AI games and additionally, rule base systems which we will also cover as well but you do see it applied for these tactical AIs as well. And really you can use a decision tree for any situation where reactive decision-making is needed. Pretty much any reactive decision-making strategy or model that you're using you could convert from one to the other and some are just easier to work with in terms of a design pattern. So some benefits of decision trees. They're very simple to implement, easy to understand, and to read especially if you visualize them like in the flowchart form we've been looking at. So you've got that top-down and left to right way of looking at them. They're modular to some degree. You have the ability to stick parts of decision trees together. So you might take a little bit of one and put it somewhere else. And one thing that this probably most interesting about the decision trees is there's this potential for training and learning. We're not going to cover that in this lecture other than just to mention that it is something to consider. So the structure of course we have that inverted tree structure and the nodes are where our decisions are made until we get to a leaf in which case that we have a special case type of node which is an action. So anything that's not a leaf is going to involve one of these conditional evaluations of a parameter like is enemy visible. So that parameter where we provide the outcome of the visibility test, and that would be like true or false. And then we can just directly compare that to either the left branch for no or the right branch for yes. Generally, you're going to have two branches per node so binary structure but you can sometimes have more and we will look at that briefly in a few slides here. As for the logic that you represent at each of these nodes, you could easily make a very complicated node in terms of the logic within one node. So you could say if A and B in parentheses or something else and just have a really long Boolean sentence to evaluate but that's not typically what is done with a decision tree. Usually, you keep each of the decisions very simple where it's just a single evaluation, like say you test a Boolean value as true or false. You don't combine it with some other Boolean variable in a compound Boolean sentence. You might say, evaluating a floating-point value. You might have a test if your test value is greater than a threshold. And occasionally you'll see what's basically an and for a range check. So if t is greater than a minimum threshold and less than a maximum threshold but that's usually the extent of any compound Boolean. >> And this works out well, you might think of it as being limiting. But it has just the nature of the tree, that there's this implicit structure to it that allows for Boolean AND and OR. And so I've got a little example here on the slide. So if you want to construct the logic for Boolean and variable A and B, where A and B are Booleans, then you can represent that in the d-tree structure. So the two figures I have here A and B, then return Action 1, otherwise return Action 2, and then it's very similar example, A or B, then return Action 1, otherwise return Action 2. So you can see the structure here, I have the root node is A and then so testing whether A is true. In the first example to the left no or false that will return to. So that makes sense because A and B, if A is false, then we can short-circuit straight to returning Action 2. But if A is true, then we continue the evaluation and so we follow the right branch leading to node B, and then if B is also true, then we continue following down into the right and we'll get to action one. So that is the equivalent of A and B. But if either A is false or B is false, so you can see that both lead to separate leaves with the action of two. However, in the case of OR, we just change the structure slightly, so in this case we're going to continue this model of short-circuiting. So if A is true in an A or B scenario, then we can short-circuit straight to returning Action 1, if A is true. There's no reason to evaluate B. But if A is false, that's the only case where we would need to evaluate B. So you can see how you can represent ANDs and ORs, even with this simple structure that's imposed to not have compound Boolean sentences. So the reason why you do this is because it makes it easier to restructure the tree. So if your decision tree, you actually have first-class structures, say like an object-oriented design where you have different nodes that you can just change the references around. Then having a simple structure allows for easy manipulation and moving things around. And it's even more so the case if you're going to have the automated restructuring, especially related to learning. So in terms of implementation, like in the millinewton book, an object oriented pseudocode example is provided. We're not going to go into all those details. But you do need some structure to represent the nodes and define the connectivity of nodes with other nodes, so that you know the order in which you're going to be processing the decisions and then which of the decisions finally lead to a terminal state or a leaf. And so that you know what action to perform. So you have to be able to do whatever your implementation is, needs to be able to transition from links to decision nodes, to links to actions. And so once you reach an action, you know it's terminal. And then you can return that. And each node is going to have some assigned type, like what is it testing. And this will usually be related to some primitive datatypes. So you might have a node for testing floats, say maybe greater than or less than or maybe a bounce checks. So you have a low value and high value test for a Boolean state. And you might have more complicated implementations that are say, application specific. So if you need to calculate, say, a vector distance, you could perhaps extend upon these base node types to make more complicated node types that address the logic that's in your particular game. And then also each node somehow it's going to build to indicate what test information is assigned to it. So you might have just a object-oriented implementation. You have a reference out to game state that just you programmed into the node. But there could be other approaches too, you might have a lambda function that you provide to the d-tree and it's wrapping some information source. So there's lots of different ways that you might approach the design of a d-tree or probably partially depend on the programming language you use, the nature of the data and how you access the game state information to pass to it. Once you have the d-tree structure in place, and have indicated the types of tests, what the tests are and what the actions are that you arrive upon. Then you need a way to evaluate this. And that'll be a recursive approach. Not necessarily through your programming language recursion. You could iterate through and track and in that form, but conceptually recursive. And then just tracking through each of the decisions until you get down to the terminal action state or the leaf. And so that's returned as the action. And it could just be an action by name or you could actually be directly calling some executable method that initiates the action. So really, there's a lot of flexibility here. There's not anything like set in stone for how to do it. It's more just the methodology of representing your decision-making process. >> Just the fact that we're forming this tree structure, I guess you could think of it as a nice feature of the decision tree in that you don't have to analyze all of the decisions that are possibly involved in selecting any given action. You evaluate the root node and then you either go to the left or the right. You don't have to evaluate both sides. And so that means you're only ever evaluating a subset of the tree. And if the tree is well-balanced, then that's going to minimize the depth of the tree and therefore the number of decisions that you will have to make is also minimized. We can also consider the number of branches. And so far we've continued to look at a binary tree. But we might have N-ary trees where we have in branches and there could potentially be some benefit in that an implementation. But often, if you think about the nature of any game logic decisions you would make that would involve selecting across multiple choices, the simplest thing is you would just have else-if, else-if, else-if and so on. And computationally, there's not going to be any benefit to that evaluation within a D-tree. To do that all on one node versus just chaining together multiple nodes. Maybe just the tiniest bit of difference, but very negligible. They're really the only way to make it considerably faster is if you can come up with some mapping function that generates from your test data and index into a lookup table. So that way you avoid the chain of if statements and then can just jump straight to an index position in the table that would tell you which of the multiple branches to take. But that would probably take a lot of work, many decision problems that you would be considering in your game that would involve something more complicated than a binary decision. Coming up with that mapping function could be non-trivial. It could take a lot of work or just not even be a natural approach to solving the problem. You're probably better off just sticking with the binary tree. And again, it does have the benefits of simplifying the shuffling stuff around. If you want to snap off a part of a tree and move it to another place, manually moving things around. That's more likely to be straightforward with simpler tree structure of the binary tree. In terms of knowledge representation, I mentioned before about accessing game state information. We have the standard node implementations to handle, our Boolean values are floating point values and so on. So we'd often have nodes of those types may be extended in an object-oriented sense or some other means of connecting a type of node with game state information. We don't necessarily have a well-defined abstraction that's separating the implementation of the D-tree from the implementation of the game. And so this is one of the downsides of D-trees because there's not a well-defined software engineering pattern or principle here to try to decouple the two so that you end up with tightly in this tight coupling of the D-tree with game state. Now, where this is problematic is a lot of times when you're writing a D-tree, you'll have a common path through the tree. So a common parsing, so when you're evaluating at each node by one of the branches at versus the other is probably going to be a lot more common. And it's going to get progressively more rare or a potential for more rarity in evaluation. So like if you just running your game, in like a demonstration mode, you might possibly never see certain branches trigger that might be so rare that you don't see it unless you force the scenario. If your game is evolving and that's common of games, like say a team developing a game, things are going to change about the game. You may have already written the AI for the D-tree and then something in the game changes for some necessary reason and you had the D-tree connecting to that game state information. Well, that could change and it can result in subtle bugs and that's in the D-trees. You have these bugs in the D-tree making bad decisions. And it can be compounded by whether this is in more rare nodes of the tree. That makes things problematic there. Now, in some cases, when you are connecting the knowledge of the game state with the D-tree, it's not already going to be in the right form. You're going to have to do some processing. You might know, say in the case of the vector distance information, you know the positions of objects, but in the game state there was no reason to calculate and store distances. There's a computation associated with that. Of course, it could be a much more expensive calculation than just a distance like Euclidean distance. In those cases, if it's only information that the D-tree needs and nothing else in the game needed it, it doesn't exist yet. In terms of the D-tree, you don't want to calculate everything you might need in all decision nodes in advance. Instead, you just wait until you're parsing and arrive on a node that needs certain information. So this is called lazy loading. You wait until you actually need the information to calculate it. That's a common approach with the D-tree and it works well. So if you parse to the left of the tree and you don't need that to calculate that distance of the player and the enemy, then you'd never happens. But if later, you do need to calculate it, that's only going to be because you landed on a node where that information is needed for the decision. I'm certain there's a performance benefit there. >> So there might be a temptation when you look at the fact that D-Tree is a tree and you know that you're going to minimize the expected number of nodes visited. If the tree is balanced, you're going to put a limit on how deep any given parsing is going to go. So that's going to be O log of N. Worst-case would be just a completely unbalanced tree where it's just a linked list. And so you would have O of N. So you might be tempted to want to really work to force a balancing of the tree, but in reality you're going to get better average performance if you take into account that some actions are going to be more commonly selected. And so the path to those common actions is actually better to have shorter number of decisions to get to those common actions than rare actions. So it's non-trivial to balance a D-Tree because balancing isn't as straightforward as just the standard balancing. It's really more like a weighted balancing is what you're desiring. And to do so, do this by hand. It's like a black art. You've got to have some intuition on how to design the decisions and how to shuffle things around. So just taking the position where you should always balance the tree as best you can isn't the best solution. You need to really also consider what are the most common actions to be performed as well. Now one interesting possibility is that you can streamline things, maybe minimize the number of nodes by merging branches. And this can work with minimal impact on the implementation of a D-Tree provided that the end result is a directed acyclic graph. Otherwise, what you end up with is a loop and you could, I guess potentially write an algorithm for your D-Tree that would detect that a loop occurred and then do something. But it's better to just keep the parsing logic, the recursive call of evaluating your D-Tree, keep that simple. And then if you're going to use any branch merging, just make sure that it maintains the directed acyclic nature to it. And so there's a couple of figures here from the Mellington book to show you what this might look like in a decision tree form. So the upper example here is a valid directed acyclic graph with the branch merge and then the lower figure is an example where there's a loop and where that would be problematic for the D-Tree. So another thing that would be desirable with a decision tree would be to extend it so that it's not so predictable. And that's one thing that is really a challenge for all reactive decision-making strategies, is the fact that agent behavior can become very predictable. And human players especially are going to notice that. They're going to take advantage of it, they're going to become bored in gameplay that involves predictable agents. And a good strategy to try to minimize that perception is to introduce some randomness to the decision-making. So in the case of a D-Tree, this is a little tricky because we don't maintain any state naturally. So like with a state machine which we'll talk about later, the agent would be in a state for some period of time before going to the next state. But with a decision tree, there is no state. Every time the agent updates and is leveraging a decision tree or decision-making, it re-evaluates the decision tree and arrives on an action. And so if say the current frame arrives on say patrol as shown in this figure, the next frame it might arrive on defend and it'll just immediately make that change. Now this is tricky if you want to integrate the random decision-making. Because let's say in the case where you see the decision node for flip a coin, if you're re-evaluating this every time when you arrive on flip a coin, you have a 50% chance of heads and a 50% chance of tails, then you could just be flipping and flopping back and forth between patrol and standstill over and over as fast as the frame rate of the game or as fast as the updates of the AI goes. And so that's going to be probably not what you desire in terms of designing behaviors in your agents. So instead, what you need to consider is introducing some stickiness. In any case you pick a random choice, that needs to be maintained until the state of the game world changes that would affect other decisions. For instance, if you had parsed in the lower direction towards flip a coin and selected tails to stand still, you would want the character to continue to stand still every time under attack keeps parsing No. So if the last frame you parsed under attack No and arrived on flip a coin, then you just got to remember the last time we flipped the coin was tail, so you just keep going that route. But as soon as flip a coin is not arrived upon in consecutive frames, then you know that the world state had changed before it comes back. So it's pretty trivial implementation change, you just add to the nodes tracking to know what frame it was. If it knows that it's consecutive frames keeps arriving on the same node, you preserve the choice through the stickiness. But if you know that it's a new visit in the near-term to a node, then you re-evaluate your choice. And you might couple this with a timeout. So just in case you might say that well, the flip a coin stuck on tails, it's only going to stay stuck on tails for say 20 seconds and that allows agents to break out of getting stuck permanently. So it takes up maybe a little bit of thought to get this random decision tree implemented but the end result in terms of what needs to be implemented is really pretty straightforward. It's just a little tiny bit of extra logic to introduce the stickiness. So just to wrap up our initial look at decision trees, we've seen that they're easy to implement, easy to understand and to read with a top-down left to right flowchart. They have a bit of modularity to them because you're able to stick parts of D-Trees together. They perform well. There's a little overhead involved in the decision tree, but downside is they can quickly become unwieldy as you get these deeply nested trees. And there's limited structure for accessing game states. So the end result is you can end up with this type coupling. And we talked about how that is prone to air as the game evolves, as the implementation of the game evolves and just the nature of the decision trees with rare branches that can be difficult to find.
