>> The first path planning algorithm that we're going to look at is the Breadth-First Search. Over to the slides and I'm sure you're familiar with Breadth-First Search from introductory computer science classes especially related to parsing a tree. And you may recall that this involves expanding, starting from the root node expanding all of the children nodes, looking for the goal or whatever node you're trying to find. And then if that's not found at that level expand all of the grandchildren and keep going deeper and deeper and of course, this involves a longer and longer list of descendants to maintain for processing and executing the search. So the Breadth-First Search that perspective or for the tree search, it works well, it can find an optimal result if all the edges are unweighted or at least the same weight. The downside is that you have to manage maintain all of the descendants as their algorithm progresses to a deeper and deeper level. And it's really as applied to a graph like a map, discretized space, perhaps from a video game. There's similar issues that you will encounter, so you still have that same sort of maintaining a list of descendants and getting bigger and bigger the further you spread out from the starting point. So I've got a demonstration here this is from the software that is used in the game AI course that's written in C Sharp and using the Unity game engine. So this is running through incremental updates of the Breadth-First search algorithm so that it allows to see this visualization. And you can see how all of the nodes it will accept the ones that are disconnected in the bottom-right, all the nodes end up being explored, in this case. And you can get a feel for the breadth nature of the expansion so there's a leading edge of the expansion that's expanding out in all directions, but it's impeded by the boundaries of the level and the obstacle so it's maybe not quite as obvious. Let me show you another video from the same software. So this we can see spreads out more before it runs into obstacles so it's almost entirely unblocked. But you can see how it's like if you took a can of paint and just poured it down at your feet and let it spread out in all directions, and then waited until the paint touched the goal. And then you would need to follow how the paint spread to the goal and that would define your path and so that's at a high level what the algorithm is doing so you're starting at the first node then looking at all the adjacencies to other nodes and then adding those to a list of descendants of course going through the check, if it's the goal and if not then for all of those descendants then checking well what is the next level of descendants and adding those to the list. So it's very much similar to the tree search. So it's very easy to implement it does require some bookkeeping or metadata to track graph nodes that we've already visited. So we want to do that to avoid an infinite loop. For instance, we need a queue structure this is similar to your typical tree implementation so first-in, first-out data structure so we can actually put our descendants in this list and then keep processing the list for expansion and then get the right order of expansion for the purpose of expanding like one level of descendants and then the next. We also need some way to track the node, how a node was reached. So as the paint is expanding, where did it come from? So as the algorithm is selecting nodes to expand, then when a node is expanded you say, well it came from this particular node so you have this from node data. And with that, you can use it to rebuild the path once the goal is found at some particular location you can work back from there. [NOISE] And so we need to track open and closed nodes so there's this notion of set membership. So there's the nodes that we have visited but they need further analysis potentially, then there's nodes that we've visited and we're completely done with them we're not going to do anything with them again other than perhaps use the data for building the path. If a given node is on the path ultimately. So we call the first tier of membership we call this the open set, or potentially the frontier. And then there's also the closed set or explored nodes. [NOISE] So next step there's this issue of how do we associate this extra data, this metadata or node records. How do we associate that with our graph? So we could just build it into our graph so every single node of our map already has some structural elements to denote whether it's open or close, like maybe a Boolean. We could also have the from node for the backtracking to set the path. But that means that at the start of our algorithm we have to have all this memory allocated, also there might be software engineering issues of cramming a whole lot into these data structures we might want to keep things independent from our map perhaps. >> So there's different approaches you could take where we could have everything allocated but decoupled and then just have an analogous indexed table, a node array, and so as the algorithm is running it knows what node is being accessed based on, say, what indexes it have in the array of nodes. And then we could have a mirror image, at least in terms of dimensions another array that's the special node records that includes our metadata, and so the indexes would be equivalent. So you would use say, Index 5 for the 5th node to normally accessing parts of the graph, then we use that same Index 5 to grab its node record. But again, this requires all of the data to be allocated. And that actually we might want to avoid because potentially we can find the goal with our breadth-first search for some nodes are ever reached. So if you imagine the idea of the paint spreading out and then hitting the gulf. Well, there might be further nodes outside that radius that never get explored and that's memory that would not need to be allocated. So why bother allocating node records for all nodes? And this is a big issue in general for a path planning algorithms. So a little toy examples. You can certainly get away with it. Maybe even for video games where you have very constrained maps can actually be a benefit to preallocate everything to avoid the cost of dynamic memory management. But larger examples, you may benefit from not having the node record approach. Instead, you might want to work with the smallest amount of data possible and minimizing the memory footprint. And then that case, maybe you would use a hash table in some fashion. We could create relationships with the dictionary concept key-value pair with a hash of the keys to store our values the node records, which include all the metadata. We could also just use a hash table for set membership, like the open and closed set, you just add them to this set and then maybe remove them and also check for membership like a contains check. We may even make data structures that are a blend of different features. So for instance, you might want set operations and then combine that with say, a queue so that you can not only enqueue and dequeue, but also check for membership. A queue in its purest form would not have that ability to check the contents. So these are issues that you have to consider for practical implementations. So this at a high level is the breadth-first search algorithm for graph form. So you want to start by initializing a queue and a set that or perhaps combined that represents the open nodes. And so these are the nodes that are under consideration as the algorithm is doing its work. And so we're going to prime the algorithm with putting the starting node, the starting point, that would be probably where the agent is in the discretized space. So quantize the agent's position down to the discretized space that the graph form and then put that's as the single node in the open queue and set. Then we're going to start a loop. We're going to keep running until that open queue is empty. We're going to pull out the current node. In the very beginning there's only that starting point. So I'm going to pull that out we're going to look at it and then analyze its edges. Check each edge to see if it's the goal. If it is, we're going to break and then we will know everything's we need to form the path. Otherwise we are going to enqueue, add to our queue the edge nodes. So wherever the edges lead, so that's going to be an adjacent node. We're going to add those neighboring nodes to the open set. But we're only doing so if that particular node is not in the closed set and not in the open set. And so this allows us to avoid creating infinite loops, this particular check, and we're going to remove the current node from the open set we've already dequeued it. So that might be redundant if we have a combined queue and set. But otherwise, we'll treat them separately. And then we're going to add what was the current node to the closed set. Then we're going to go back to beginning of our loop repeat until open queue empty, and we're going to dequeue again. And so we're going to have a new current node and we're going to keep repeating this process over and over. So it's a very straightforward algorithm. You may be wondering where is the path. And so once this algorithm completes, which is either it runs out of open queue or it finds the goal and it breaks out of the loop. If that happens, then we need the resulting path. And so the way this works is that as you recall, the metadata that we're storing in our node records includes a from node. And this would be just the ID for where it came from or perhaps a pointer. We're going to start with a goal, look at it's from node, then go to that node and check it's from node and keep working in that fashion with a terminating condition of is the node that we are currently on the starting point? Once you get to that point, then you have a complete path, but it's backwards. So we need to run a reverse list operation. And then that is finally the results. So then we can pass that information back to the agent and then the agent could use some agent movement, like to follow a path, and we can see our game perform the path planning. In terms of performance our breadth first search is complete. This is in the context of a finite static map or graph. The results from our maps which use typical of the video game. So it'll be completed, we'll find a solution if there is one, it could be optimal and that is dependent on all the edge having equally weight. So if they have say, different distanced, then this would be not optimal. We could potentially pick a fewer edges, but that adds up to a longer path. And then we would terminate before we've explored whether there is something that had longer total number of edges, but the weights add up less. So for instance, on a grid Lattice with 4-way connectivity, all the edge weights are exactly the same with square cells. If we had anything else like waypoints that are not of any uniform placement, then we could get differing results. Or even 8-way connected grid would be a problem because the diagonals are longer than the up, down, left, right directions. The amount of time that our algorithm takes the process is the branching factor, which is the edges that each node has. A grid Lattice is very structured, so we have the four-way connectivity, so that would be branching factor of four. And then [NOISE] the exponent of b to the d, where d is the shallowest depth. Because our breadth-first search is going to find the goal at the most optimal, at least in terms of the edge count, then we know we're not going to search any further than that. So that's why it's b to the d space is the same because we need to track all that, the nodes and edges at all of them have to be evaluated. So that is a look at breath-first search. It a jumping off point for considering other possibilities. Next up we're going to look at depth-first search.
