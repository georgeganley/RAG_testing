>> In this video, we're going to look at iterative approaches to solving ballistic intercepts. And so sometimes we can solve directly but if we start to add more and more degrees of freedom to the movement of either the projectile, like adding acceleration or the target has acceleration or other types of movement then we will create a system of equations that has a higher order polynomials and will get difficult to solve. So we will maybe lose the ability to use the quadratic formula and have to use some other approach and in some cases that might not even be possible. So when things get more complicated than the approaches we've already seen for directly solving, you're generally going to want to go to an iterative solution. So we're going to look at a simple iterative approach using the static target solver that we looked at before which had a fixed target and 3D, the projectile was affected by gravity. So we can use that in the following algorithm. It can also work with other ways that you might calculate as well. So this is going to just leverage the static solver. I keep calling it more than once as a way to refine an estimate of a moving target. So the first step is you assume that the target is not moving and then you solve for the intercept, to find the t-value of the intercept. And for the static solver the t is totally dependent on how long it takes for the projectile to get there. The target itself is not moving because we're assuming it's fixed, at least from the perspective of the algorithm that we're using. But then what we're going to do is plug in the t that we just solved into the targets kinematic equation. And so that might be, say, with velocity and acceleration. So from particle dynamics, you would say your new position would be based on the original position plus initial velocity times time plus 1.5 of acceleration time times squared. So you plug that in and you're going to get this new position for where the target is. And so again, we're using this algorithm is meant for static targets. And we're saying the target is in a new place now. So we take that new position, plug that back into our algorithm in step 2, we just have, have this new position. So we're now going to solve for t again. And we're going to refine our t value. It's going to be some new value that reflects the fact that our target had moved. And so we do this again and then plug it again into the kinematic equation for the target. And the idea is that we should converge on a t. So the difference in the current t and the previous t will get smaller and smaller or the difference in the position. In either case, we would expect both to get smaller and smaller. And so we're going to repeat this iterative process until a terminating condition has been reached. That might be just a depth count like how many iterations. It might be that we're looking for some minimal change or even combined these terminating conditions together. Like you say the t value that we're calculating is only changing by just some little small amount. That would be enough to say, well, we're done at that point. So you typically would want to cap the number of iterations. So in a video game, 3-6 iterations is fine. When running the algorithm I've found this is useful to preserve the last good solution, when you call the static target solver you save the last kid once when you iterate. When you move the target forward, you might possibly move out of range. But if you're just on the edge of moving out of range it could possibly still be a good opportunity to launch the projectile. And so if that is the situation, you want to perform a sanity check. So when you finally exit your iterations, if you had any good solutions at all, you can analyze it. You can plug in your intercept time that you solved into both the projectile and the target kinematic equations. That'll tell you where they both are at the same point in time, which should be a collision. But we can check for some minimum distance that might be, say, the sum of the radius of the projectile plus the radius of the target, if we can represent those objects with a radius. Keep in mind, we're aiming at an infinitely small point like the centroid of the target. We don't have a way to aim at an area. We can only aim at a point. But just the way that this particular iterative solver works, we have this opportunity to check if we're close enough with our estimate. So it has this nice bonus that we extend our range a little bit because we can consider hitting a target right on the outskirts of the maximum range. Now there's this other issue that if our very first attempt at solving in that algorithm, if I go back to the loop. So if the first visit to step 2 fails, we have nothing to work with. We don't have a t value to work with. So that's a problem. So simplest thing is just to fail in that case. But in reality, the target could be moving at a fast clip towards the point that we're launching our projectile. It's coming fast enough as possible. Our projectile could be fired immediately like at a high arc, for instance. And then the target will come into range of the projectile that's now falling towards it and then get a hit. If we fell immediately, we're not going to catch that. So we might be able to adjust the algorithm to deal with this. I haven't attempted it myself, but it might be possible to, for instance, analyze a target that we can solve for the point of closest approach. And that would be a good baseline to figure out, well, if we know the point of closest approach and we know the time of that closest approach, could our projectile hit that with whatever speed we can throw at? Maybe we have to throw it at a high arc to get it to arrive at the right time. That might be possible. So if you can solve for the point of closest approach that, I guess, would be the worst case. So that'll at least allows you to put a bounce on the potential to hit the target at all. So if you cannot hit at that point, that would at least let you set a balance, so you might be able to look a little bit in front of or behind that point. So I haven't quite figured out exactly how to address this case of if your first attempt at refinement or setting the starting point for refinement fails, how could you deal with that? But I think the point of closest approach, something related to that would be useful. So here is a video of the algorithm I just described. Says the static targeting with the iterative approach applied to a moving target and the target is moving with constant velocity. So it's a zero acceleration. We can see the metric here. I think I mentioned before that the text is incorrect. It says shots per second. Clearly that's wrong. It is 100 times the shots per second. But the actual number is not really important because it's going to depend on the configuration, but it's the same settings for the different algorithms. So all of these little shooting range scenarios are all using the same reign of distribution for the movement of the target and the launch point. And also the velocity of the target is random as well. So we can see that the shots that we're getting off, this metric we're swirling around 500. It is a pretty good value. Of course, with the misses we've got over 1000 hits, zero misses. So it's very accurate. In fact, you never see it miss. I've adjusted it so that it can hit the targets even on the edge of the range based on the sum of the two radius of the projectile and the target. So that extends the range a tiny bit to keep the score up. And so compared to the law of cosines method that cheats, that allows arbitrary amounts of speed added in the y direction, that's the best, but of course it's cheating. So I think I got around 600, maybe 700 somewhere in there, for the shots per second times 100 metric that we've got here. >> If you want to stick with a speed limit, this works pretty well. In fact, it's probably the recommended solution that you'd use in inmost cases would be to use this approach. In terms of the pros and cons of this algorithm is easy to implement. Not much code that you're adding on top of what you had to implement for just a static target solvers just a little bit extra week we saw the pseudocode few slides ago. The cons, you might not be able to refine to a stable solution. You might actually have some instability that could especially be around the point of closest approach to the target because you're going to go from getting close as the target bool will be getting closer to and then pass the point of closest approach would be getting further. And you also might have problems like with accelerations where you have direction changes that are caused by the accelerations. So I think those are the source of scenarios where the refinement might have some trouble. Using the static target solver and this type of refinement is going to tend to favor shooting behind the target, so that's not good for dramatic effect. You can have like an a first-person shooter, say an enemy agent firing at the player is always going to be shooting behind the player, and therefore the player is not going to see with the first-person perspective. That's not good for dramatic effect. Mentioned before, if the target is initially unreachable but will be reachable in the future, then we might miss the opportunity to fire at them. So we do need a special case logic to handle that, which isn't addressed here, and it doesn't work if our kinematic movement of the projectile and or the target, if that can't be directly just evaluated, say plug-in a t-value, and then figure out where it would be at a certain time, then we can't do that. So some equations for motion are actually incremental like in order to figure out where it is, you have to evaluate it at incremental points in time. The current state of the object is based on its previous state. You can't just directly jump to some arbitrary point in time, you have to actually simulate out the whole thing and there are more complicated models like some with friction that where you would actually have to do that so, you cannot use this algorithm in that scenario. Next step, I've got an iterative algorithm for Law of Cosine. You can also come up with an iterative algorithm to use with it, and that is so that we can properly enforce a speed limit. This is a bit of a different approach than what we saw with static targeting algorithm. We're going to start off, we're going to call the algorithm as normal with the full force. But let's say we're actually going to be solving in 3D, even though it's a 2D algorithm for solving in 3D with gravity, let's say. That means we're going to be introducing that this Y-direction component. That's going to be cheating a little bit. We're very likely to end up with velocity, the magnitude of which is greater than our maximum speed that we would like to enforce. What we have to do is we will have to assess what the magnitude is. If it's too fast, then we wanted to run the algorithm again, but with a new maximum speed, we're passing to it. It's like our hold back algorithm where we just had to fix whole back except now it's going to be dynamic. So we're going to pass a hold back that is halfway closer to the length of an optimal launch in the x, z direction. This would be assuming that if we were to throw at 45 degree angle while you have some of the energy, we'd have to go in the z-direction and someone has to go in the y-direction. We want the whole back to be halfway closer to that point wherever the current hold back is. What would be the optimal launch for r max S naught, S hold back but SP, yes, we take a half-step and then we go back through the loop again, rerun the equation. Otherwise, if our velocity is not greater than S, well, there could be some different circumstances we need to consider. One is that it's a very good match, and that would be if our magnitude of velocity is nearly equal to r max speed. If it's, if it's approximately equal to the max speed, Then then that means we're throwing as hard as we wanted to. We can't have it be exactly equal because we're doing all this refinement, we're not going to build a converge perfectly on the maximum speed if any refinement has to actually occur. So that's where the one minus epsilon is coming from, so if I say epsilon is 0.011 minus 0.01 is 0.99.99 times the speed. So we're just saying we're getting pretty darn close to the max speed. But we also want to make sure that we're not wasting energy in the vertical. We're checking to see if the S hold back that was last used because this might actually be several iterations in. The last hold back that was used, we want to check to see that it is greater than or equal to the x, y, that would be at optimal angle, meaning like optimal for distance, 45-degree angle through. If it is greater than the value or the optimal angle, that means it's a shallow through and that's good. We don't want to waste energy in the vertical anymore than we have to, because that means we're just wasting time. We're pushing the t-value out further unnecessarily giving our target more opportunity to evade. We want it to be low in angle as possible. But if this overall criteria is met. Well, it's good enough. We can exit and return this result that's nearly perfect. But if it's too slow, so if that condition wasn't met, we can then check well, if it's too slow, that means that the magnitude of our velocity, is less than our maximum speed that we're trying to achieve. If that's the case, then we're going to run through the loop again with adjusted hold back speed. We're going to use the previous speed plus half of the max speed minus the previous whole back. This will allow the algorithm to start to push towards a faster speed basically. The other thing, if it wasn't too slow, it might be that it's wasting energy on overly steep lob. That would mean the angle is too high. If that's the case, then we could try again with the whole back adjusted to be halfway closer to the length of the optimal launch for 45 degrees. It probably sounds a little confusing. The description and it is a little trickier, but it's not a lot more code in terms of implementation as compared to the static approach. Similarly, you want to cap the number of iterations 3-6. You also can use the [NOISE] approach of preserving the last best valid result, but the best result now, we have to define a bit differently. That's going to be which one was the fastest in the x, z plane without going over the speed limit. If we have any that have met that criteria, we only want to replace our estimate if we find one that's better. We don't want, just want to add energy in the y-direction for no reason. For instance, we have this issue of needing to fail immediately if the first attempt fails because then we don't have anything to work with. But perhaps we could adapt the algorithms similar to the discussion we had with the static approach. Now as for xy vector link, I kept referring to that optimal launch. You recall from physics introductory physics class you took before. The optimal launch angle is 45 degrees to get the furthest that you could possibly send the projectile. So you can figure out what that would be in the x, z plane because you're forming basically a 45, 45, 90 triangle and so you can use Pythagorean theorem to determine what the x, z direction contribution to the overall velocity should be. >> If I go back a slide, that's what I'm referring to when I referenced the optimal launch, is that length. So we can see this in action, the 100 times shots per second metric here. We can see that stats are very similar to the other iterative algorithm of static targeting, we've got no misses, and the count is pretty much the same as what we saw with the other. So the law of cosines only gives you a result if it exactly hits the target, if it's able to exactly hit the point that, that represents the target whereas we had that little fudge factor possibility with the static targeting that extends the range a little bit because we can consider the fact that the projectile can still hit the target without their two centers overlapping. Basically, we just have to consider the sum of the radius. So the law of cosines has a little bit of a disadvantage there, it doesn't allow for that, and it can also, I think potentially still throw at a higher arc than absolutely necessary because we're only testing against the 45 degree. It might still be possible to make an even shallower angle than 45 degrees, but you can see that it often will converge on a solution that is lower than 45. So in practice, I don't think it's that big a deal, but there's probably a certain scenarios where the quickest throw is not found. And there might be a way to adjust the algorithm to actually favor the quickest to hit a little bit better than the current algorithm works. In terms of pros, finds exact solutions for moving targets. It might miss solutions near the limits of range perhaps, and it may not perfectly optimize shots for maximum speed with the lowest angle, therefore, meaning the soonest intercept. The way that we're refining it, it could, in some situations not stably converge, and this would probably be similar problem areas that the other algorithm has like near a change in distance. So closing distance and then increasing distance like point of closest approach or perhaps if you have different derivatives of motion, if you're accelerating such that you're getting closer and then you're getting further away again, that thing around those areas you might run into trouble. Also, a target that is initially unreachable but will be reachable in the future, it can create implementation difficulties because the first attempt to hit the target might be an issue though. It's less of an issue than with the static targeting because this actually does take into account the motion of the target. So this would be like if you're approximating some more complicated movement, that would be a big deal. But you can see that just in terms of the numbers, like at least as long as I ran the simulation for the two, they're both getting very close to the same rate of hits for the configuration so I think they're both pretty useful. You can only use the constant velocity with this method. You might be able to revise it, perhaps, to break up movement into small segments, say if you have non-zero acceleration. I haven't looked into that at all, but you can only use a simple kinematic movement for your target and then the projectile you can use it with gravity. I guess probably, you could also have more complicated movement for the projectile provided that you can directly solve it. So lastly, I want to mention the other iterative approaches. So I said before that sometimes you can't directly solve the kinematic movement equation for either your projectile or your target and that means you have to model incrementally the position and state based on current timestamp and then some small Delta T to the next timestamp. So you have to simulate the step-wise way and that is adding some complexity to trying to figure out, well, how are you going to aim your projectile based on these movements? So in that case, you need a way to actually simulate the projectile movement on this incremental approach and we have to figure out how close it got to the target. Again, it might involve both the projectile and the target moving. Basically, it's like keeping track of a timeline in space. So for each of these little Delta T's, you have a new position, so lots of little line segments, like a path is stored in space and each of us has a timestamp aided with how much time has lapsed since the incremental stimulation. So you can figure out how close the two pads got. The idea is you want to refine so that they converge so you start with some initial guess and then you refine by dividing. So it's conceptually similar to what we saw with the law of cosines incremental equation, but we need some bounds on this. So we want to define the minimum and a maximum range or the simulation. This is covered in Millington Artificial Intelligence for Games book, if you're interested, you can check it out. So often, you might start with an initial guess that's approximated by using a kinematic equation that can be solved directly, so say I'm meeting drag, for instance, that would give us maybe a starting point and then we can find the bounds by maybe the maximum possible range without drag, and then knowing the drag would be something less, and then what's the shortest shot we could take, like firing straight down or just wherever the launch position is. So we've defined some limits and then we can basically divide space. So we can say, well, we'll take a half-step back or a half-step forward and so on, come back and forth. We're doing a similar thing with the law of cosines incremental approach. So that high-level gives you an idea, but it's a lot of brute force computation to make this work and it would probably be worth it if you had maybe a very realistic war game where you have maybe some ballistic trajectories that they want to really be accurately simulated.
