>> Hello. In this lecture, I'm going to introduce steering behaviors and go over some of their basics. The steering behaviors is a technique for managing character movement through different types of fundamental movements that are based on forces or accelerations. So it's an extension of the kinematic movements that we've seen before, but it ends up being a lot more powerful and flexible. So first of all, recall that with the kinematic movement that we've seen previously, we were directly assigning velocities to the agent. So that meant we had these instantaneous changes of velocity. These were effective in accomplishing some character translation through the world. But the actual agent movement did not look natural. And it can look a lot better if we could introduce acceleration. So that's the whole premise of our steering behaviors. So again, we can have the velocity change instantly with the kinematic movement. But now what we want to do is have the agents apply an acceleration frame to frame of the simulation so that we will gradually change our velocities towards whatever goal is in mind. So for instance, moving the character towards a particular goal. So the first part of the algorithm is identifying a direction we want to go similar to what we've seen previously with kinematic movement. But then we're going to apply an acceleration or a force in that direction, the velocity of the agent is maintained as state information. So we have this kinematic state, and that's preserved from frame to frame. It can be modified, but it can only be modified to the degree that the acceleration is able to modify it. So for instance, if you had a very slow acceleration and a high velocity, it's going to take several frames before that velocity can be redirected to a new place. So if goals change, for instance, the agent is no longer seeking a particular goal and now seeking a new goal in an entirely different direction, it'll take a few frames, and the effect you'll see on the screen is that the agent will take a curving path as it gets reoriented by this acceleration over time, gets reoriented in the direction to go. And so that can look a lot more natural, more realistic compared to maybe expectations the game player would have based on real-world experiences. So for any calculated acceleration, the current agent velocity is going to be updated. So think back to our discussion of how simulations works, so frame based simulation, where we're updating the state of the world as if it's one fixed timestamp, and we're updating time by some small increments such that we hit a target frame rate, say 30 frames per second. So each one of these frames, we want our agent to calculate a new acceleration based on the situation that the agent is in. So as the agent is moving, the direction relative to the agent is going to change because it's translating through the environment. So we have to re-determine direction vectors like a relative position vector to a target or a goal. And every time we do that, we can use that to determine the acceleration. And this is as simple as getting direction, relative position vector for our direction will normalize that to a unit vector. We can multiply that time, say a maximum acceleration, and immediately we've got an acceleration vector that we can work with and apply to our velocity. Now, we don't want to allow max acceleration non-stop. This could lead to extreme velocity. So our agent could be accelerating up until the point it finally reaches the target. We don't want that typically. So simplest thing is to impose a speed limit so that the agent can't just accelerate forever. Now as an alternative, some games have advanced physics simulation. So this is a topic we covered in the video game design class. And with physics simulation, we might instead implement a drag. And so the drag is applied to an object that is translating. And that would mean that acceleration goes slower and slower up to the point that it's balanced with the drag where the agent would reach the top speed. So that's balancing the drag that's proportional to the translational speed and balancing that against the acceleration. You'd have similar effect on rotations as well, so that there's an angular velocity drag. But either case, you do want almost always a speed limit imposed on translational velocities and angular velocities. Now, in terms of what we're going to be doing with these accelerations, we could accomplish other tasks than just directing the agent towards a target. So we can abstract a way or generalize that really what we can accomplish is target matching or variable matching. And in this case, we might have different derivatives of motion or the dimensions either translational or rotational, and so we might be trying to match the agent's position with some other position. We might be trying to match the agents of velocity with another velocity. So for instance, and another agent can be moving at a certain direction and speed. And we could match that. The two agents could be at totally separate positions, but they'd both be headed in the same direction and speed. That might be good for group behavior. If we had a group of agents, we might want some level of coordination. We could match orientation or angular velocity. So we can apply this approach of accelerating to all different scenarios. And that allows us to come up with lots of different types of simple behaviors. So let's first consider seek and flee. And so we've looked at similar scenarios with the kinematic movement. >> In this case, we want to perform variable matching on a position. Now fleeing is going to be the opposite of that, so whatever the vector towards a location of interest is, we would just want to go in the opposite direction. In terms of determining the relative vector, we can just swap the order of the two points when we're calculating the relative vector and flip them. So we're going to determine our acceleration and that's going to be the same as how we determined velocity for the kinematic second flee. So that's just mentioned before, we're going to get the relative position vector, normalize it. That gives us a unit vector. We can then multiply that times the desired acceleration, which would normally be full speed ahead. Then really the work or the unique part of our steering behavior is how it's applied over multiple frames. And so I've got a few different equations on a little bit of pseudocode here to explain how this works. So first, we take the agent's current position, so this would be one of the statics, the metadata that we preserve about the agent. We take this position and then we're going to assign it to the position plus the velocity times t, where the t value, or actually a delta t is the amount of time elapsed since the previous simulation frame. So this will allow our agent to update its movement according to how quickly the simulation is updating and especially adjust for variable frame rate that is definitely likely to occur in a video game. The new position is just position plus velocity times time. And we also update the velocity. So this is stored similarly to the statics, will have kinematic values that are stored. So the new velocity is equal to velocity plus acceleration times time. Now if you recall from your particle dynamics physics equations, you might be thinking, well acceleration we should be using a t value that's squared. But if you pay attention to the code here, you'll notice that when we're adding the velocity to the position, that is going to be based on the previous frames updated velocity, which will have already been multiplied by a t-value. Also normally when you think of using the t-squared for position or displacement, you would have velocity times time plus acceleration times time squared. Now, the reason why with a code is like this where we're only applying the velocity in a frame and then updating the velocity which will affect the next frame. This is done partially because our t-values are already small. We're going to make them even smaller if we were squaring, so the accelerations would be super tiny. You can potentially run into a problem with numerical accuracy with floating points to get so small, it becomes meaningless, especially with high frame rates. So this approach avoids developing too small of floating point values and it is still effective in simulating velocities and accelerations. Now, next, after updating the position according to velocity and the velocity according to the acceleration, we can then check if the speed of the agent has gotten too high. So that's going to be taking the magnitude of the resulting velocity vector, then we'll just have information stored about what's the maximum speed the agent can go. And if the normalized, or the magnitude of the velocity is greater than that, then we will set the velocity to a slowed down version. The way we do that is we get the unit vector of the velocity, and then multiply that times the speed. So that will change the magnitude of the velocity. Now if you're actually writing this in code, you would probably save the magnitude of the velocity to create your unit vector rather than doing that as a separate calculation where you call some method, you'd instead want to take the velocity vector divided by the magnitude, which would give you the unit vector, and you wouldn't be performing that square root of squares trice wasting cycles. So that optimization is not reflected here, but you would certainly want to store to a variable the magnitude of the velocity. One problem with this approach is that while seeking a target, because of the acceleration, you can end up in a scenario where you never actually get to a static target in particular, I've got a demonstration of this. This is actually from Red Dead Redemption. You can see hopefully in the video, there is a brown bear out in the woods here is running at very fast speed in a circle. You might not be able to see, but there is an injured NPC laying out there in the grass and the bear is angry and wanting to attack. But in that, at the current speed that the bear is going and the ability to accelerate towards the target, it ends up orbiting. This is a very common problem in game AI solutions for character movement, is that an agent that is moving at full speed and trying to accelerate towards the position just ends up going in circles. And so we can actually characterize this with an equation. So we can use a centripetal acceleration formula to determine what this radius is. So in our case, we already know the acceleration because we're simulating that as part of the steering behavior algorithm. So we know the maximum acceleration and we know that we're accelerating towards the target, and we know the velocity or the maximum velocity. And so the equation is acceleration equals velocity squared over the radius. And so if we shuffle the terms around, because what we really want to know is the radius that we might encounter, this orbiting. Well, that's going to be, the radius is equal to the velocity squared. Now in this case, since we have a vector, this will actually be the magnitude of the vector squared or the speed squared over the acceleration magnitude. >> So in that case we will be able to determine our radius. And so that's the minimum turning radius for the agent for that given velocity and acceleration. Now typically when you plug into the equation would be the max velocity and the maximum acceleration. And in video game, your agents are always trying to go full speed and accelerate as quickly as they can to that full speed. But that clearly identifies the problem that you can run into. So at any given point for an agent, let's say you have an agent of this facing forward direction and is currently moving in a straight line, so if the agent is currently moving in a straight line, let's say it at full speed ahead, well, you can look either to the left or the right of the agent relative to the forward vector. And if you've already calculated the radius using the previously shown equation, you can see, well, if you turn full speed to the left, there's a circle and if you've turned full speed to the right, there's a circle. That is the minimum turning radius. And any point within either of those two circles, if the agent chooses to go towards that target point at full speed and full acceleration, the agent will never get there. Now the target is likely not to be exactly at the center point of either of these two circles. So what you would most likely see is a processing meaning there's a spiral graph-looking pattern where the circular path at the agent would be taking over time, would wobble around the target point, but still the agent would never get there. So yeah, any point within the circle you can get to. Visualizing these two circles for the minimum turning radius, either left or right also is a good way to think about the instability of actually having the agent crossover a single point, without a capture radius. So we've previously talked about why or that we want a capture radius because of numerical accuracy issues. Well, this demonstrates the numerical accuracy issues because as an agent's moving forward, let's say it's aimed exactly at the point it wants to go at, well, that point is going into a more and more narrow spot between these two circles. And if there's any rounding error that bumps that point either to the left or right and it accidentally ends up falling inside the circle, the agent won't be able to get to it if it stays at full velocity and full acceleration, trying to get to the point, so you just keep circling around if you don't perfectly run over the point. So the solution is you either need the agent to slow down or move away and come back if there is a target within the circle. Now, of course, you can also have a large capture radius on the circle just to say that it's been successfully visited, and that might be sufficient in some situations. Rather than seeking a target, we might desire to have the agent arrive at a particular location. And so in this situation, that means that the agent can only stop on a point by accelerating or rather decelerating to reduce the velocity just the right amount such that the agent stops on the point or within some Epsilon. So this is often achieved by determining a slowdown radius, that once the agent is within the slowdown radius, there will be a linear interpolation or alert that is calculated going from the maximum speed because that's the fastest the agent could be going and we'll scale that down to zero according to the distance. So a distance from the point of zero would be matched with a velocity of zero or speed of zero. And if you are on the outside or just on the edge of this slowdown radius, then your agent would be going at maximum speed. If it was half the radius, it would be 50 percent of max speed and so on. So it's just a simple linear mapping, and that would be the target velocity for which the acceleration is trying to achieve. So an acceleration would be applied to the velocity to get to the target velocity. Now, this can create a situation where if your slowdown radius is not the right size, you might actually exceed the maximum acceleration allowed by the agent. So you have some target velocity and you can calculate well what acceleration would be needed to achieve that target velocity, and it might be beyond the max acceleration allowed. So in terms of defining the slow radius, you could just fiddle with it and through testing, get it to where it doesn't overshoot. But you could also solve this directly if you refer to your introductory physics that you've taken before in high school or freshmen college, you probably have seen this simple particle dynamics equations for what distance would it take at some particular acceleration to go from one speed to the next, so you can just find the appropriate equations and you can determine for yourself what that slow radius should be. So that's something that is probably worth the effort to determine if you're implementing and arrive steering behavior. Now, in addition to the slowdown radius, you might want to also implement a capture radius like what we discussed for kinematic agent movement. So if you go back to that lecture, you can see the approach used there. Now, you might have a situation where you're trying to arrive at a non-static target though, where the agent is moving, and so in this case, the equation would be the velocity of the target minus the velocity of the agent divided by the time to target constant. So whatever that small amount of time is this use. I think in the kinematic, we were using somewhere around 0.25 seconds, it would be the time to target. Of course, you play with that value as necessary. In the steering behavior version like the arrive that we're talking about right now, the time to target probably should be much smaller like 0.1 instead of 0.25 because we're already slowing down with the slowdown radius with the linear interpolation. So this is just a last little bit of slow down so that once we get close enough to the target, that might begin to get in the range of numerical accuracy issues. The capture radius can take over, and then it can, over a couple of frames, lock the agent right onto that desired target. >> So we can also perform variable matching with orientation. If you have like a 3D game that you're considering in 2D for the purpose of agent movement, this would be a rotation around the y axis typically. And so that will be some angle that we can use to represent the orientation of the agent. So the same basic algorithm as Arrive but we're working with orientation and angular velocities and angular acceleration rather than positions. So the general technique is very similar. We'll use a slowdown angle and a capture angle. The concept is very similar. But where things get's a lot difference is when you rotate around a full 360 degrees, you start over again. So we actually define our angles as negative Pi to Pi relative to the current facing angle of the agent. So whenever the agent is looking forward, we can rotate negative Pi or Pi to get to the opposite facing directions. So you can pick either left or right to rotate. It doesn't really make sense to talk about rotation any further than that because you generally want to talk about what's the shorter of the two directions to go. So rotation, say just pass Pi, you would actually want to go the opposite direction to rotate to get there. So that is something we need to consider and build into our align is to define our ability to rotate where needs to be defined as either negative Pi or Pi relative to the current facing direction. Now we can also do velocity matching, and we've already seen that with the capture radius just for over a small period of time. But we can do this for other scenarios too. Like maybe an agent that wants to move in the same direction and speed as a body moving in a group. That would be a situation for that and it can be seen in the Boids implementation, which we will talk about later for flocking. So like animal-like group behavior. And so this is basically what we did before with the the capture radius as just the target velocity minus agent velocity divided by the time to target. And then we will want to make sure that our calculated acceleration that will test to see if it's too big. If that's pass our maximum acceleration, then we will reset it, or clip it so that it's only the maximum acceleration. At this point, we now have some basic steering behaviors defined. We have seek and flee, and arrive and opposite of arrive is also flee. We can align with positions or angles. There is velocity matching. So from these basic steering behaviors that we have, we can create other source of more complicated steering behaviors, which we're going to look at shortly. But before we get to that, I do want to discuss an alternate steering behavior design that can also be pretty effective. In fact, you could build it from some of these techniques that we've talked about so far. And the basic idea is that we can lock our orientation and direction of velocity together. So what we've seen so far, the orientation of the agent can be completely independent of the velocity. So you could imagine, say walking to the side but facing one direction like a strafing movement would be possible with what we've seen up to this point. But, in a lot of cases it might be desirable to lock the two together so that the orientation and direction are locked. So that means character always faces where it's going. But if you do that, you can get some interesting results. If you have the agents angular velocity and the resulting orientation you get from applying that velocity, that's going to dictate the direction of translation. So when the agent orients in a particular direction, the only direction the agent can go is forward in that facing orientation. So I'd say the main advantage of that approach is that the agent will never appear to be sliding across the ground. Now certainly if you have a game where agents are strafing, that would be appropriate. But in a lot of cases, what you can end up with is, what looks like the agent just sliding in a scenario where it doesn't make sense to be sliding. So I've got a simple example here. This is from Unity using their NavMesh agent, which is based on a simple steering behavior implementation. So this is the minion character. And you'll notice that translucent blue cube, that's like a waypoint. So the agent is seeking that, it's making no effort to slow down to reach it. It's just running through and once it hits a new waypoint is identified, and the agent is then heading in that direction. So there's an acceleration applied. Separately there is an angle align behavior being applied to orient the character. But you'll notice that the minion starts to move towards its next waypoint, which is off screen, starts to move there before the forward facing of the minion has finished turning. And it looks strange because it's like the minion is just sliding on ice even though it's wobbling, it really stands out. And you can have a poor quality animation look to the game player when you see this. >> If instead we required the agent to or always orient towards where it wants to go. In this situation what would happen is assuming the agent maintains the current full speed forward, it would start to turn and it'll take a wide circular turn. That would probably look a lot more natural. So the way this would be implemented is the agent first attempts to align with the relative vector to the target. So we get that relative position vector. And then we use that to generate the target direction for the alignment. So we're applying an angular acceleration gradually rotating the agent to either the left or right, depending on whichever is the closer angle. And then decelerate as it arrives at the final correct facing. Now, during the course of this rotation, which will probably take multiple frames, especially if the target is a significantly different than the current agents facing directions. So it'll accelerate over multiple frames, get to facing the right way. We can have the agent in simplest case just move full speed ahead all the time. So again, we will end up with these wide turns as the agent is accelerating towards aligning the facing direction or orientation. But we can also implement a more advanced version that's not going to have these extreme wide terms. So there's two parts to this. One is implementing a turn induced deceleration and the other is implementing a variable forward acceleration. So we're not always going to be accelerating full speed ahead all the time. Instead, it's going to be dependent on where our target is relative to the current facing. And so I'll go over how this would work. So when an agent is moving in a particular direction and then begins to turn, but according to this alignment towards a target, well, that new vector, we can use in comparison to the previous frame and the idea is we take our current to the newly updated velocity and we can project the previous frame velocity or the new direction for the velocity. So we'll have like a unit vector direction that the agent has just turned towards. That's the direction that the forward vector is now facing. We project the previous velocity, that would include both the direction and the magnitude. We perform a projection onto that new facing direction. What's going to happen in that situation? Let me show with the mouse where I'm talking about in the picture here. So this green arrow, that is depicting where the unit vector is pointing for our new facing. And that was derived by applying our angular acceleration as we accelerate the angular velocity to rotate towards the target facing. That's where we ultimately want the agent to face. So I'm saying that previous frame was facing down on the screen. And the new frame we're now facing a little bit turned to the agents left or right. So we can project that previous velocity onto the unit vector of the new forward direction. Now that's going to end up being shorter. So if you think about, we take a right angle off of that new unit vector direction, that's where we're going to project onto the previous velocity. What You're going to end up with is a shorter projected vector than the previous velocity. So the rotation that was applied results in a deceleration in the form of this shorter velocity. Now, you don't need to clamp this. You just directly apply it and you just say this was an acceleration that was specific to the rotation. So if you think of a car turning, you start to turn the wheel, which turns the tires. The tires dig into the road and introduce a deceleration. So there's that friction there, resisting the forward direction and then redirecting it. But there's going to be some energy lost in that. Now in a car, we're going to keep accelerating to hold speed or close to holding speed, typically. So we can do the same thing with our agent. So once we've got this new shorter velocity vector that was shortened because it was projected onto this new direction, we could immediately reclaim that lost velocity through the acceleration, unless we can turn so quickly and the linear acceleration agent is slow enough that it can't catch up over multiple frames and the agent will slow down. And so this is something that you might desire. So you tune the parameters of the agent to get the effect you want. So you can have the agent just always trying to accelerate to regain the lost speed that was induced by the turning or you can further refine the acceleration by comparing the desired target direction to the current facing direction. So we can perform another projection. So we can figure out the desired velocity, which would be full speed towards the target. And it's going to take a while for us to get there. But that would be ideal if we could get to that point. And that's depicted with the blue vector, that would be a full speed ahead there. We're not quite turned to face that yet, but we can project that onto our current forward vector. And then we can use that as a rule of thumb that, well, we don't want to accelerate much while we're not facing the target. We only want to accelerate a little. Basically, what you get from that is, you can avoid big wide sweeping terms. You're taking on this strategy of, well, let's get turning more before we get moving forward because otherwise we're just taking the agent further away from the target. So you're going to minimize. And as those two vectors get closer together, that projection is going to get closer and closer to the full length of the full speed ahead vector. So you can use those two strategies together and what you end up with is like, say an agent suddenly has a new target and is facing a completely different direction. The agent will tend to favor putting on the brakes and turning in place. In fact, you can even make this work a bit like say, a car that's driving. When you perform the projection, if it's a widened enough angle, you'll actually be projecting onto the negative direction of the vector and therefore, you can have the agent go backwards. Normally, you might have like a conditional logic that say if you have a negative, we'll just don't have any translational acceleration until the agent turns more. But you could have the agent actually take advantage of that negative vector and if you allow it to have the agent backup, then it'll backup while turning but then it'll go slower and slower as that angle gets closer to flipping the velocity to the other side, you'll hit a target of zero speed just briefly. And then as you turn further, now you can start the agent. It will accelerate more and more in the facing direction, and then it'll get closer and closer to the target. So I personally liked this approach to applying steering behaviors to agents. I think it looks better than the other approach where you have the independent turning and translational acceleration. But there are certainly cases where you would want them to be independent. Like if you have an enemy agent that's strafing while firing at a location, perhaps, that sort of thing. Now if you're using the term first steering behaviors, you will need to make a few adjustments. One in particular is if you're determining the minimum turning radius, well, the minimum radius of the orbit is going to be the maximum speed divided by the maximum angular velocity magnitude. So the angular speed max. So translational speed max over angular speed max is going to determine the orbit in that scenario. And that's just because we've defined motion a bit differently. So we need to calculate differently that radius. Now if we have that fully advanced version of turn first steering that I talked about where there's a variable acceleration according to the angles and using the projection, well, that already can basically avoid the whole problem of the orbit radius. You're not going to have these wide swinging turns. You're going to tend to turn in place more. And therefore, the orbit problem you're not necessarily going to have. And then also because you do have the locked alignment with the direction of velocity, that means certain types of combinations of steering behaviors or blending of steering behaviors and we're going to talk about that in the future. But that's not going to be possible for all the scenarios that you might imagine. Just because our agent has limited freedom because we've tightly coupled the orientation with the velocity, the certain things that just can't do, like walking sidestepped.
