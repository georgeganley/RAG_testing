>> Hello. In this lecture, we are going to look at another topic in learning, and this is case-based reasoning. So case-based reasoning is one of the most popular AI techniques. It's up there with rule-based systems and machine learning. It has its origins from the symbolic era of AI and it's really I think, identifies a shift towards the more machine learning techniques. Some aspects of case-based reasoning still grounded in symbolic AI, but also you're beginning to see this shift towards more machine learning type of approaches. So there's lots of commercial applications of case-based reasoning and it's applicable to many domains, including video games, as we are going to see in this talk today. So first of all, I'll just jump around a little bit in this video. This is just some academic examples of using case-based reasoning. I have the links in the lecture notes if you want to check them out. And of course, you can easily just google or search on YouTube perhaps and you can find lots of examples of using case-based reasoning in games. There's also a number of different papers, so researchers, including a Georgia Tech have explored a lot of the utility of case-based reasoning and applying it towards interactive media, like storytelling and other source of agent decisions. So it's worth outside of this lecture to check out some of these. Let's see if I can jump around a little bit here. Here's a case-based reasoning solution for playing Tetris with good strategy to win. I think there's some real time strategy game examples, there's robot soccer case-based reasoning. There's more strategy games here. So we're checking out. We'll discuss a few applications as well. So with that said, let's talk a bit about, well, what exactly is case-based reasoning? One of the classic examples with case-based reasoning, and this is, I believe the first example that I learned about when I took an introductory AI class many years ago, is that we had a scenario for case-based reasoning applied to traffic planning. We've already learned about path planning, and so if we wanted to solve the problem of how to get cars to go where they need to go in the most efficient manner, well, we could just use a path planning system. And as we encounter new problems or issues like a road that's closed, we could just replan, meaning just rerun our Astar search again. And so this is going to work, but it's going to be as computationally as expensive as whatever the algorithm we're using is. And we might be able to optimize things a bit maybe using a higher hierarchical approach to path planning could help. But if we were to use a case-based reasoning approach, then what we would be doing is storing previous cases. Meaning, on some other day perhaps, a car might have wanted to go from point A to point B. And maybe that first time we do this, we would run our Astar search amid to the computational costs of doing so. But then, we store that record. We can store some features about this, we'll call it a case. So this particular case, we've got starting point and a destination. We might also have other attributes of the scenario as well. We might store time of day, the weather, the temperature, all things that could possibly be relevant and could be stored with the case. We could also omit information. We don't necessarily need everything. The key is we want to have enough information so that we can refer to this case in the future. So we can store this case. And let's say in the future we again need the vehicle to find a route for going from point A to point B. Well, if we have some means of retrieving this record, so that means matching the current conditions to previously stored cases, so if we can find this record again, then we can find this cached path or the plan. And we might just build or directly use it or if we can't find it exactly the same case, we might find one that is fairly similar. So maybe rather than starting at point A, it's point C. But maybe point C is fairly close to A in terms of location. So instead, we're looking for a solution for point C to point B, you don't have it. But we can maybe still use that previously stored case for point A to point B. So maybe rather than completely replan using Astar, maybe we can just add a little correction to this case. So it's some minor change to the previously defined case and then we can try it out. And maybe we actually have, say the agent or the software we're using. It remembers what it's committed to in terms of selecting and using this modified case. And it might keep track of it and makes sure, well, the car actually get to point B and if it does, then maybe we would update some metric of utility for this stored case and we'd say, well that case was useful and so that can be stored in the case database and we would know to use that case again in future. We could also store the augmented case, the brand new cases we made. So from point C to point B, we could store that as well. The idea is that with case-based reasoning, with enough cases, we will have sufficient data that whatever problems we face will be largely solved simply by retrieving an appropriate case and then if necessary, modifying that case to meet our needs. And so there is basically a sequence of operations that we want to perform whenever we're considering a case-based reasoning solution. Now different authors, different researchers have come up with slightly different terminology and processes. So it depends on what book you are reading or what papers you're reading exactly how this works, but there tends to be a lot of similarity across these implementations. So you generally start off by analyzing the current situation so that involves identifying some specific features of the environment and features that you know that you will find in your case database or case space. You then will retrieve the closest matching case or cases; you might actually grab multiple. At that point, you will adapt or revise the cases that are found and you will want to make the case match the current situation. And as you can imagine, that it's going to be highly domain or application-specific of what it means to adapt. So like in our traffic example, we just looked at, probably any of the modifications are going to involve using path planning in analyzing our map information or our graph data. So we might path-plan a small section of the path, add a little extra tail to the path in order to get the right starting point and endpoint in our path. But other problems where case-based reasoning are applied, it could be quite different in what it means to adapt. After this adaptation's made, there'll be a test or review process and ensuring that this modified case matches our situation. So it's basically like a validation process. If the testing identifies any issues, then we will repair it or perhaps abandon and try a different case. Then lastly, we will store the new case, the new solution in the database. So the testing and the review phase, you might have this as something that could process, that can immediately be run or you might have to actually stimulate or wait for the real world results. So if you have a plan, wait for the plan to be executed to find out the utility of the adaptation. >> So with case-based reasoning, it requires a good bit of domain knowledge in terms of authoring these different components in our case-based reasoning system. So of course, the state representation, what information is relevant that is meaningful across all, or most of the different scenarios that we're encountering. You don't want to be storing information about the state of the world if it's not an accurate reflection of the decision-making. So that domain knowledge is important. There's also the design of a distance function. So this is the comparison of state representation across cases and the current situation. So what is the state representation of the current situation? And then we want to be able to have a well-defined function to find the distance between the current state and the state of all of the different cases stored in our k-space. Adaptation is similarly something that is strongly influenced by the nature of the problem domain. So there's not a universal adaptation that we could apply. And then same with the revision that you might need to perform. So all of these things, really, it does require this domain knowledge. It also requires a lot of data to implement a case-based reasoning solution that is effective. Meaning that the majority of problems that your case-based reasoning solution faces should involve simply selecting a case and then applying that possibly with some adaptation to the problem at hand. So not needing to fall back to some other solutions. So that means that you're going to have to have a broad coverage of likely scenarios. And if you don't have an exact match, you want to at least have cases that are close enough so that they're easy to adapt so that you're not making huge changes to the previous cases. Ideally, we'd be making just the right amount of change to them. So that it's still easy from an algorithmic perspective. And you have to watch out for the learning that can take place through this adapting and creating new cases, that the process can get stuck in a test and repair loop, and not converge on an efficient solution. So something important to understand about case-based reasoning is that it is not a well-defined algorithm. That, you can't just quickly throw case-based reasoning at a problem. It is more of a methodology. So it's a very high level. And it's modeling human reasoning and thinking the same process that a human might go through in terms of solving problems. And that is, well, considering solutions that you've seen before and then adapting in that way. So the process is all about storing these past experiences, these cases, and those are accessed in memory or the k-space. Whenever you're given a new problem, again, you're going to be retrieving from this case-based, based on the assessment of similarity to current situation and whatever cases are being considered. And then reusing for the new problem, revising based on how well it worked. So this is determining the utility. And also, remembering, saving this for future use. So the act of using the case-based reasoning solution is going to result in always learning because of whatever changes were made from previous cases. And even if you can use a case pretty much unmodified, you're still learning in the sense that you're keeping track of the utility or the efficacy of that particular case. So the cases in the case database that are most useful, they are going to bubble to the top. They're going to be recognized by these metrics. If you have a certain case that you keep finding and it keeps being beneficial to generating new plans, then your case-based reasoning system is automatically going to favor continuing to use it, until there's evidence that indicates otherwise. So reusing solutions to previous problems, and we have cases indexed by similar problem descriptions. So one way to think about it is that we have a problem space and a solution space, and there's a mapping between the two. So the problem space, we have a number of different problem definitions. And for some new problem that we haven't yet identified a solution for, we find a problem that is close within the problem space. And then we will figure out what adaptation to make by recognizing the differences in the problem space. And that's going to inform us, as to how different the solution is going to be in the solution space. Now again, this is something that is going to be very application specific, but that's the idea. It's that we will identify what those differences are of the closest matches of cases that we can find. And then figure out, well, what is this new solution? Then we'll, of course, store that. Here's an example demonstrating, from a human perspective, just scenario where we might be applying our own case-based reasoning. So this describes an example of, let's say, riding or putting together a presentation. So you're probably not going to start from scratch. Often, you might say, pull a similar presentation. If you've given lots and lots of presentations, you're probably going to say, I gave a talk that covered many of these concepts previously. So might grab a particular old presentation. And then, again, rather than starting from scratch, you're going to be figuring out, well, how close is this to what I need? And it might be a perfect match. Maybe you've given the same lecture before, or you maybe need to revise it, change it, so that it's appropriate for the audience or whatever the different conditions are this time. And so here, you'll see where this process of revising can come into play. So it makes sense in this situation that the author of the presentation can just review it. And they understand, as they make these revisions, if they're appropriate and accomplish the goal. In some cases, there might not be a way to know other than just going and trying the plan. But in this case, the problem is appropriate that you don't have to give a bad presentation in front of the audience. If you already understand the material, you can just realize what problems there are. Then this will introduce this iterative process. And so because of that, we will end up on an adapted version of the presentation, that through some number of revisions, finally, it is applicable. And we can, of course, store it, save it to the file system. And maybe also, once the presentation is given, we can remember how the audience receives it. And then that will give us some intuition in the future on if it's an appropriate case to select. So you can see how a case-based reasoning fits into this human decision-making, just as it does for a computer implementation. So here is another look at the case-based reasoning methodology. So like I said before, different authors have refined, and added, or simplified steps to the methodology. But here, you see, you start with a problem. You have new case. So you're going to retrieve from previous cases, and then perform the adaptation. Then, of course, this new case you can apply to your problem. Or perhaps, there is the revisions that occur and the retaining. Again, every time that you see case-based reasoning described, you might see slightly different presentation, but they tend to all involve at least the same core steps. >> So case-based reasoning is really built around the idea that similar problems have similar solutions. Observations define a new problem. So these observations being whatever the current state is and then that will be used as an index into our case database to try to select our similar problems. Thus a critical is being able to compute similarity in a consistent, accurate way so that we can retrieve useful cases. Adaptation can be essential. We'll see that it's not always necessary, but certain problem domains, especially adaptation can be important. A case representation, like I said before, it's going to define or represent knowledge about the scenario that the previous case was generated and we're going to use the current state with the selections of the same features. We're going to use that as a way to determine what are the closest cases. The information we're going to store is the problem or situation. That's just the definition of the problem. This is going to be domain-specific. Then we're going to have our solution, which might be a plan, a classification. Again, this is going to be domain-specific, the nature of the information that's being stored. And we're generally going to have an adequacy. And this is because we have lots of cases in our database. But when we find lots of close cases, we want to make sure we're using the best ones. And so one way we can do that is with this adequacy or utility score, and this is something that's ever evolving. Every use of a case means that we have this opportunity to update it. So if it turned out to work well, we update it and have a count. So we'll have a ratio like of successes relative to the total number of attempts to use it. In terms of the information we have, it can be complete or partial. So for instance, like matching the problem description, we don't necessarily have to have all the information about the state of the world. In fact, in many cases, we probably prefer to not do so. We maybe can do just as well matching or indexing with less information. Similarly, the solution can be detailed or abstracted, and so the abstract solutions might actually be preferable for adaptation, for instance. If we already have an understanding of abstract solutions, then that would suggest that it's adaptable. Representation depends upon the domain or task. In terms of the way we'll store this is generally it's going to be like an attribute value vector or feature vector, so we just have a case represented by some number of features. And we could also perhaps have some structured information rather than just like a flat vector, we could have something like a graph like structure. That's of course, going to introduce new complications for matching, for comparisons and perhaps there's other solutions. But typically in video games, the feature vector approach is probably what you will see the most. Imagine maybe in, say, some strategy type games you might have like more of a graph structure perhaps. But there's certainly, if you have efficiency on the mind, probably the vector is what you're likely to be working with. The goal of similarity that we're trying to understand, the current state relative to cases, what are the cases most similar? So the goal of similarity is to select the cases that can be easily adapted or just directly used to solve a new problem. This is basically it's a prediction of the utility of the case, and the utility is the measure of improvement in efficiency as a result of a body of knowledge. So is basically how effective is a particular case at improving or being usable for our solution. So the similarity is something that we determine before we apply our solution. But the utility is something that we don't know until after the solution has been applied to the problem, so we won't know until we see if it works basically. Now, there's lots of different ways we might go about computing similarity, but generally they will follow this a pattern shown here on the slide. Where similarity, the inputs is going to be the current state of the world, like maybe the feature vector, compared to the feature vector for the case. We've got these two different state representations, current state and the state of the previous problem. And then for each of these features, we're going to do just a pairwise comparison individually. So compare the current state with the first feature of the case and then the second feature and so on. This similarity will often be normalized. And this is important because you want to have some understanding of how much a feature is influencing the similarity score. But that said, even if we say we'd normalize, there's some customized functions for each of the features. If we normalize that 0-1 scale, we then might actually want to have a bias that certain features are more important than others. So we also have a weight. So each of these individual feature similarities that are normalized will then multiply by a weight, so we'll have these weights. These could be determined through domain expertise. They could be just like the fact that we've identified the features are useful at all. We might further say some are more useful than others. We might also empirically determine these weights maybe through some supplementary learning process. In addition to the case-based reasoning, maybe we find a way to optimize by making adjustments to the weights and the similarity over time. So that's certainly a possibility. And the similarity score is not something set in stone. There is definitely otherwise and what we'll see other examples of similarity. But often, you will see this particular approach to similarity. >> So for the case retrieval, we've got a problem description and then we've got an input, a collection of cases in addition to our current problem description. So the output of the case retrieval process is of this collection of cases, we want to pick the most similar case and so that's going to be based on that similarity score that we just saw. And so this could be just the single most similar case or instead of just a single one, we might want multiple. Because especially for considering adaptation like maybe one of those cases is likely to be easier or better adapted than others. So it might be useful to have a mini. And another variation is that we simply just want a sufficiently similar case. And so this you can imagine might be useful. Depending on the nature of our database, it could have a huge number of records. We don't necessarily want to exhaust all possibilities finding the absolute best record. The cases that we do have maybe the particular domain that we're working with, any case sufficiently close enough is appropriate for adaptation to the problem. And that can also improve the retrieval speed. Just simply having a threshold. So as soon as you find a case that is greater than the threshold, then that is acceptable. So in terms of solutions for retrieval, of course, you can simply just go through sequentially in the database and make a selection. That of course, the worst-case you'd have to search the entire database. You might have a two-step retrieval where you select a subset of cases and then sequentially within that set. And so basically suggesting some type of strategy for a hierarchy. And there are also other more advanced approaches that we will look at briefly in a few slides here. Now, in terms of the features that we might choose to store in terms of representing the current state and the cases stored in our case database like thinking from the perspective of say, a video game, the state of the game world. There are features, what we call surface features, and these are just measurements from the state in unmodified form. So for instance, we might have just absolute positions of the agent and the enemy. There's hardly any cost in retrieving that information which we have access to say, a vector 3 XYZ position for the agent and the enemy and we can just store that in the database. But for the particular type of problem I was trying to solve, it might make more sense for some processing to take place. So we call these derived features. So derive features, you'd think of as like metrics. So these metrics are useful for the decision-making, and you probably would have the same sorts of metrics would be important, even if you weren't using case-based reasoning other decision-making that we've talked about so far in the class, you may be still need these. But there are certainly implications of having derived features and that is that they can be expensive to calculate. So you have to balance things out. You might want to think carefully about, rather than just blindly come up with arbitrary derived features that you're not really sure about. You probably want to spend some time thinking about it like consider wealth, other approaches or similar problems, what information would be useful. And then only spend the time calculating those if they're truly needed. So some features of our indexing that are desirable, it's one is that it'd be predictive of case relevance. So for determining a similarity between the current state and something in our case database, it doesn't really matter how similar the feature vectors are if that is not irrelevant case. Ideally, we would have designed the features that we're storing and the similarity score and the weights and so on such that mathematically when we calculate the similarity, that should be predictive of the relevance. But it isn't necessarily. So that's something that you have to work to ensure that it works like this mapping, the similarity is predictive of the case relevance. If it's not, then you're back to the drawing board and need to rework things. You also want the indexing to be recognizable in the sense that it should be understandable why you're using certain features and also recognizing the matches from the cases, like recognizing why a particular case was selected. You also want the indexing to be abstract enough to allow for widening the future use of the case space. So if it's too narrow, then you're never going to be effective at adapting and therefore the utility of cases will never increase and the overall case base will not specialize in solving the problem, you'll just end up churning a lot of creating new cases that never stand out as being useful. Also, the indexing should be concrete. So discriminative enough to facilitate efficient and accurate retrieval. So here's another look at similarity measure. So this is using Euclidean distance. So you can think of all the features that define the problem space as each being a unique dimension and you can use Euclidean distance for comparing. And you still have that issue of before of some features might be weighted more highly than others if you're not careful. So for instance, if you say had a distance in meters that varies a lot in terms of the different scenarios encountered in your game, so that would be like a huge difference. But for a bool, you had true or false and it was true value versus a false value, so it's only different by say, a 1.0. So if their difference is 1.0 they're the same. It's a difference of zero. So compared to let's say your distance in meters, the Boolean would be weighted very small compared to this potentially huge distances. So you'll need to make sure to normalize these. But then in terms of importance to the problem you can have weights. And so even if you're using a Euclidean distance, you might have weights applied to the difference between each of these features. >> Is an example from a particular game. I believe this was like a reverse engineered StarCraft agent. There's some hooks that you can monitor the StarCraft game while it's playing. And so you can input user inputs and also read out positions of enemies and your own units. And so you can have an agent that plays the game. And so these particular authors, they made a case-based reasoning solution to playing the game. And so what it was looking at was for selecting strategies that were based on what types of units were present. And so this makes sense because you'd say you have a lot of areal units, then you're going to need aerial, meaning like flying units. In real-time strategy games, that often means that you have to have real early specialized defensive units for protection like ground to air attack or other aerial units. And then you can also have other sorts of strategic situations where you have to have specialized units or configurations of formations. So you could have a case-based reasoning solution like it was developed here. The important thing for similarity of the situation was the ratio of troops. So you can imagine that if you tried to represent this with absolute values and the similarity score, that would put a huge burden on the case-based reasoning or the database for case-based reasoning to represent all of these different absolute value amounts of say, ground troops and aerial units and long range indirect attack and all the different possibilities. But by representing state with simply the ratios, that added a generalizable element to the similarity scores. And so the learning could take place more easily. So these ratios and then that leads to the different strategies for what's appropriate for production, like building new units to get the correct strategy or to support the correct strategy, which would be to be able to defend your base from aerial units or long-range ground attack or whatever is appropriate. Now, another approach to retrieval that can be used is a kd tree. And so this is one of the more advanced approaches that can be used. So you can imagine that we can do the sequential approach, like I mentioned before, you have you k-space and you just compare your similarity score to all the records. If you're looking for the best one, you have to look at all of them. But we could come up with some hierarchy and that's what a kd tree allows you to do. And so if you think of your feature vector that represents the state of the current problem and the previous cases. If you think of that feature vector is like a multi-dimensional vector, then you can apply the kd tree. And what it does is you analyze all the dimensions and you pick one of the dimensions and then you see if there is a threshold value that you can use for greater than or less than and split all of your data points. In this case, it's the cases in your database. So if you can put like roughly half the cases on the left and half the cases on the right splitting on that dimension, then you've taken the first step in creating a tree structure. And then you can further split selecting whatever dimension does the best job of splitting. And you can just keep doing that and maybe returning again to the same previously used dimension. So you keep doing that and if you optimally select the split points and the dimensions for the splitting, you will end up with a roughly balanced tree. And so then for calculating similarity or selecting similar records, you now have this mechanism for analyzing the the current problem state. And you just go through comparing the appropriate dimension at each node to the threshold value. And you can work your way down and then you can find the best match node. And so this is fairly popular to use in case-based reasoning when you want efficient retrieval. Now, you might also consider using some dimensional reduction strategy. And this can be useful because when you do select a whole bunch of features for your case storage, some of those features might turn out to actually be redundant. They're highly correlated. And so they don't really provide much contribution to differentiating cases. You could have maybe just used one. And that might be something that would be reflected in your weights, especially if you can figure those out yourself. But you might get to the point where some features that are weighted so low that you don't even need them. But we can maybe formalize that process doing some dimensional reduction like principal component analysis approach. And then that would help us have a better designed set of features or potentially the way it's just revising the whole strategy. What do we even need to store as our features? >> A typical retrieval of records in the k-space is built around finding the closest example. So if we're going through sequentially we'll just keep track of the sorted order; which ones are the closest, and we might pick the k most similar items. The problem is in doing so we might end up with a lot of cases that are all very similar, so it doesn't really matter which of any of those that are selected for adaptation or to apply to the problem. They're all going to end up having similar utility, but if we're trying to promote learning then we might actually want a more diverse set of matches. So this is where this concept of diversity enhancement retrieval comes in, and so there's a lot of research that applied to case-based reasoning is trying to improve on this problem that I just described. So selecting k items such that they are both similar to the current query but different from each other. So we might need to modify just solely picking what's the closest to the current problem description but as maybe we select the closest problem, then that's going to augment how we're going to select the next item as we work our way up to k total items. We might be forced to look further away from the original problem in a methodical way, but then the benefit is we get a broader coverage of the possibilities, and we can avoid some of the less relevant items that may be are redundant with another case that already has high utility. So this can be very useful for case-based reasoning. So in terms of case adaptation, this is an area that again is very domain-specific and is very much an open problem because there's not a universal way to adapt cases. In some situations you might be able to do things symbolically. Look at rule-based systems, we had wildcards and we're able to manipulate symbols in terms of analyzing problems. So in some cases you might be able to do that to be able to identify certain symbols in your cases, and just be able to swap them out with a new symbol and things will work appropriately, but rather it'll depend on the problem. But here's an example of a recommendation system, say you're searching to buy a new used car. So this gives an example of maybe the user identifies some features that they're looking for and a previous successful match that led to a sale. It is found, but it has some differences. So you might go through something like wildcard swapping, maybe related to engine features or color, that sort of thing. And so you could maybe identify some adaptations that could be applied to a previously successful match and then you have to through some maybe validating. So for instance you might do the variable swap approach but then you generate something that's just impossible, like a V8 would never have a certain number of valves or a displacement would just be impossible. So you might have to have some additional watchdog or validation that would go through and confirm that the adaptations are appropriate before attempting to use them. But assuming that you can come up with adaptation that works, we can understand the benefit that adaptation can give us. If you don't have good adaptation; if you don't have it at all, that means you're going to have to store more and more cases but your database has to be bigger because you're not adapting. If you do adapt that means your database can be smaller, and therefore our retrieval effort would be lower. So you can consider this trade-off as you go from a few cases to many cases. The more cases you need that are appropriate for the problem space their retrieval effort is going to increase linearly, but for adaptation if you have a few cases that means that it's going to be harder to adapt to generally because your case is going to be further from the solution. So any sort of algorithm that you implement, it's probably going to have to work harder. But as you add more and more cases, that means the difference or the distance between a previously stored case and whatever change needs to be made so that it's applicable to the current problem, that's going to get smaller and smaller. So there's a sweet spot where the retrieval effort and the adaptation effort hits like an optimal point. So this all idolizes, and this isn't based on real data. This is more like just trying to give you some intuition about why it's useful to have adaptation. That said it's often hard to have adaptation in games, and many of the examples that you find including the ones I'm showing you have no or minimal adaptation. So the adaptations that you have again, they're going to vary a lot depending on the domain. We've talked a bit about how the adaptations might be generated, so you might have structural adaptations. This is where you have adaptation rules applied directly to the solution so maybe modifying certain parameters, swapping out or interpolating. That's much like what we are looking at or considering with the used car sale example, but you can also have derivational adaptation. This is where you reuse algorithms that were maybe used originally to generate the case solutions. So this would be like the classic traffic planning example. So you're going to reuse the same algorithms that you used before for path planning. And those results are stored as cases, but we might use a star to say we got the path from A to B and now we need C to B, then we'd find a path from C to A added to A to B. So CAB. So all we have to do is that little bit of extra path planning for C to A for our start location and then destination. And again this is all going to be domain-specific as to whether it's appropriate to have the structural, or derivational, or maybe a combination, or maybe you just don't need adaptation at all for your solution. So here I've already mentioned that there's no good general adaptation strategy that you can broadly apply. It's really going to require some expert design for your heuristics and your constraints. And so let's look at an example here. So this is another real-time strategy game. Wargus, I believe this is like a clone of your Warcraft II type or StarCraft type of game. So these authors developed a case-based reasoning solution. So this game involves resource gathering and building like in Warcraft II and there is a building-specific state lattice that is in the game. So these nodes represent different states that a particular player like the commander of the forces what their capabilities are. So you're probably familiar with this if you played a real-time strategy. You have to build certain buildings that allow you to build new buildings that allow you to build new units, and those new units might allow you to collect new resources and then you can build another type of building. And so you have this chain of dependencies that defines what you can do at any given point. So in this particular case-based reasoning implementation the. >> The agent has some particular state based on what has been built. And this will open up different tactics for the agent. As things get built, it might identify a plan to build more stuff because your army is not advanced enough yet, so you need to build more things, or it might be that the current situation, you have a certain set of buildings built and resources available. So that opens up certain strategies for setting up protective Tourette's or putting together a military force to go and attack. And so in this example, they used a k-nearest neighbor matching. In this case, the different states of the world. The feature vector is stored in the case database, and reflective of the current state of the game. Those features were related to to the state lattice, this hierarchy, and other features, but they're all associated with a plan which is repeated many times in the database. So you've got like say, a strategy of attacking or defending, different specialized types of attack and defending or building. So these different strategies appear more than once under different scenarios represented in the cases. Because of that unique situation with these redundant outcomes, or the plans. The k-nearest neighbor worked well. And so with k-nearest neighbor, what you're doing is say, if you have some means of measuring distance, you can find the k-nearest of something. So we're like we could use our similarity score that we've talked about before. But in terms of selecting a case, what we're actually doing is multiple cases are determining the outcome and that's the majority consensus and that of the k nearest cases that we find in the case database. The assumption is that we'll find lots of cases that all point to the same strategy. So like several say, like a particular defensive strategy or an attack strategy or a building strategy. So we'll have different unique cases, but they all will point to common solutions or strategies. So we can just count up of those k-nearest. Well, what is the dominant feature strategy that decides this case? That's the deciding factor for what the case-based reasoning solution selects. So I'm going back again to the slides so that there's no adaptation here. The only revisions that are made or it's just updating the utility scores. So those cases that contribute to the majority, we update their performance results. So another one, this is another real-time strategy game. And so this is an application building a plan. So we have the case-based reasoning coupled with these fairly complicated plans. So rather than having one large elaborate state machine, we have these snippets of plans, so it's a little bit, It's got some elements of a star planning that we've talked about previously. But the case-based reasoning is identifying from the current state of the world. These pieces of plans that can be applied and expanded and executed. So we can build on previous plans by appending to whatever the agent is currently executing these new bits of plants. And so we can update periodically, adding this. So another example, this is a commercial applications. Probably one of the most interesting examples of case-based reasoning that I've seen it in video games, at least. Abd so this, you may be familiar with it. This is from the fighting game Killer Instinct. So I'm sharing a little bit of gameplay here. A fan of the game, recorded this to YouTube. And so he's demonstrating, training his own own agent. So in a way he's programming it through example. So he is in human control of the agent that he's training. Instead they what's going to happen. And these are called shadows. So he is training his shadow how to fight this particular enemy. And then later, he can pit Is agent against the other agent. And so you can either fight the built-in AI of the game or you can fight other like your friends. So you don't have to actively do anything during the battle, you just sit back and watch. But all the moves selection is based on a case space that is built of the human trainers noobs. So in fighting games, there is a lot of high-level strategy such as, yeah, I'm trying to trick the opponent into responding to thinking like a certain attack is going to happen that it doesn't, or say, forcing the opponent to stay at a certain range, stay far enough away. There are things you can do to try to set up the opponent to get in the right spot so you can get a combination of moves going. And there are certain combinations that are really hard to stop once they start. And they can do a lot of damage. So there's lots of high-level strategy, but there's also this reactive type of things that player might do as well. So high-level strategy might involve lots of steps like a buildup city, the setup to get a combo or the actual execution of a combo you can think of as a high-level strategy. But there's also just individual like reactive noobs that are important as well, like blocking if there is an attack that is coming. So is really a challenge. How do you get case-based reasoning to capture not only this reactive response like immediate reactive decision-making. But also that the high-level strategy. So in Killer Instinct, they have a case database and they've got 40 state variables. These cases are stored on a really short time interval. So it's on the order of like per frame or close to it of the game. So these, the state information is things like whether the character is on the ground or in the air. Again, all the state information for the training data is coming from a human playing in this little special training arena, I guess. There's some information that is character-specific. So like a certain character, say can do special moves that no other character can do, then you might have information about that. There are also locations of items and in addition to where the opponent is and what state they're in. You also have, like I say, if there's a fireball or projectile flying through the air, there's information about that. Animations where they are in their frame count is stored. Previous action is also stored. This gives some context to any of the cases and is useful for chaining together multiple cases so that it gets back to the high-level strategy that we were talking about before, is that by being able to relate one case to the next, allows for having these sequences over, across time through multiple cases. Actions taken a course that's what we're looking for is for any given state, we want to know, well, what's the appropriate action to take. These cases are sorted in a feature vector, very efficient, like compressed, and designed for fast matches. And then a nearest neighbor is used for retrieval. >> So in terms of adaptation, there's almost no adaptation like the other game examples that we've seen. There can be some small changes. I believe I mentioned that there are. They can swap one character for another when there's lacking data. If your agent has been trained largely on certain opponents and then there's say a new opponent, it can just make assumptions that while there's going to be some other opponent, even though that's not going to be a perfect match. And it's not going to learn from this, the only learning takes place when the human trains it. So that's one thing you're going to lose out or at least I think it doesn't adapt other than the human. I guess potentially it could similar to the way that the human training works, but I don't think they do that. Not positive though. By the way, if you're interested in more information about the Killer Instinct, I'll have notes about it. So that there's a game developer conference presentation. So I believe got a link to a full one-hour talk on that. And then also a game developer conference paper that's on the website that you can check out if you're interested in seeing more details about this. I think that is probably the best example of case-based reasoning. Certainly with commercial games. So we will conclude by looking at advantages of case-based reasoning. So big advantage is with the learning potential, this reduces knowledge acquisition effort. It requires less maintenance to maintain good solutions with your agent. You have this ability to reuse solutions and improve the problem-solving performance. You can make use of existing data that you might have. It improves over time. It's adapting to changes. So incremental learning is actually taking place. And suitable for complex problems lacking formalized models. So you don't necessarily have to have some well-defined model. Potentially, you might not even have strong expertise in the problem and you might still have success with the case-based reasoning solution. You also have an audit trail. You know, the cases that lead to solutions, and that can be useful, maybe less so in video games, but in general, is useful from an AI application sense. Also, case-based reasoning has been well accepted in various application areas. Certainly, it has worked well in the game examples that I showed, and also other areas as well. As for disadvantages, you can quickly end up with large databases. These databases can be challenging to scale, you face a bigger and bigger challenge of retrieval and maintaining the information in the database. It can be difficult to change problem domains just like you're basically, even though you might have a good understanding of how the methodology of case-based reasoning works. It can be difficult to say reapply implemented system or say you have an existing case-based reasoning solution and the database is full. But the problem changes substantially in some way. Like new maps or for a video game, maybe you introduce a bunch of new maps. And so you still have all the old database. So that even that can cause trouble. The differences might be bigger than whatever your adaptation solution can adjust to effectively. Case-based reasoning also can have problems with data noise. So you can end up with a poor matching, or noise ends up where you end up storing lots of records because they are different. Where if you didn't have that noise maybe you would've had closer matches and you wouldn't be storing as much to the database, but the noise is basically creating these faults new cases. Also, case-based reasoning. A lot of the non-video game solutions are not fully automatic. There's been a lot of use of human intervention. So the case-based reasoning, if it doesn't have a perfect match for a solution, it'll ask a human to intervene somehow, to maybe make a final selection or adaptation, or say that this system doesn't know, so the human has to add the new case. Well, that's not going to work in a video game typically. I guess there might be a few special cases in video games where that would. But ideally in a video game you want to completely automate it. In case-based reasoning isn't necessarily going to be easy to always do that if there's things missing in terms of the case base. And the last thing to mention, this is from the old website, aigame dev.com. This was a critique of case-based reasoning for game dev. And so this quote, in fact, the crux of the argument, if you have a good scripting language or even a visual tree editor to capture sequences, you'll be orders of magnitude more productive and more reliable than an expert trying indirectly to get the system to induce specific sequences from examples. As such, it's fair to claim that case-based reasoning isn't particularly well-suited to these problems in-game AI. So this is really the author has issue with the fact that case-based reasoning only has these snapshots. And it can really be a challenge to get snapshots to be identified and selected in the right order so that you recapture the sequences, but still allow for diverse response to changing conditions. So yeah, that's our look at case-based reasoning. It is something that I think in certain domains, even within video game genres, that case-based reasoning could be effective. Certainly, the fighting game scenario has been proven to work well. And I think also examples and strategy may be strict strategy game genres. Real-time strategies or turn-based and it might be a supplement to other AI approaches not to be like the entirety of the agent implementation would be a case-based reasoning solution, but maybe something to augment other approaches.
