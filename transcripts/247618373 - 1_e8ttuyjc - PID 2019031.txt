>> Hello. In this lecture, we're going to continue our look at path planning. In particular, we're going to look at a new way to discretize a game world space. So this will be different than the grid lattice for instance. So this is the path network. So the path network is again an alternative to the grid lattice and other similar structures like maybe a quadtree, where we have this uniform structure defining an area. So instead of having that area-based structure, we're just going to rely on positions in the world and associate those positions with a graph. And so this graph will have the typical nodes that you'd be familiar with in other graphs that we've looked at and edges. The difference with a grid lattice though is a grid lattice has the implicit structure. Each of the nodes of the grid lattice is just known to be the center or some default offset from the dimensions of the grid as it's overlaid in the world. But in the case of the path network, each individual node has its own position. So for each node will have this additional information which are like a position vector so like two floating-point values. And then we have edges. And unlike the grid lattice, where all edges have the same way or all up and down left, right edges are same and diagonals are also the same for that category. We can have arbitrary edge lengths for the path network. So this still provides us with a means of performing path planning. We still have the graph structure, and so with that graph structure, we can again do the path planning and assuming that all of the edges are unblocked in the graph. So each node position is a space that the agent can actually go to, and then all edges are unblocked, then all the agent needs to do is just follow along the path. So it's really pretty straightforward means of discretizing the game world space. So why would we consider using a path network over the grid lattice? Well, the first thing is that we can consider one of the main deficiencies of the grid lattice, and that is that it is not very space-efficient. It uses up a lot of memory with unnecessary structure. Even though overall it's an efficient structure with the uniform layout, it still ends up being pretty wasteful and has a big impact on the search efficiency. So those are certainly things that we would like to avoid if possible, and potentially the path network will help us get there. So the path network, we have this ability to be variable in the way that we might put a lot of nodes and edges in one area of the game world and then maybe a big open area, say like a desert outdoor area. The nodes and edges could be very sparse. One other thing we might be able to achieve with the path network is the paths that are returned might not have that aliasing effect from the quantization part of the discretized space. So the jagged zigzagging paths that the agent might need to follow which is problematic for continuous movement agents. Not necessarily a big deal for a game world where we already have discrete movement, that is exactly the grids. So this would be much more appropriate for continuous movement. We do need to embrace this new agent movement paradigm, and that is because the nature of our path network, it has no area to it. We have nodes which are just single positions in the world, and we have edges which are just thin lines. There is no area to them. So the agent really can't be exactly on the path network, is more going to be in the vicinity of the structures, the nodes, and the edges. So in order to make this work, we need to embrace that the agent will have these different types of ways of interacting with the game worlds. So one we'll call local movement, and the other is remote movement. So local movement is just when the agent is moving around with normal movement like kinematic movement or steering behaviors. This is based on observing positions in the game world such as where an opponent is, other agents, collectibles, and so on. Those are positions that are easily accessible. We will likely include some visibility tests. So anything that the agent is doing locally will be based on being able to see the thing that either location they want to go to or whatever artifact the agent might want to move towards. So this could be based on a raycast. For instance, we could perform our raycast against multiple objects in the vicinity, and if we don't have an occlusion during that raycast, then it's safe to move towards whatever that is. Now we also have this other mode of movement called remote movement, and that involves the path planning system. So the agent can request a path return from some separate process that does the path planning and returns the path and then at that point the agent follows the path. And so this likely won't involve walking precisely on the line. Certainly, the agent is going to have a radius or some width. So it's going to spill over to the left and right of the line as it heads down anyways. So we have to be aware that there's lack of precision here. During the remote movement, the agent can either be on the path following from node to node and staying on or very close to the edges. Again, it's unlikely that the agent can be perfect, but we'll still consider that being on the path. And then the agent can go off the path, and this is usually because if some interruption, either a dynamic obstacle has gotten in the way, maybe some opportunistic opportunity task pops up, like go pick up something like a goody. There could be an emergency, maybe the agent has encountered an enemy and has to go fight the enemy. So during this time, the agent can remember where they were before on the path, then go into a local movement based on kinematic movement or steering behaviors, and then do whatever needs to be done. And then assuming they get to a point where they're finished and want to get back to the path following, they remember that the point where they left. And so they'll attempt to steer towards that just with again, local movement. And once they get to that spot, then they can safely begin following the path again. So this is a bit different in terms of how we had agents moving before, where they're always on the navigable space now they're not. So that is a new challenge to deal with, and so something we have to be aware of. >> So one design implication because of this, is that in order to be able to use the path network, our agents local movement must be robust so we have to have effective detection of obstacles, reliable movement on terrain of various types, whatever is part of the game, the agent needs to be able to reliably deal with it. So that potentially makes implementation a lot more challenging. I want to go through an example, basically highlight the high-level steps of the algorithm. So here I have a game world in 2D with obstacles and you can think of these as, like buildings or hallways. And we have our path network of course, so we have nodes and weights. The first step is, let's say our agent wants to perform remote movement, so we'll put the agent into the world. We want to find the closest visible node. This is a situation where the agent is going to query all of the a local nodes, in the worst case like a naive implementation, we would just check against all nodes of the graph. But in a bigger game where performance is important, we might have some additional spatial subdivision structure, break up the space of the world into bins of some sort. This might be like a grid Lattice, but only for the purpose of defining neighborhoods of objects. So you could figure out which of the bins the agent is in and then what are the nodes within that band, and then you also searched the adjacent grid cells in those bins as well. This is a common data structure that is used in games. But once you have your neighborhood of nodes, you can then perform a ray cast to each to see if casting a ray from the position of the agent towards each node, is it an occluded? So meaning you don't get any collisions with the ray as you aim towards the node. Now in this case, the example shows one ray cast to the right, and node A is blocked clearly because of the wall. But then our ray cast to the left shown in green is able to get to the node G so the agent is able to see the node. That's the first step. Next, we need to do a similar process for our goal. So we have a goal to get to the pot of gold. For this pot of gold, we do the ray cast. This situation we have more than one visible node, so we are going to pick the closer of the two. And so ad the agent seen more than one node, we would've done the same thing, pick the closest. So now we have a starting node in the path network and a goal node in the path network. We also have these little tails, the little tail to get the agent from where the agent is currently to the start, and then once we get to the last node in the path network, that little bit to get us to the pot of gold. We will remember that and append it to whatever the result is once we have a path. So we request the path search system to perform a search. This would likely be an A-star search. So here is an example of result path, so the agent can now begin the remote movement process, and so this will involve following the path. So first, we'll complete that little bit, that little tail extra bit that gets us to the beginning of the path. From the agent's perspective, it could have already been passed all of this information, just one complete path, but it might have to separately steer to the node before it can then follow the path. And then at that point, the agent will follow the path, and then finish off the little tail that gets to the pot of gold. So it's really straightforward process to use the path network but you may have noticed some issues here. So one is that there's some inefficient movement, so from the perspective of where the agents started from and where it was going, this particular path led it along a less than efficient route. As it's definitely a lot smoother than the four-way connected grid Lattice zigzagging along the grid cells, so certainly smoother than that, but we do have this odd veering away from where the agent clearly needs to go for the most efficient path. And then especially bad is the strange double-back as a result of the quantization. So when we were determining the closest node to the pot of gold, it actually created a scenario where the agent when following the path, has to backtrack to get to the gold. So ideally, we'd want the agent to take a more direct route to get it. There's other concerns that we have in this scenario and that would be when the agent cannot see a node from its current position and same with the gold. You can have the same scenario with a gold like the pot of gold. So in this case, where does the agent go? We might have to consider some solutions. Had the agent started in view of path network nodes, it could go through a process that it keeps checking to see if it can still see one, and if not, it drops like an intermediate waypoint. Similar to going from following the path to getting interrupted and going off path. We could extend that process to maybe remember where it left and then hopefully be able to see that whenever the agent's done doing what it's doing, hopefully it can still see that point. You can get more complicated and chain together multiple intermediate or temporary waypoints as well, in fact, we'll talk about dynamic waypoints in a bit. We also might be able to come up with something with just the local movement, such as following along the edges of walls. There could be something we do maybe dividing the edges of the path network into point somewhere along partway along the edges to create more nodes. Of course, this can get expensive, but like subdividing edges and keep creating new virtual nodes, then the agent could test with the ray cast to see if it could see those. That would allow the agent to figure out the right way to get on the path. Another thing you could do is just teleport the agent. This could work especially well if the player can't see. If the player is not looking, just teleport the agent and they won't even know what happened. They'll just know that the NPC is now doing what they're supposed to rather than being stuck. But there's a lot of things that you could try to do here but I think this really indicates how the agent needs to have more robust local movement in order to take advantage of the path network approach. >> You might be wondering how do you go about building a path network? And there's two main strategies, one you could have a manual placement process, using a level editor and then just drop nodes and then connect them to make edges. This can be very tedious but it can have very good result. And you might have some hybrid where you say you have manual node placement but then automatic edge forming. Or it can be totally automatic but the advantage there would be that it'd be quick but it tends to be inefficient especially in terms of how many nodes and edges need to be placed, and it can also be very temperamental, like if you tune some system that does this automatic placement, and then say you have some new level that your development team has created and say you're in charge of building the automatic placement of nodes. You try it on the new level and then it's not working with a new level, even though it worked with prior levels, so it can be a temperamental flood of thing, but we'll look at some automatic methods of placement. So one is that you could have a flood fill, so you start with some seed position and then you determine offsets in various directions and just iterate through the left and right, up and down, and so on, and start placing nodes. And of course you don't want to place a node if it's not a valid position. So if it's inside of an obstacle, you would just either delete it or never place it there to begin with, and so the whole growing processes, this flood fill, is constantly analyzing the game world to decide whether that is valid or not. Same thing with the edges. The edges that can be created, at least say a candidate edge can be created and tested with the world to make sure that there is nothing that intersects with the edge or gets too close to the edge. And we would probably have an offset by the agents collider radius because we want to ensure that our agent can actually traverse down each of the edges without bumping into anything. A big prominent here is that this can be as dense as a grid lattice but you're losing out on all the uniform structure of memory savings. As you recall with the grid lattice, you don't actually have to store in memory positions for where the graph nodes are, you can drive it at run time just by the index into the grid, and then the cell width, just you multiply that out and that'll tell you where you are in the world. Same thing with the edges, you don't actually need to store the edges because it's already part of your grid, so you can just analyze from a current cell like an ij position in a grid lattice cell, you can say, well, do I have a clear path to the left, right, up, down. Just by analyzing relative to that ij position. So none of that needs to be stored for the grid lattice but with path network, each of your nodes is going to have a position vector in the game world but again, with the flood fill, you have this automatic structure so it's not very useful. You might get add an additional process, you first grow this very dense structure and then go through plucking away nodes you might be able to automate that, try to identify how many nodes can be taken away but that can be a very challenging process to implement. Another more popular approach is to use points of visibility. This is an automatic technique for path network placement. And we have features in our world, perhaps that maybe geometry of a building, hallways and so on and this will create natural inflection points. So you can imagine that these convex angles that are part of the geometry, they get in the agents way so the agent has to steer around those features to get where they're going, and the most efficient route is going to be getting as close to those features as possible. If you think about, pulling a string through an environment and pulling it tight is going to get pulled up against those corners and be right at those inflection points. Now the actual path the agent would have to take having some radius to the agent, would mean there's going to be some radius to the turn, so there's going to be an offset from the, say, the convex corners of the walls or other features. But then as that offset is applied, the most optimum route would actually be a curve or we can just approximate it as just an offset to a point and then the agent can turn at that point if they're following a path network route. But the idea is that, you identify all these inflection points and then you can connect the inflection points with the edges so you make path network nodes at the inflection points or the offset position and then you connect edges just by line of sight, you could possibly cap how far an edge connection could be made, so maybe you only make edge connections that are within some number of units away. But this can create functional path network to explore the full environment and can give pretty good path results. This can be an expensive process to identify, probably will end up with lots of these points of inflection of the contexts, points to perform the offset. If I really want to have some simplified version of the geometry, often you can get this from the physics collider, so is a visual features like what's drawn on the screen, it's often more intricate than what's used by the physics system, is approximate geometry. And so that would be a lot better for running this process of generating the path network. In order to place these offsets, we could find a bisecting line of each of the convex angles and then just along that line from the convex corner, just move from that corner point out by the radius of the agent perhaps plus a little further distance just for fudge factor, and then that would be where we've actually create our node. So we can do this a first-pass generating all of our nodes, and then go through just a brute force process of testing with a re-cast or actually a distance from line segment, would better capture what we need because we want to make sure that the agent can fit along a corridor from each of these points. So that we would include an edge intersection but also the offset that would be tested for. So once we do that, that'll create nodes and connect to the edges and then we can use that in our game. Here is a visualization of how this process would work so we start with some geometry that we then get an offset from, the geometry shown in gray, the offset is in blue and so that would be these points. Then we just again go through this brute force process of checking for what edges that we can connect. So once all of those edges are connected, then we can pass that onto our game, immediately we can use it. You might find that you want to maybe have some hybrid approach where the game developers could maybe add some extra points, may be combine points of interests, say collectibles, spawn points, so depending on the game type, you might add some additional nodes just to make it easy and not rely so much on local movement for the agent to get to other features. >> The paths you do get will tend to hug walls and go right at the point of inflection for turning. So once you perform your path search, you'll have some pretty good paths with this route. Downside though is that you can get some unnecessary nodes and edges created. Again, you might have fairly complicated environment. This guy like architectural features that cause a point of inflection to be recognized. But is really more resolution than you need in terms of the discretized space. So that can be tricky to get right. You might end up wanting to go in and delete things or adding hints to the game scene that mark regions and say don't create nodes in these regions and so on. And you can end up going down a rabbit hole of adding these extra features so that you can give hints or have better heuristics for this automatic placements so that it does what you intend. But it is possibly taking a lot of work. At some point you might think, well, maybe instead of trying to force the automatic path network to work, we might instead just use like a navmesh, something like that. So something to consider is what level of complexity are you willing to take on just so that you can get the path network to work. One other thing I want to say about the points of visibility is that you could potentially try to automatically find other points as well. And so one thing you could do is maybe certain concave angles. You could possibly try to place points there, but it's a little bit more challenging to do. And of course, doing so will have no benefit in terms of path quality. And if you already have robust local movement for your agent, this would be pointless because the agent could just go to one of the points of visibility as the goal. And then if they needed to get near something in the corner of the room in one of these concave angle areas, they should be able to do so. But if you don't trust that ability, that would be a reason why you would want to maybe place additional ones. So if you were to place at concave angles, maybe like the corners of a map, in addition to finding the bisecting line of the angle, you also need to find the offset from the two edges that make that angle, so like the two walls for instance, you need to offset by at least the agent radius probably more. So you probably are going to add a little fudge factor and then determine a point along that bisecting line to replace the path network node. So again, this is especially useful, I just wanted to point out what would be necessary to do so probably a more useful thing would just have these points of interests again, that would be associated with game world features or objects like spawn points and collectibles, that kind of thing. So let's suppose maybe we have a situation where we have candidate nodes already defined. So this could either be part of manual placement, like a hybrid manual placement, or it could be part of a fully automated system. This would just be the second step after having found a candidate node position. Now we want to start evaluating a collection of nodes and determine if we have a valid edge between them. And so by a valid edge, I mean that we have an offset from the line segment such that the agent could fit along that entire length from the starting point to the endpoint. So can use the agents radius as an offset of that line segment. [NOISE] So that would ensure that if the agent is perfectly following that edge as part of a path, then the agent can fit. So we can use a couple different tests. So one would be the point distance to a line segment test. And then we can also include a line segment line segment intersection tests. So if we have both of those tests, then we can do the necessary evaluation. Assuming that we can grab the appropriate information from our game world and in terms of lines and edges of obstacles. But ultimately, if the corridor is clear from the starting point to the endpoint of the edge segment, then we add that to the graph so we connect the two nodes in question. So here I've got a figure that considers the different possible scenarios that you might run into during this process. So at the top I've got a valid edge, shown in the yellow or gold color. The agent is shown in blue. So I'm going to, hopefully you can see the mouse cursor here. So here is the agent shown as if it was moving along the corridor. and you'll see that we have a starting point for the edge segment and endpoints. So those are two candidate nodes. We could define this line segment and we could check for distances to nearby points or a naive approach would be to just test against all obstacle points. So that would include in this case, we've got two obstacles with four corners each. So we can test against all of those if they're closer than the radius to the line. And we also have the boundary corners as well to test against. But another possibility is that the points of the lines or edges that you encounter might not be within the distance, so then you have to consider the impact of edges. So you wouldn't want to test against all four sides of the obstacles to perform an intersection test to see if any of them intersect with this candidate edge. And also the four sides of the boundary we could use the test. Then another possibility is a parallel edge condition. So what if the edge was really close to say the boundary? In that case, the vertices of the boundary wouldn't be too close to this candidate edge. But it's rather the other way around the vertices of our candidate edge, are too close to the edge of the boundary. So you got to invert your tests. You have to consider for both perspectives to catch all cases. So you have to do the point distance to line from the perspective of the candidate edge and also the perspective of the edges of your obstacles and boundary. And then you also will perform the line segment line segment intersection test to see if they actually cross. So you can see some of those other scenarios here. So we have CA, there's a candidate node that is outside of the game world. So in that case, we can just screen with a range check and immediately identify that did not proceed further with that one. Over here on the right, this test distance failed. That is a failure. The solid red line shows what the failure was and that was it was too close to the boundary. So that would be the distance to the boundary line of that node was too close. Here we have an intersection tests fail. So this node here, there I've got the mouse near the bottom. It is the radius distance away from the lower boundary, which makes potentially good. But at least when we try to connect it to the upper right node, you'll see that we get a line segment line segment intersection against two of the four edges of the obstacle. Of course, the first time we test against even one edge that fails, we don't want to continue because it's just a waste of processing power. So the first failure we encounter, we probably ordered these in some hierarchy priority so that maybe the more likely to catch a failure or first, or maybe something related to the computational cost. So depending on the way we order this could be more or less expensive. Certainly we want to have the short circuit exits or continue on looping with other combinations. >> Another failure we have here on the bottom. So this path node in the bottom labeled with the text, PathNode. We could cast or draw a line segment over to the left, and so that looks like we wouldn't have any edge intersection, so we have a clear edge. But then look at the distance from that edge to the lower corner of the big obstacle. So you'll see that that distance is too close. So that is a problem. So that would be the distance from line segment to point test, and compare that to the radius we see was too small, so we have to abandon that possibility. Over here to the left of the big obstacle, we have this node and it is too close to the edge of the obstacle. So this is where we consider from the other perspective and so that would cause this edge from being created. The reason why that is is because, if the agent tried to go all the way, say, if go to left and then down following a path, it can't get that close to the obstacle, so it doesn't have a fully clear corridor. So just for those tests, if you're careful on how you set things up, you can capture all of those different possibilities. Next step, I want to look at a bit of a tiny case study, this is from the game Quake. It was highly extendable. Its software made it such that hobbyists could make their own modes to the game. This one particular person, Steve Polge, made an agent that could play death match. And I recall back during the time that this work was done, people that were fans of games, if you wanted to be in a discussion rather than Reddit, you just use Usenet, which are the old school newsgroups. And I remember a lot of debate talking about how no one would ever be able to make a death match bot that could provide any challenge to a human player. And so Stephen took on this challenge and began implementing his own bot. So this bot actually ended up working really well, and in fact, gives a lot of good death match players a hard time. It was not ever even complete, but it was still really impressive. And the reason it was incomplete is because the work he did was so impressive that it drew the interests of Epic Games and so he was hired and ultimately built the Unreal Tournament bots and worked on a number of other games. But the Reaper Bot is interesting because it used path networks for movement. So the picture in the lower right shows one of the Quake editors with path network nodes that are placed. You cannot see the edges. So you could either make a handmade paths of nodes, or handmade path network for recognizable levels. But then if, say, during a multiplayer death match, there's a new level that was unrecognized, the agent could even dynamically build a path network. And so that was something I wanted to consider is, so how might you have your agent perform the building of the path network? So you can think of it as like dropping breadcrumbs. So this of course would be similar to what Hansel and Gretel attempted, of course, I guess the birds ate them all and it didn't work out so well. But in the case of the agents, they can just store things in memory to keep track of where they are. The idea is that the agent drops waypoints at important locations, and from doing so, creates a complete path network. So at a high level, this algorithm would work by, you start at some initial location, that would be the first node, and then each think update, and this update could be not as often as the frame rate of your game, it could be slower perhaps. And the reason you do that is for performance reasons, you wouldn't want to do all these computations every single frame, so you could maybe skip a few. So during this update, you check to see if from the current agent position, can they raycast cleanly to the last waypoint or perform the distance to line segment test. Most likely we would only be a raycast though because it would be impractical to test against all the obstacles around. It'd be hard to facilitate only identifying the closest obstacles. So you do this test, and so as long as you can still see the last waypoint, there's nothing to do. But if you can't, then what you need to do is store that last waypoint as a node and then basically continue on this new path. So every time that the agent can't see where they're trying to remember where that last waypoint is, like it's secluded, so they walked around an obstacle, then that's when you need to start a new waypoint. And so these keep getting dropped and you constantly are testing. So just continuing on a chain is really pretty straightforward, it's got a constant load in terms of performance and the memory, how many nodes is store, is going to depend on how often the path it gets occluded. Eventually, you run into this scenario where you loop back on yourself though, so this is where you run into issues because you would want to reconnect with the previous parts of the path you created and also be able to leverage those points to avoid just creating nodes on top of nodes on top of nodes, so the agent has to be aware of this. The problem is, this building process can get pretty expensive and the load will vary and you are trying to maintain a real-time performance of a game and it's getting worse and worse, so dynamically managing that is going to be a challenge. I believe in The Reaper Bot's case, there was a cache of a fixed size, so things fell off the back end to the cache if they weren't used often enough, so there were some levels where the cache was not big enough and the agent could get caught going in circles because it would forget what it had learned before it came back again. So it didn't always work perfectly, but it does have some potential. So applications of this dynamic path network approach. It could be great in scenarios where maybe you have procedurally generated worlds. So there's no way that you could pre-author or bake the path planning into the game as the player explores these new parts of the world. If you did need to have agents be able to perform path planning, maybe like pets, some sidekick, or maybe it's just a much more complicated procedural content generation game where you do want to have some persistent agents, then this might be critical to getting it to work. It's something like this where you could dynamically build the path network for the agent. >> And this could also work in all scenarios like the Reaper Bot where the developer just couldn't take on the effort to hand-make path networks for every single deathmatch level that was out there, so if someone was running but it'd be nice if the bike could just work on any level. So that was the motivation here. Disadvantages, of course, there's the runaway waypoint formation, eating up memory. The cleanup process can become expensive. And by the cleanup process, I mean, when the agent loops back on previous pads and being able to recognize and join those, there's a lot of complexity that is created. Recognizing that you're back to old nodes and not making new nodes on top and so on, it's really a challenge. Now, we've seen that the path quality with a path network can certainly be better than a grid lattice. But we've also seen examples where it has problems, such as the weird tracking back that we saw in a previous example. So we might still want to be able to clean up path such as with a string pulling algorithm. And the issue here though is, well, we could come up with a way to do the string-pulling. We would be testing against world geometry, which it's hard to make any guarantees about how much geometry is going to be in any given level. Now, the problem also with the string-pulling is that we can't prebake this. Or I guess you could if you've cache all of the different possible paths, but that would be impractical for large maps to cache all possible paths that could be returned. So this is likely something that does need to be performed fully real-time. Another approach you could have is to use a Greedy Path Following. So you're going to spread the processing out over multiple frames because the agent is going to be constantly making movement decisions. And those movement decisions could potentially do some of the smoothing for you. So I can show you just a high level how this might work. So in this case, we have this greedy steering following the path. So instead of trying to religiously follow exactly the path, the agent is going to always be looking ahead for opportunities to cut corners.So in this case, it's just going to say, can I see that my current target node if yes? Can I see the next one? If yes, can see the next, and so on and so on until it gets to the last one that it can see. And at that point, the last one that can be seen means that you look one further and couldn't see. So you have to backtrack to a node. And so that point you're going to steer towards the next to last one that was evaluated, which is the last one that you could see, just go straight at that node and then each frame or every so often maybe each thing cycle, you're going to keep trying to look ahead to see if you cut off the corner again. And so over time frame to frame, you might actually create a curved path. Or your agent will create a curved path that will look a bit like string-pulling. Now the danger here is you can run into trouble. So for instance, what if there's a pit that you could fall into. You have to watch out for the red cast isn't going to hit the pit, so you've got to deal with that. A way to deal with this actually is to have an invisible volume that is the ray casts we'll hit. Of course, this volume doesn't impact game physics, it only impacts the ray casting. So that's a good strategy for dealing with pits, it's just having this Invisible geometry. You can do the same thing over like slow-moving, terrain like if you have a mud pit that technically the agent can go into, but you just don't want them too. You can do the same thing so that would facilitate this greedy steering. And you could also sub-divide edges rather than only looking at the nodes. Of course, that would be more expensive, but let's go through just a scenario. So here we have the agencies, the first node before it even makes this current frame decision it looks at first node, looks at the next nodes, you can see it. Third node, you can see it. Here's a little [inaudible 00:53:24]. If you're only doing a re-cast, you might have a situation where going to go bump into the corner. So you might want to do the point distance to line segment tests, but you need to be able to efficiently identify the local geometry and not be testing, it's like huge amounts of geometry in the world. Many game engines will have some way to efficiently runtime. Identify again, something like the Ben key strategy I've talked about before for identifying neighborhoods, the spatial organization approach. But in any case, we want to make sure we have a clear corridor. So this scenario, the agent can easily get to the second node, but the third node is a no-go because of the corner of that triangle. Now there's some problems with using the greedy steering we've already discussed. So it's not a perfect fix for poor, mediocre path network, half quality. The ray casting can still miss some things. The ray casting can get expensive. You can have problems, especially on my variable height terrain or different terrain types that would affect movement speed. So maybe the path that you've searched for, has already done a good job of evaluating the quality of the path through edge weights and now you're going away from those paths that are guaranteed a certain overall cost and now you're walking through the mud pits and so on. Or your agent is getting into some trouble. So it's not really a perfect solution. It can work especially more in simple games where you have very simple 2D structure. >> The shortcuts your agent takes might not actually be good shortcuts. And in order for them to be good, the agent has to be really good in real-time evaluating the game world. Let's look at some of the benefits of the path network. Discretization of space can be very small. We can get away from the density of the grid. It doesn't require that the agent be at a path node at all times unlike the grid. So each cell in a grid Lattice is directly associated with the path node. That doesn't have to be the case here, which can be a benefit. And therefore, you can allow the agent switch between local and remote navigation. Works well with continuous movement agents in games such as first-person shooters and RPGs. Also, we can associate with our nodes some useful metadata, some like gameplay related things such as cover locations or collectible pickup points, and other points of interests. Downsides of the path network, is that one you might have valid agent positions, but you can't see the network. Therefore, the agent is not able to easily get onto the network. And we talked about what are different strategies for to get the agent to find the path network again so that it can perform remote movement. You can still end up with jagged path shape, maybe not as the stair-step look of the grid Lattice, but you still can have some very goofy looking paths, and backtracking. Has trouble with dynamic and rolling terrain. Because the agent has to make all local decisions as soon as they're going off the path. The storage and complexity issues can runaway, and maybe even approach as bad as the grid Lattice. If you're trying to get really good coverage of your network. So you keep adding more and more. And then before you know it, you're no longer getting the benefits that you were hoping to get over the grid Lattice. And keeping in mind the grid lattice has that implicit graph structure in it that has associated memory for that density as the structured nature of the grid doesn't need to store the 2D vector positions for each cell. It's all implicitly generated. Whenever the agent goes off the path network, it can be dangerous. So we've seen that we have to rely a lot on that. The abilities of the agent during local movement. And it can also put a lot of real-time computational pressure on the agent implementation. If we could bake a lot of information into our discretization, then that would be less at the agent has to do. That might be pointing towards the benefits of something that does define area. Maybe if there's something similar to grid Lattice, but didn't have that, such the density, the structure of the grid. That's something we'll see. We'd like the nav mesh for instance. One last thing I wanted to look at to close things out with the path network of variant, the path network. This is the path network with variable size corridors. So far we've considered corridors being just along an edge that the offset, the radius and you end up with what looks like a rectangle with rounded caps or I'm a Tic Tac pill shape and in 2D. But instead, if we had variable radius than it would be more like an ice cream cone with a rounded tip. This could of course have different sizes of radius for the nodes. And so this would be able to define a useful area to the agent. The agent is smaller than the corridor and therefore could move around within the corridor. That could allow possibly for some planning while still fully on the path. There's no need to necessarily leave the path at all times to say get around a dynamic obstacle. Maybe you can just move to the left to right within the path. Maybe collect things and still stay on the path or so on. It might make string pulling more efficient. We have this nice concise definition of these areas. They're convex structure, and it's defined by the 2D vectors where the two nodes are. So node A and node B are each 2D vectors. So that's two floats. And then we have two additional floats for each radius for the starting point and endpoint that each have their own radius. In terms of determining a point containment. This can be pretty straightforward to do because with the point distance to line segment calculation if you look at the details of an implementation for that, we're going to end up with a vector line equation. So we have a t scalar times the direction of the line. That scalar is going to be normalized 0-1, from a to B, a would be 0 and then B would be 1. And so that would tells you where you are along the line. And then with a linear interpolation that can tell us which of the two, where along the scale of from the first radius to the second. Like how big that radius should be, so very easy to create our test. This is going to work with multiple agents because you can size it as large as you can, and then as these variable size agents leveraged the path network for path finding, you can just subtract away provided the overall network, like all nodes, are bigger than your biggest agent. You just subtract from each node radius, whatever the agents radius is, which will give you a smaller radius. That point, you just treat the agent as a point, not as their overall sides. And you just think of moving that point around within each of these convex areas which are fairly efficient to determine. Anyway, it allows us this planning. Some downsides with using it. There's a course, the actual generation of these baking. What's the appropriate, like how big can you make each of these radius for each node, or where do you put the nodes and so on. It's a challenging optimization problem to pull that off. It's still doesn't fully represent the navigable space either. It's only as good as where you have notes placed. And also it doesn't accurately reflect the inflection points. You might be able to have an inflection point be contained within an area, but it's not necessarily going to be right at the center of these points. So you got to work with that. That maybe begins to include some features that you might find in a NavMesh, but still has some disadvantages. And so of course, we will also look at NavMeshs, which might have some even better ability to fully represent the navigable space.
