>> Next step we're going to take a look at Dijkstra's algorithm is similar to breadth-first search. So in fact, let's go back to thinking about breadth-first search. The nature of breadth-first search expansion guarantees that the shortest path is going to be found for equally weighted graph edges. But it also seems wasteful to spread out the search equally in all directions. Because clearly the goal is in a certain direction, there's not a lot of winding hallways to go around like a maze, then it especially seems wasteful. But let's focus on this first issue of the expansion. So again, that works for equally weighted graph edges. But what about scenarios where the edge weights are not equal? I have a little scenario here shown with a simple graph. There is a path AFE. Those two edges between the three nodes each have a weight of five. But we know the breadth-first search starting at A is going to favor stopping as soon as it finds a goal with the shorter distance. But if we look at the sequence A, B, C, D, E that's 2, 2, 2, 2, adds up to 8. So really that would be the optimum path. So this is an example where a breadth-first search fails. So could we revise the algorithm so that it can handle this scenario? Let's think about what adaptations we might want to make. One thing is we could add some extra metadata to our node records as we're expanding and considering different nodes, we have a cost so far. And the way this would work is as nodes are expanded, we're going to update this cost so far. So as we pick a node to expand. Well, we know where it came from already because of the from node information. Just the fact that the algorithm is on the current node considering what to expand. So as this occurs, we can just add the total for the current node when we initialize the next node, we just add the edge length to that running total. And so each node will have a running total for whatever the shortest path was that lead to it. And then as far as the algorithm itself, the breadth-first search in this adapted form, instead of expanding everything equally, we want to select whichever has the lowest cost so far. We're not going to use a stack or a queue, but instead we need something that allows us to efficiently extract this information. One special consideration is if we ever have a situation where an open node is revisited from a different from node. We would need to check if the alternate route that would be formed in this case would be better or shorter and therefore updated. Now that is not a concern for this particular algorithm. But if we come up with any other further variance, I want you to keep that in mind that we might need to do that. Another issue that we're facing is that if we had negative weights, we could potentially have future edges that we might encounter on an alternate route to the goal. So let's say we find a path to the goal using this approach. We might actually have to expand the entire map. If we did have negative edges because there is always a chance that the running total, the cost of far could suddenly drop. It turns out for our case, like for a video game with a Euclidean space that we're creating our discretized space from. And therefore our graph is dependent on. We're not going to have negative distances in your typical case. So if we impose this all positive weights condition, then that means that we can stop as soon as we find the node. Just expanding the cost so far. So this change that we've made to the breadth-first search, this is Dijkstra's algorithm. So Dijkstra originally intended to evaluate the entire graph from the perspective of one starting point. And then when you populate the entire map, like a finite size map or graph. Then you could look at each other node and it would tell you the cost to get to that point. And you'd also have all the information in the map using the from node backtracking that we've seen before. Between the two it serves as a map from that one starting point. So you always know the shortest route from the perspective of that point. But we can revise this so that we start the algorithm from the starting point and then stop once we reach the goal. So that is called the uniform cost search. It's a variant, I guess of Dijkstra's algorithm. And probably more appropriate for our purposes for path planning. You can think of as like a breadth-first search for weighted graphs. And we can see it in action here. It appears pretty much the same as breadth-first search in the four-way connected grid Lattice example. Once we reach the goal here, we'll see that the path looks the same and that's what we'd expect because all our edges are equal weights. So we're not really even taking advantage of what Dijkstra's algorithm provides to us. So this would be more important if we had like unstructured layout of weight points in edges. So we have varying distances than Dijkstra's would be critical to finding an optimal path, at least in comparison to breadth-first search. Look at some other examples here is Dijkstra's unblocked, at least for most of its expansion. And again, it looks just like breadth-first search. Here we see Dijkstra's blocked. The fact that it does spread out. The way that it does means that it doesn't get stuck in a local minima situation. >> Here is one with 8-way connectivity. Let's see, it's not starting. Let me see if I can make it play here, it wants to be full screen for some reason. This is what 8-way connectivity. So you notice that it's got an octagon look to it. That's because of the eight directions. And it looks like there's some little video glitch there. Sorry for the corruption there, but hopefully you get the idea. Next up, I've got some code for Dijkstra's that is a little bit more detailed. This is from millinewtons game AI book. I just wanted you to be able to see this for reference and probably helped to clear my portrait off there. Also at the very inner shows the backtracking and reversal to create the path. But this demonstrates the update of our open and closed sets and the operations for updating our costs so far. Otherwise, it is very similar to the breadth-first search, of course, you can check this out probably a little more legibly in the lecture notes PDF. We can consider Dijkstra's algorithm related to games. So back to this issue of the weighting of our edges and the positive value requirement. That's generally not an issue, but maybe there are some circumstances where it could pose a problem. So if the weights instead of distance, were travel time, then you might have problems if there were time travel involved in some fashion. Actually, games that do involve time travel, so you'll have to find some alternate way to think about path planning if you're working with time. But that is, of course, a very specialized scenario. You also might have teleporting. So you need to watch out for edge costs that are equal to zero. If you've had an edge cost equal to zero, then you could get stuck in a loop and keep going back and forth between the two because that would be favored and you'd never get anywhere. So you need to at least have some cost in place. I have a portal shown here. Of course, it'd be an entirely different scenario if you could create portals in arbitrary places related to Dijkstra's. This is rather assuming that you have fixed portals within the static map. So one problem with Dijkstra's algorithm is that you can potentially end up evaluating unnecessary nodes. So because of that, it can be much worse than breadth-first search. This is a little demonstration of how that might play out. We could have many nodes. Of course, we could make this a much more extreme example, but they have small weights. And so those will be favored for expansion. But then ultimately they could not be the best path to the goal, but they still have to be explored. And then here we've got the top half has got a lot of little short edges. But then there's this one really long edge at the end that takes us off the making progress. But alternatively, we could have a different direction that has maybe one edge is very expensive, but actually gets us really close. This is a problem with Dijkstra's, is that it doesn't work well in this situation. In terms of performance, I'm assuming here uniform cost search version. So it is complete, it is also optimal. Again, recall that we have the requirement that this is a static map of finite dimension. In terms of time, it is a complicated bounds here, at least that the equation shown. It's b the branching factor with an exponent of one plus the floor of C-star divided by Epsilon. And basically, it's related to the possibility you could have all these little small steps. And therefore it can make it much worse than breath-first search because it ends up taking all these little baby steps. If the step cost is equal though, it's almost the same as breadth-first search. The only difference is the point at which you check for the goal. And rather than checking at edge expansion, it checks when pulling from the open pull. And because of that, it's d plus 1 is the exponent. That's the same. It's got the same space requirements because it's got every node visited has to stay in memory. And so that finishes our look at Dijkstra's and so next step, we are going to start considering using additional information about our domain. So that will allow us to maybe guide our searching towards the goal in an intuitive way. Again, leveraging what we know about our problem domain.
