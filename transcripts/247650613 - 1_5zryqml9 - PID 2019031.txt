>> Hello. In this lecture, we're going to revisit decision trees. This time we're going to see an application of decision trees that allows them to learn behavior through observation. This could be as a pre-training phase, or possibly even interactively learn. So the decision-making will be driven by these observations. Let's start off by considering this game that probably many of you have played in grade school, 20 questions. The game of 20 questions is one kid will imagine something in their head without telling anyone, and it can often be a theme like an animal. So you imagine an animal on your head, you don't tell anyone. Then, the other kid or possibly multiple kids, will ask questions of the person who imagined the animal. And these questions have to be true or false, or yes or no. So the goal is to figure out what the animal is within 20 questions. And then the kid that's asking the questions wins. Otherwise, if it takes more than 20 questions, the person who imagined the animal wins. So the idea in the game is to ask questions that work down to a smaller and smaller subset of all animals as quickly as possible. This is also often like a programming assignment in introductory programming classes. You can find several examples of it online. So you might imagine well, how can we go about building a decision tree for the 20 questions scenario? And so we'll start off with a simple approach for how to do this. So first thing we need is that we need a list of our objects, in this case, list of animals, and then we also need to have a set of attributes that some of these attributes will be common across multiple animals, but the idea is that you have enough attributes that each animal has a distinct configuration of attributes. So we can put these attributes in a pool and we want to select from this pool or set of attributes. We want to select from them in such a way that we're picking the attribute that best discriminates between the current set. So whatever the current set we're working with is, we want to basically come as close as we can to evenly splitting the group in half. So we're motivated about making a balanced binary tree. And anytime that you split the set of attributes in half, then you will repeat this recursively and you keep working your way down through the tree, always selecting attributes to split, then of course that attribute no longer is relevant in sub trees as we work down. So you pick an attribute to split on, you make a left branch for yes or no, and then a right branch for the opposite. And then you keep working your way down until you get to the point where ideally you will have a single leaf node that is the animal in question. Now there's a few practical concerns that you run into like occasionally you'll have attributes that are maybes or unknowns for your animals or in those cases, your attribute doesn't discriminate so you would pass those maybes down both branches, and then hopefully later attribute will do a better job with those wildcard type scenarios. You might also get to the point where you've run out of attributes and if that happens, you can always fall back to asking just very straightforward questions. Let's say if you got down to say a set of different birds, you could say, is it a chicken? Yes or no. And then if you get it right, of course you're done but if not, then you would ask, is it an owl? Is it some other bird? You just keep working your way through but ideally if you ended up with a tree like that, you would add more attributes. It's also possible that you can end up where you know the animal, but you haven't exhausted all your attributes. So of course you're not going to continue to recursively generate the tree with unnecessary decisions. So you would drop out early. But this is really straightforward thing to implement, it's not particularly difficult. The way that this, at least as presented right now is pretty simple, and that's because we only have one example of each of the animals. So there's only one line in the table for chicken and one for owl and so on. So that makes things easy. And also we only have these yes or no questions that we're dealing with. So that's really simplifies the problem but as we see, if we get a little bit more complicated scenarios, this whole issue of figuring out what decision best discriminates your set of objects or instead of being objects, they could be like actions that an agent is trying to decide upon and as we generalize this problem we'll see how to work with it. So the real power of decision trees comes from their ability to learn. So the decision trees we've seen before, the concept is very simple and it can be pretty tedious to try to design and maintain a decision tree. But, the automation that's possible with learning can make them a lot more powerful. And so there are a number of different algorithms and variations of algorithms that can be used, but probably the most well-known is from Quinlan's work. So this is the Iterative Dichotomiser 3 algorithm, but I typically just see it ID3, and this particular algorithm is a way that it has a general solution for how to train our decision tree based on observations. >> Typically, we would use this to predict human decision-making. So we would train on human behavior. And we can also use it for, in addition to decision-making, in say, like a strategy game, we could also use it for classification problems, like what is something. But we'll have some object or situation that's described by a set of attributes, very much like what we saw with the 20 questions. Now, these attributes they can be discrete like we showed with the 20 questions, but they can also be continuous values. In the case of continuous values, we have to find a way to split the range of possible continuous values. And the idea is that we're trying to predict what the outcome is that the human made. So that could either be a decision for a gameplay behavior or it could be a classification like looking at images and deciding what object is seen or maybe what the enemy is currently doing. You might have like in a video game, that sort of thing. We have this current set of decisions with attributes that describe these decisions. And we're trying to decide how best to split these up similarly to the 20 questions. So we want to choose the best one, whatever does the best job of splitting them up. And now before I said that did the best job of discriminating between two sets, but more formally, with decision trees, with learning, the analysis done is based on information theory. So the best attribute to use for our decision to split is going to be whichever attribute will gain the most information once we make that split. So good attributes are going to make homogeneous sets. And that's not always going to be the case with messy real-world data, but that's the goal. And so the ideas just recursively go down every time a new decision is added based on picking the best one. We're going to go recursively down each edge and further split the groups that have already been divided and split. So here is a classic example for learning D-Trees. This is some data about potential customers that are going out to eat and they encounter different scenarios at the restaurant they visit. And we're trying to figure out, predict or classify the customer based on how likely they are to wait to be served. So these are restaurants that all have potentially some amount of wait. So it might be like 0-10 minute wait, or 30 minutes to an hour, 10 minutes to a half hour, that sort of thing. And so there's several different attributes that we have about each of these scenarios. Again, we're trying to classify based on whether the target or the candidate customers actually wait. And some of the attributes are, alt is there an alternate available bar, if the restaurant has a bar included. Fri is short for Friday, meaning is it a Friday or a Saturday? Pat is the amount of patrons that are already at the restaurant. Hun is whether the candidate customers are hungry. Rain is exactly that if it's raining or not. Res is short for reservation. And then there is the type for what type of food it is. And est is the short for estimate of how long the wait is. So here we have just some example data and you can see that of all of these different attributes, you can follow along left to right to see what they are for any particular example. And then you have your target wait, which again, that is whether the candidate customer chose to wait or not. So you'll see a mixture of true and false values. So this is the data we want to be able to pick attributes, and whichever attribute does the best job of splitting up the data, that will be the root decision of the decision tree. And then we will advance from there to eventually along both branches to the left and to the right, recursively deciding how further to continue splitting up the data. The idea is that if we have any future scenarios, we'll be able to determine the attributes of the new scenario and then be able to guess. And so you can imagine this would be maybe useful for if you owned a restaurant for deciding how to maximize your profits and/or keep the most customers to stay rather than to leave. So a good attribute is going to be one that does a good job of splitting in a way where all are positive or all are negative. And we could pick anything to split and not end up with a good result. So for instance, the type of food. With this particular dataset, if we chose the attribute for type, you can see well clearly, it does split up the data, but it doesn't split it up in any sort of usable way. So you end up with the French food. You have one positive and one negative. Same with Italian. The Thai food, we have more people, but it's still split with two positive examples and two negative, and burger as well. So there is no progress that was made by using type. But if we split by the number of patrons already present in the restaurant, you see that this particular dataset, so there's three categories for the patron. We have none. Now if there's nobody there, then the customer is not willing to wait. But if there are some patrons there, then they are very likely to wait because all the examples are positive of waiting. But then if the restaurant is full, you can see that well, it didn't work perfectly here. It's not like a binary thing. When we pick the best split, it's a continuum potentially. If you have a lot of attributes, some attributes might only be slightly better at splitting the data than another attribute. >> So let's say that we've gone through this process. We've just been high-level talking about how we go about selecting the attribute. But let's say that we have done this and we've built our decision tree. So we'd end up with something like this, where in this case, clearly it's not a binary tree. So that's one thing we notice right away because some of our attributes have enumerations of different categories. There's hunger, which is a binary, so we get the two branches there, but patrons, we have none, some, and full and for the type of food that's a four-way split. And then Friday, Saturday again is binary. So we have a variable number of branches according to what these attribute decisions are. But you can see that we could parse through the tree with some new example. And then that would allow us to end up with a decision, so whether or not it's the right decision, will depend on what the application is. If we just need some reasonable behavior for say, a video game agent, then there's not necessarily a right or a wrong answer. But if you're trying to classify something, then that may be depending on what the repercussions of that decision are, then maybe that is very important. So here's a new example. This is a video game scenario, so this will be somewhat similar to what we just saw with the restaurant, except just this game-focused scenario. So this is should the agent attack? And the idea here is that we have data from a human player. So we're trying to make an agent that does a good job of playing like an RPG-type game that's got random encounters with enemies. So different enemies are popping up all the time. And the player or the agent in this case doesn't have to fight every single enemy that they encounter. They can skip some. So we have these attributes like well, can the battle actually be bypassed? Whether or not there is loot available. If this particular battle is associated with unlocking an achievement if you get the win. If the agent is on a quest, how much experience is available to get the environment. So this is related to how favorable the terrain is. Whether or not the enemy encounter is a mini-boss. And a mini-boss that needs to be beat in order to make further progress. Then we can consider the element of the enemy or the magic that the enemy uses, like earth, air, fire, water. Estimated time for how long the combat will take. And so this can be categorized as quick, short, long, very long, and then team size. So that would be how many monsters are in the team. And that's also a category. So none, small, and large. So from those attributes, if we have a lot of example data that we're using to train from a human player, we might build a decision tree. So again, this relies on us being able to select attributes that do the best job of splitting up the data into these homogeneous groups so that ideally the end result classification is all one or the other. And so this case, the classification is just two values of whether or not the agent should follow through with the encounter and try to defeat the monsters. Here's some example data based on the attributes that I just described. And so you can see the final column has the yes or no for deciding whether to attack. And so we've got all of these different examples. So we'll consider some possibilities here. So let's say that we look at the attribute for the elemental magic that's involved. And so in this case we've got the indices of all the positive and negative records. This is a very small amount of data just for the example. But you can see that 1, 3, 4, 6, 8 and 12 are all the positive examples. And then we have similar number of negative examples shown. And so let's just say we pick again, the elemental magic involved as our split. And you can see this isn't a very good attribute to select because while certainly we do split the data up into these four different branches, each one of them are perfectly balanced in terms of a positive and negative examples. But with team size and so this being three different categories, so single enemy, a few or many, you can see that that selection, we have much better result in terms of, for instance, the team size of single, then we have no positive examples and only negative examples. You might imagine that a single enemy has not much in the way of any reward or otherwise there's no benefit. It's just a waste of time basically. But if there's a few enemies, then that probably balances out difficulty and danger, but still some potential for a reward. Just my guess for this made-up data. So we've got the four positive examples and no negative. Now if there's many enemies, that is a situation where the downsides might begin to outweigh any potential benefit. So there's actually twice as many negative examples as positive examples. Now this particular bit of the decision tree shown further splits by whether or not the agent is on a quest. And so if they're on request or not, that can further split the data. So of course, the example records or the rows in the data that are considered for the on quests split. Well, this is a subtree we've already whittled out the team size single and team size few. So the only data records we're considering are those that were passed down to the subtree for the team size many. So you'll notice that the on quest true, took all of the positive records, which were just the index 4 and 12, so ended up where there's no positive records for on quest false side, but it did end up with a couple negative ones there. So keep that in mind. You're always reducing your set of data at each subtree as you go down through the decision tree. And so here is an example for starting with team size, which was the best option to select, then on quest and element. And then finally, for one of the branches, we have, we need to select an additional attribute for a decision and that would be an achievement. So this doesn't look like that first example decision tree that I showed you for this scenario. Assuming that the first example was the ideal tree and this one is looking different. Well, most likely scenario that would lead to this is that we just didn't have enough example data to train on. So therefore, there wasn't enough data to properly identify what the best splitting attribute was. So it's just the algorithm can only do as well as the data that it is provided with. And this is a situation where we're supervising the learning process. So we need to provide it with the training data and then we need to validate what the result of that training is through a test set. >> Back to this attribute selection issue where we've been waving our hands and just saying it's the best one. We will look a little more closely at how information theory can be applied for formalizing this selection here. What we're trying to figure out is, well, how much information does something contained like our set of attributes or set of examples and the associated attributes? Then we're going to ask a question and the answer to the question is the information. And the amount of information depends on how much we already knew. The amount of information that's gained, it's going to always be relative to what we already know. So an example might be like flipping a coin. So you could look at observations of flipping a coin to learn something about it. We're going to use entropy as part of the information theory, and the way in which we're going to assess how good an attribute selection works. We're going to be measuring information in a set of these different examples or observations. We're going to find out the amount of agreement between the examples. If all of the examples are in the same action, then it would be zero entropy there. But if they're all evenly distributed in different then we have high entropy. So that would be a value of one. So that's the maximum entropy actually. If there are n possible answers, p_1 through p_n and p_i has a probability defined by this probability function of p_i, if that is the selected answer then the amount of entropy is this function h, where the equation is the sum over all the different possibilities p_i times log base 2 of p_i. The whole sum is negated. Let's look at if we just pick just one single I value, so we only have one possible value. That gives us this function here. So from 0-1, we have this skewed curve that looks really weird, but I think it's worthwhile to look at. So this doesn't really make any sense because this scenario, it is basically saying that there's this only the single possibility. If we're considering something like a coin flip, let's say, then we have the probability that you flip heads or flip tail. So this equation it's degenerate at this point, but let's add in, I'll go back again, so you see the sum. Of all the possible answers, in the case of a coin, we have p_1 for heads and p_2 for tails. That means that we're going to have two of these P time log base 2p values. We're going to have the sum of that. I'll now go to that example. This is just the summation, this expanded for two. The probability values. If you've got through some number of trials, if you have heads or some percentage of trials you have heads, then you know the other percentage you have tails. I have basically set that up in this equation when I graphed the function here. This is just graphing all possible values of p_1 from 0-1, so that being the probability. Let's say we're flipping a coin and it has a variable likelihood of being heads and tail, it's not a 50/50 split necessarily. It could be 0% of the time it's heads and always tails. Or as we go sweep across the x-axis, we're transitioning from always tails to a 50/50 split in the middle, and then at the other end it is always heads. And so the x-value, this passed into the x times log base 2x value. You'll see that the first term is just x, but the second term in this summation from the entropy equation, I put 1 minus x. So basically just saying whatever percentage is lost by heads, it's gained by tails, it's always going to be a total probability of one. The probability of heads plus the probability of tails always sums to one. So that's why there's the x and the 1 minus x. But back to the graph. You can see that if heads and tails are equally likely in this situation. So that is the values are very tiny here, but right in the middle of the x-axis, that's 0.5. If you go up to where the curve is, you see that it peaks right at one. That means we have maximum entropy, like in a coin toss scenario, we have maximum entropy. If it's a fair coin that is equally likely to be heads or tails. Now this equation for entropy is flexible. We can apply it to other scenarios like the attributes that we saw in the examples used in our decision tree training. That's what we're going to use it as part of this determining how best to split our data attribute we'll use for our decision. For our training set, at least in the example that we currently have, is like heads and tails in that there's two possibilities, there is that the agent should attack or just retreat and pass on the battle. That's what we're looking for. For our entropy, for any given attribute, we can determine how much entropy is present based on how many positive examples we have and how many negative examples we have. You can see here, it's just like when we graph the coin toss scenario. So we've only got the summation of the two terms, where p is the number of positive examples and negative examples, so we just have these ratios. We know the total number of examples is p plus n. That's the denominator, and then you either have as the numerator, either p or n, depending on which we're talking about, either positive or negative examples. So we can plug p over p plus n for positive examples, plug that in for the first of the entropy term, that summation, and then we can plug in n over p plus n for the negative example for entropy. So when we are looking at an attribute, when it does the split, we can see very quickly, for this example, we can just figure it out what are the positive and negative examples? Like the attack behavior, we have an equal number of positive and negative. So overall for this scenario, we have full entropy, all of the 12 records we have, we have six of each. So we're starting off the whole scenario of when we're building our tree, we have an entropy of one. We're going to use the entropy as part of this remainder equation. So we have some starting entropy, we just saw that what starting entropy was. What we're trying to do is figure out how much entropy remains after applying an attribute. >> The input to the remainder function is whatever the attribute is and then based on that, we're going to go through all of the different answers that are possible for the attribute, so that would be the different categories. Some of them were binary but some had three or four levels. We're going to go through all of those. For the instances of the particular attribute, we're going to have some positive and some negative examples, or if we're lucky we're just going to have all positive or all negative which will be better. For that we're going to take the sum across all of those different possible answers for the attribute. We're going to look at the ratio of the positive plus negatives for each of those answers. So we're taking the summation of this divided by the total answers, and then multiplying that by the entropy. Again, this is for each of the instances for that answer. And so in this case, we've got just either the true or the false, or fighting or not fighting, so we only need two values here. So we can see how this can work out with the poor attribute or the elemental magic. And so in this, as you recall, was the bad example where it didn't do anything at all to isolate our records into positive and the negative examples. It split the data up four ways but they were all still equally balanced positive and negative. And so here you can see that we've got 2/12. We started again with a total of 12 records and then so for water, we have two sets. This is like a weighting factor, or weighting the data, so 2/12, and then times the entropy of the positive and negative examples. So here, and again, these values or indices so this is Index 1 and Index 5, so that's why there's 1/2 and 1/2. So the entropy there, and then we have for fire 2/12 again because there's only two examples, but the entropy is the same value again. If you continue on for air and earth, we end up with a remainder of one bit. And now, we started with one, so you can see here the remainder after doing the split is still exactly the same. But with team size, you can see how we've got much better. Just looking at it we can tell it's much better data because we're not balanced with the number of positive and negative examples. So in this case, it ends up with a 0.459 bit. So we can see that there's a much better reduction with this remainder. So the information gained ends up being the entropy over all at whatever step we are in the process. So what was the entropy that we started with minus the remainder if we select a particular attribute. We're going to do this for all of the available attributes, wherever we are in the tree, so we might just assume we're at the very beginning and so we have all attributes available. So we'd go through all of them and we will compute this game. And then for each we're going to figure out, well how much is it reduced. And, again, this is all relative to what the initial entropy was. So if we already had poor entropy is going to account for that in the calculation or later. Is part of one of the subtree of the decision tree, then we're still going to have to make these decisions but it's all going to be relative to what we're working with. This point we can easily select which is the best to work with. Once you've made the selection, then you do the exact same thing recursively. So you will then be working with a new starting point for your initial entropy. So whatever the initial entropy at the relevel, you won't have further in the tree. So for instance, after we've already done the split for team size and we are on the branch for team size of many, you'll have two positive examples and four negative. So that's reduced entropy and that's reflected by the left term. Let's see if I can get my mouse cursor to show up. So this example here, so you can see there's two for the positive, so for Index 4 and 12 fill in to this Value 2. And for the negative examples we have 2, 5, 9, and 10 indexes, and so that is the four. But that is out of the overall 12 that we initially started with, so for the many branch where it's only got six total records, but we still are using the denominator of 12. So it's a reduced entropy because of the work that was accomplished by selecting team size. And then we're subtracting out the remainder that is based on the entropy for selecting on quest. And there's only two levels for on quest, so the remainder is only going to have these two terms rather than, I think, we had three before with team size. And so we plug out and of course we have these new entropy calculations in here as well. Those are based on what the distribution of positive and negative examples are, for the left and the right branch, so left being false and right being true and that's whether we're on quest or not. So that'll give us a new gain from that selection and so if you have multiple attributes to select, we would again make the comparison. It's going to be fewer attributes and it's going to be a lower starting entropy that we're going to be working with. >> Now one practical issue you can run into when you have data, especially real-world data, and maybe you collected from human player is that you might end up with exactly the same attributes describing an outcome or maybe a decision of what action to take. You might have examples, one or more or two more examples that go one way, say fight, or not fight. So you have say, the party size, the elemental magic, and all those attributes, they are perfectly matched. But then you have examples in your table of data where the player chose to fight and the player chose not to fight. And so this is a bit of a tricky situation to deal with in terms of how to interpret and use the data. So you could either just go with the majority classification. So you could actually go through the data and determine what do you have the most of, and then maybe just only train on that, or you could report the probability. So in addition to whether it was true or false, you might have what percentage that might be useful in real-time like a confidence score. So if something is very high probability in the face of this noisiness and you could be more likely to act upon it in terms of anything that's interpreting the results pass back from the decision tree. You might have some other components to your agent that's interpreting these recommendations from the decision tree, like maybe high-level strategy. So you still have other agent control that's filtering or interpreting what the decision tree is passing. So it might be more likely to act if the data is more consistent. And so in terms of the algorithm, this is just a bit of pseudocode from Millington. So this is just a high-level describing the process involves just you continue to process the example data until it is empty. And if it is, then you just return a default value that has been already passed in. Otherwise, if all examples have the same classification, and of course, you're just going to return that as the classification. Otherwise, if you might have run out of attributes, since if that's empty, then you're going to use this majority value from the examples. So that's what we're just talking about. And then otherwise, that means that we had the opportunity to pick an attribute and split and add some more decisions to the tree. So this is where all the actual work is done. So this choose method is where we're determining the gain and information based on the entropy calculation and then whatever attribute reduces the entropy the most, like what we just walked through. And so we make a new decision tree. That's really going to be a subtree and then we will iterate through and then recurse down once we make these splits. Now you can also use the decision tree in scenarios where there is continuous data. So all the data we saw was discreet. Like enumerated categories or just true or false values. But if we have continuous data, what we can do is we're still going to have a fixed number of examples. So we can actually take all that data, sort according to whatever the attribute question is. So it might be a floating-point value, we can just sort all of them in lowest to highest. And then we can just start trying to all possible splits of the value. And then whatever gains the most information is the best split. So we might pick say, the value right in the middle, whatever that index is. And so everything below the index will be 1/2, and then that index and everything above will be the other 1/2, and then you can run through the whole calculation of information gain, just like we've been doing. So it's a little bit tedious to have to go through and do all this testing, but it's still possible when you do you have continuous values. And so if we go back to our 20 questions example, we can see probably, well, it would be straightforward to use the ID3 algorithm that we've just looked at. And we could even modify the scenario a little bit so that it can handle some messy data. And likely way in which you would have messy data is while you could get help from an online community to build this data for you, you could just say have a website where you ask people to list attributes and fill out the basically entries in the table that describe these different animals. In fact, I think I've seen a website that basically did this in the early 2000s. So you could visit and play. You could play the 20 questions game online. And I believe that the way it worked is through a few questions that would help further training, it would gain knowledge. And so we'd get these new records basically but it'd be noisy because it's just random strangers off of the Internet. And so we'd have to have ways of dealing with the noise that we discussed before but it could be updated and become better and better every time that the training was rerun. And so if you play against the website, it was the website would try to guess the animal or whatever the category was. The object that you were imagining in your head and you would do a really good job of guessing. And there's also other implementations that aren't necessarily decision trees as well. But clearly, we could use the ID3 algorithm to build our own 20 questions game. So just briefly, we can consider all the different possible configurations of a tree. So if you have say N attributes, then we're going to end up with just an incredible number of possible trees because of all of the different ways that we can order our decisions. So even with just six attributes that this just said an impossibly large number. So there's a lot of power in terms of what a decision tree can represent because there's so many different configurations, that means it's very flexible in terms of capturing these decision-making hierarchies. >> So we can just briefly cover this a few slides to go. How do we assess our decision tree? And so that involves having training set of data and then a test set. So in order to have a useful training data, we need a large enough amount of data that any problems with examples, especially related to noise that appears, we want to make sure we have good coverage of all the scenarios that are likely to occur with whatever the scenario is like playing a game, and we also want to have enough that it overpowers noise, or hopefully that'll be the case that we'll have enough data that it smooths things out. Now, so we're going to have a lot of data, but we can't train on all of that data because if we train on all of it, then we'll have no way to gauge how well it works and so rather than using it all up and then having to go and collect a bunch of new data, we can just split up our data into a training set and a test set so that will ensure that when we're testing, that we are testing with the data that was not used in training so there won't be that bias there of already having seen the examples before. So this training set allows us to produce this hypothesis, which is basically the expectation of how the test set should classify. So we can score our decision tree on how well it does in terms of picking the right decision for instance. And so we can actually go through dividing the data in different ways and retraining from scratch for instance. And this can help us to figure out, well how much data is necessary for training and also what's the ideal amount so we can graph the data for instance. So if we vary the training set size relative to the test set, and are also shuffling things around selecting different amounts and again, always recreating our decision tree. We can look to see how well our hypothesis is working compared to the test set so we're going to have a scoring metric. So if we're training on a very small number, well, we'd expect it to perform poorly. But as the training set increases, maybe there's a lot gained, but then after a certain point, there's no longer anything gained and so this is useful to figure out what's the optimal training set size for whatever the problem domain is that we're looking at. So you can basically get an idea of how much data do you need and it's not necessary to go beyond that for any future training. One problem that can affect our decision trees is that the problem of overfitting. And so this is where our decision tree learns a hypothesis that's consistent, but it's using irrelevant attributes so the attributes don't actually matter in terms of say, the general problem or future examples. So this rope results in these spurious distinctions, and it can end up influencing decisions that your agents making so as you go through your decision tree, is making decisions that are not appropriate at some point in the future when the decision tree is used and that's because, like in the case of decision tree, we would have detected the information game like an attribute that's not particularly important, was identified as being a good attribute early in the decision tree so it's a closer to the root level when it should have been. Just didn't matter at all or didn't matter until very low in one of the branches. So this is something that can really affect all learning algorithms. You just have randomly distributed data, but it just because of random luck, you end up with patterns that appear as if the selecting of the attribute has information game and so all learning algorithms can be affected by this and so something you have to watch out for and maybe address with adjustments to your training data or the size of your training data. And one interesting thing that you can do with D-Tree learning is we can not just learn, before the fact, build a decision tree as part of the development process and then that static decision tree gets shipped with your game. We could have the decision tree actually have live learning in the game and so. >> The way that this would work is that we would have each of the decisions in the tree, so there's the nodes in the tree that are not leaves, but also the leaves. We will keep track of all of these examples. So what we had as a table form before, so I could look like a spreadsheet, we're going to keep track of those examples records at each of the decision nodes and then also the leaves. And what this is going to allow us to do is as new scenarios are encountered, we can still parse the tree that we have. So new scenarios, they're going to have attributes and they're going to be the same attributes that were used to build the tree up to the point that it currently exists. So we can parse through and then decide whether we reinforces the data we currently have, or whether some modification needs to be made to the tree. So this basically it's combining the D-Tree that we've seen before with the D-Tree learning algorithm. Again, that is mainly facilitated by putting the actual data from each of these scenarios is stored as part of the nodes of the tree. So any node in the tree can be asked to update itself given some new example. And then you can have these three different situations that play out. So this is from the Millington book. If a node is a terminal node and that means that in the decision tree that the terminal nodes are the nodes with the actions. So if that's the case, if the added example also shares the same action, then the example is added to the list of examples for that node. Again, this is the second one. If the node is a terminal node, but the examples or action does not match, then we make the node into a decision and use the ID3 algorithm to determine the best split to make. That means that we've added this new example, but it doesn't agree with what was uniform data previously. So now hopefully we have additional attributes to select from, and we'll just pick whatever has the best information gain and then we'll do possibly more than one split depending on what the record was that was added. Now, if the node is not a terminal node, then it is already a decision. So this is like an inner node of the tree. We determine the best attribute to make the decision on, adding the new example to the current list. The best attribute is determined using the information gain metric as we did in ID3. So these results if the attribute returned is the same as the current attribute for the decision, and hopefully it will be and most of the time it will be, then we determine which of the daughter nodes the new example gets mapped to. And we update the daughter node with the new example. But if the attribute returned is different, that means the new example makes a different decision optimal. And so this is where ID4 is the most painful. So because of that, if we change the decision at this point, then all the tree further down the current branch will be invalid. So you have to delete that whole tree from the current decision down and then you have that whole pool or the whole set of examples again, and you have to do the entire ID3, using the current examples that you have. If that happens, things can get rather messy. So this live learning decision tree, the ID4 style, that was used in the game black and white. I don't know how many students in the class are familiar with this game anymore. It's pretty old at this point. But interesting it was a game where I guess you'd call it a god game. So you are like overseeing a village, and so your job is to protect your village and help them to thrive and advance. And you have a pet monster type creature, this giant. And you could pick your giant, whichever you prefer of like one of three, I think. But your giant was learned and it's like a toddler. He or she didn't know how to behave and just would randomly do things. And so you could punish or praise the creature, like give rewards. If the creature ate your own villagers, then you would give a punishment. But if it say stomped out a brush fire that would risk burning up your village, then you would praise them. So the creature would learn through this feedback giving what to do. So all of the tree building in the adjustments would be based on these feedback measurements that we're given. And so you could get these different values that were passed in, so then the tree could rebuild itself. And it worked pretty well. You could pretty quickly train your creature. You had to really focus on being consistent, try to remember the way that you've been teaching your creature and you would want to make sure to try to balance out reward with punishment like you don't just want to punish all the time. But it would learn quickly the certain things that you did not allow it to do. Didn't always work so well when there are new novel situations, so you might have to intervene a lot, say some new disaster was occurring, for instance, you might have to intervene a bit. So to wrap things up, we've seen how ID3 works and so we have this nice general approach that we can use for awesome arbitrary set of attributes as long as we've got enough example data for say, selecting actions. And again, if we have all these attributes describing those actions, and we have good amount and quality of data that's consistent, then we can build our decision tree from it like a preprocessing build step. And we can even have learning that's live by storing our records in our tree and have a tree that's dynamically learning. So that is an interesting possibility there. Now there is a challenge in that like the ID3, it's just too inefficient, especially for online learning and the ID4 approach. It works well, ends up not being a lot of changes to the tree. We saw the example like worst-case if you have a decision node that gets flipped such that it no longer the best attribute is selected. So if you had that scenario, then you can quickly run into performance problems. So it's not a completely fail-safe solution and is probably better suited for certain problems than others. But in the Millington book, he does say that from his use of it in some of the games he's worked on, it has worked pretty well, such that it will generally rarely have to rebuild parts of the tree. It still has that possibility though of getting unstable and just churning and churning and rewriting itself and hogging the processor. So this the use of decision trees for learning is something that is certainly a possibility that can be useful and it definitely makes decision trees overall much more appealing as possible use in video games.
