>> Next step, we're going to look at the AStar algorithm, part of our look at path planning algorithms. So the AStar algorithm combines concepts of Dijkstra's and Greedy algorithms together. We're going to be, as we expand our search, we're going to be expanding nodes that work on a combined heuristic. We're going to have both the costs so far like Dijkstra's that we're going to be leveraging, but also a heuristic estimate to goal, and that would be like Greedy best-first search. So we're simply taking the sum of the two for a given node in, we can take the cost so far. And recall that in Dijkstra is that accumulates through the progression of expansion, you start with a distance of zero. And then we take each of the edge weights, which will tend to be the line of sight distance between each node. So that is added to the heuristic estimate and then we act on that. So if certain conditions are met in terms of how the AStar algorithm is defined, and in particular the heuristics, as well as the conditions of our graph, then we can have a guarantee of delivering the best possible path and potentially perform well as well in terms of algorithm complexity. So an example heuristic would be, Euclidean distance or line of sight distance from a given node to the goal. So here is a demonstration of AStar in this example, since it's going nearly corner to corner. Perhaps doesn't do the best job of demonstrating how AStar can avoid searching the entire map. But we can still see that it does avoid expanding into some areas and will favor moving towards the goal. It does tend to fan out a bit. That's partially because Manhattan distance is being used on a four-way grid and so there are number of nodes that will have the exact same distance. So we can also look at some other examples, such as this one with a direct line of sight unimpeded, looks very much like Greedy best-first search. Very few nodes expanded in this case. And so that's certainly something that is good to see especially if you're considering selecting an algorithm to use in a real-time video game where performance is going to be important. In cases where we're blocked and we've got the four-way connectivity and Manhattan distance. So it does tend to spread out. It's a bit like dragging a selection box in a 2D user interface. But you'll notice that from the starting point, it does not expand other than one level to the left and right. That's the leading edge of the open-set frontier. If you look closely at the colors of the nodes, you'll see that that's open-set. And yes, so it doesn't waste any time going to the left or up in the search, and because there is an obstacle in the way it's necessary to spread out. So this looks a fewer nodes than Dijkstra's, for instance, or breadth-first search. Now, we could consider even with a four-way map, we could use other heuristic functions. And so it might be interesting to see. Well, what if you use Euclidean distance? So actually I did that and here is a demonstration. So in this case, it's got definitely a different pattern of expansion. You'll notice that it's the algorithms spending a lot more time expanding nodes to the left and up, unlike the Manhattan distance. In fact, it's expanded more nodes. So the heuristic use Euclidean distance is less accurate estimate tends to underestimate the distance from any given node, especially like on the diagonal, because the only way that the ball can move is Manhattan-style distance. So either up or down or left or right, even if you like the end of the path there, that diagonal is the same as going straight down to the right. So the estimate tends to be off and that ends up resulting a poorer heuristical result in degrading towards something that is more like Dijkstra's and spreading equally in all areas. So it's important to select the heuristic well. Now Euclidean distance works a lot better with a grid lattice that has 8-way connectivity as shown here. So now it looks more like an oval that is directed towards the target. And when the front of expansion encounters the obstacles and gets stuck, it starts to broaden more and more. And then finally it gets past the edge and is able to make relatively direct shot at the location. >> The Euclidean distance aligns really well with 8-way and that allows even less nodes to be searched. Next up I want to show you the code for A-Star. There are some corrections here to the Millington book. So if you happen to have a copy of the Millington book, you'll want to refer to this also for programming assignments that are related to building the A-Star Search. Make sure to reference this as opposed to other sources because this implementation deals with the possibility of reclaiming nodes from the closed set, which is a possibility that some implementations of A-Star do not address. So the red boxes are corrections where I think, if I'm recalling correctly, there were some names that were not correct based on edits from the previous version. So all the edits weren't consistent I think was the main issue and there may have been one line missing. And then the purple box isn't technically incorrect for the pseudocode shown but a very likely problem that you would run into is that if you are editing a node in the open set, then you need to move it and move its position relative to other nodes. And in the case of using a priority queue, that means changing its priority. And so the conditional there is only addressing nodes that don't need that done. So it's assuming that if you had a priority queue, it's inspecting the node record itself. But your typical priority queue, the priority is separate from the data internal to the structure. So most likely, what you would have is an else condition and then update the priority in that case. Here is an example from the Millington book of how nodes might look in the progression of expansion in a human-readable form for the metadata, the node records that would be necessary. So you start off with node A, it's a start node. You have a heuristic estimate like a Euclidean distance to the goal, like 4.2. Also, cost-so-far is zero. It has no prior node which is shown in the connection. And then there's an estimated total cost and that's the g plus h of n calculation, which would be the cost-so-far plus the heuristic value. And we can tell what set it belongs to because there is annotated with close. So you can assume that that node is a member of the closed set. So a very similar metadata then similar to what we've seen before with the other searches. So we're midway through the A-Star search. It says several nodes have been evaluated, and then there's a couple of nodes that are unvisited. But you can see how the estimated total cost for each is changing, as well as the costs-so-far is we have a running total and we can get the data needed to generate this costs-so-far running total by the edges that have the weights assigned. So for instance, the edge AB has a weight of 1.3. So in generating the node data for B, we take the cost-so-far of A plus the 1.3. So node B's cost-so-far is going to be 1.3. Its heuristic is going to be dependent on the discretized location of B and G, which is the goal node. We'll need some means of obtaining the X-Y position in the game world's vector space, which is probably stored in your graph. And then you can just apply the Euclidean distance function. And that will give you your heuristic. That can be stored in the estimated total cost as the sum of costs-so-far plus heuristic. So that's where the 4.5 comes from. The connection is stored, it says AB so that you can tell the left side of the connection is where it came from. So there's other ways you could store that. You could just say from node and it would list A, for instance. It's also in the closed set just because you can assume as part of the algorithm's progression that this node has been evaluated and moved to the closed set. And so you can check out some of the other nodes. I encourage you to spend a little more time just looking at this slide and making sure you're comfortable with it, compare it to the algorithm pseudocode. And then also let's consider what happens in the case of certain types of updates that might occur. And that is the possibility that a closed node may be revisited and it's necessary to correctly do A-Star as you're expanding nodes. If I go back to the previous slide, we will see that node C is open. And so an open node of course is available for consideration as part of the algorithm. So it's the next node to be evaluated because its estimated total cost is the lowest. Let's see now actually, at this point it's not the lowest. After E is evaluated, it will then be the lowest cost. So if E gets updated, it will become closed and then C will then be the lowest estimated total cost which would be selected and then evaluated. So that's the point we're at in this slide. The current node we'll assume C circled in the bulb there. E has already been evaluated and closed. But this is a scenario where as we're expanding edges of node C, we're going to check out E, even though it's closed and see that if we went from C-E, it would be a better result. And that's because if you subtract away the 1.7 that came from B, and that's originally what led to E being visited in the first place. And then we replace it with the C-E edge instead, we'll see that that gives a better cost-so-far. And if that's the case then it needs to be updated. But the problem is that if we updated it in its closed state, well, that could have an effect that trickles to multiple nodes in the graph. So rather than determine that it needs to be updated and then try to bubble the change right there as specific code, it just happens that you can instead move it back to the open set and then at that point, it has the option to be selected again if it affects the solution. And that will allow the normal A-star algorithm to do the bubbling of the change for you. And so you don't have to have this extra secondary helper algorithm to do it. So it's an elegant solution it's just to flip it back to open and then it can be reassessed if it needs to and any bubbling that needs to occur will happen. >> Other than that the algorithm is really what you would expect, just switching to a different criteria for expanding. In terms of the algorithm, it is outside of that special case, is pretty straightforward, but it does depend on some critical operations that are occurring. So we've talked before about what's the best way to store the node record metadata, and also the data structures we might need like a stack or a queue. If you are manipulating things that are in the middle of your list, then you suddenly need to consider other data structures. That's the case now that we're optimizing this g plus h for the estimated total cost. So because of that, we have these critical operations of adding to our list or whatever the data structure is that we're going to select. So we're going to be thinking about what's the algorithmic performance of adding to our list, removing from the list, finding the smallest element which is important for the selecting of all of the OpenNotes? Which one has the best estimate? So that's where the smallest element need comes from. Then also perhaps being able to find a particular node, whether it's to retrieve something, some data like a metadata mapping like in a dictionary, or just to find out that there's a set membership containment. We need to find a balance between all of these operations if we have a data structure that is performing these actions. Simplest thing would be a naive solution where we have a linked list. So this would allow us to do things like delete items from the middle if we wanted to or add items and so on. But, finding an element in a list would mean that you might have to search the entire thing. And in the context of our A-star, this could be happening every single time, every iteration of our loop. So this would certainly have a compounding effect and lower performance of A-star. So really we would like to be able to find entries more quickly. We could have sorted list but finding would be efficient. But then the cost to add is going to increase a lot, because every time you add, you're going to have to deal with the sorting. It turns out that if you look at the distribution of calls that a star makes, it's going to add a lot with much less often finding the smallest element calls. So because of that, we really want to to make it more efficient for the the adding and also the removing. So this is where the priority queue comes from or a heap implementation. So it's a tree structure but it's based on an array. And I'm not going to go into the implementation, other than just to say that this data structure is generally ideal for use in A-star. And it turns out that it's really easy to get the smallest element because it's the head of the tree. Then when you remove the smallest element or add a new element is big or log in. So it's a good compromise given the needs of A-star. There are other possibilities that you could consider. For instance, a bucketed priority queue. In some cases, especially in a game where you have a fixed size map, there might be a way that you could tune the size of the buckets. You can think of the buckets as just being unsorted list, so you could minimize the need to manipulate the ordering of your priority queue just by having a bucket of a handful of items. So you'd probably find a sweet spot, but there's a lot of work in tuning it to get it just right. So it can't have performance benefits, but it's often not worth the trouble. So one thing to consider is what happens if a goal node cannot be reached like it's blocked off for some reason? So when you run your A-star, what's going to happen is you're going to fill your graph with your search unless it's depth limited. Then at that point, you have to decide what to do or you're just going to return failure, or perhaps you could look for whatever the closest node is. And so you could do that by looking through the closed set that when you've exhausted the open set, looked at the closed set, and you look for the node with the lowest juristic score you've already calculated and cached all that information. So in the case of A-star, it's a low-hanging fruit to go ahead and take advantage of that. And it's also leads to reasonable behavior for an agent. That if the agent can't go where it's supposed to go, like say an enemy chasing the player, you might want the enemy to at least go as close to the players they can get. And maybe the player hops down from a perch or opens a door and comes out, and the enemy is there ready to cause some mischief. So we're going to come back to the topic of the heuristic function for A-star. So we have seen that there's certainly potential for there to be more than one useful heuristic. There seemed to be some implications there, like when we saw the use of Euclidean distance with a four-way connected grid Lattice. And so that was an example of heuristic that still works but it wasn't as good. So there's other things to consider where this heuristic. So regarding A-star, the computational performance of your heuristic is very important. You may have actually noticed this, I didn't mention it in the video, but of course the Manhattan distance is much less computationally impactful than Euclidean distance. So the Manhattan distance we're just adding the x and the y absolute differences together, and then with the Euclidean distance, we're taking the square root of square sum. So that square root on your processor takes a lot more cycles to calculate so that's going to have an impact. And we can actually play around with our heuristic at an extreme. If we set our heuristic to zero, we actually get Dykstra's algorithm. So that's interesting. In fact, if we set our costs of our value to zero so that each edge for instance it's treated as if they all are no weight, then what you're going to get is greedy best-first search. And that would be with a heuristic though that is reasonable. >> If you had a perfect heuristic, then AStar would go straight to the correct node, and it would do so in O of p, where p is the best path to get there. But if you had such a heuristic then you wouldn't even need to have AStar in the first place. So if there was somehow such a heuristic, you would have just a streamlined analysis of the heuristic that would generate the path that would have to be some very specialized case. So otherwise you're in a scenario where you don't know of any perfect heuristic, so maybe be a bit of an art in selecting a heuristic, and it's going to be based on observation for your particular scenario. So like you might actually consider your own game that you're developing perhaps, and the nature of the maps, and that's going to drive what's the best heuristic to implement. Now if you overestimate on your heuristic, like return too long of a path. So we previously saw where we had too short of a path, but not with too long of a path. And if you do that you may not return the best path. And so we look a little bit at some of the details of AStar and some of the analysis that's been done of AStar previously, there's this notion of admissible heuristics. And so that as related to AStar is a heuristic that never overestimates the cost to reach the goal. So as soon as you have a heuristic that's overestimating, then it's going to become inadmissible, and that's just terminology. The words sound a bit like good and bad, and so it's important to realize that that's not really the case. In fact we may consider having inadmissible heuristics. So that again doesn't mean that it's wrong, and in fact have good empirical results, especially in certain scenarios. But all that means is you just won't have the best answer, or always have the best answer. It just means, well that you could potentially have a very useful answer, and maybe do so much more quickly if you consider computational cost of calculating the heuristic. So Euclidean distance is the standard admissible heuristic for pathfinding, because the pathfinding problem is usually built on Euclidean vector spaces and therefore it would be impossible to have this problem of the Euclidean distance overestimating unless you had portals, for instance, so that you could just teleport to some location, and then that would introduce a problem. Excuse me. Manhattan distance can be admissible if you have four-way grid movement. And in fact it would be a better heuristic than using Euclidean, which would tend to be too short. And we already saw a example of that. Now if you are overestimating, you can actually make AStar faster, it will tend to home in on the goal more quickly. This is probably something that you would arrive on empirically through testing and just understanding what the scenarios are that you're dealing with like in your game. Now some interesting stuff from the game AI textbook. It talks about other source of heuristics than ones directly based on the distance between two nodes like Euclidean distance or Manhattan, of course that being admissible. But we may choose to use something else like a cluster heuristic. So this is interesting in that it breaks the graph up into rooms. And these might be structures that you've identified through the process of creating your discretized space. And in doing so you can assign nodes to belonging to certain clusters like rooms. And then you just define your distance heuristic, as well membership in which cluster, and then what are the distances between the clusters. And this can all be precomputed. So you're avoiding even doing the distance calculation in that case. And that is maybe feasible because you have just a handful of clusters. So it's not a huge hit on memory, but you have the benefit of avoiding the square root. And so that potentially could be admissible, but it's not a general guarantee. So for instance you could have nodes that are on the edges of their respective clusters but you've measured the distance, your precomputed cluster distances are based on the middle of those regions. So if the two nodes are on the two edges closest to each other, then that distance would be smaller, and therefore the cluster heuristic would be overestimating. So that would be clearly an example of the cluster heuristic not being admissible, but again don't assume that that means it's bad. So we've got an example that's showing this figure from the book. We have Euclidean distance used to show, well if you process a search from the two ends of the path shown, which is from the top-left corner to the bottom right corner, how many nodes would be explored? So we see all of the closed node-set, and the open node-set, and unvisited nodes. So in the case of the indoor level, the nature of the walls forces the AStar algorithm to spread out. It becomes more like Dijkstra's algorithm with the spread. And then the outdoor level we see here, it has got this very narrow bit of data. So clearly is the greedy part of the heuristic is being very effective there. And so if you use a cluster heuristic you can have much better results. So here is how the cluster heuristic might work. Now in this case we've got waypoints that are, if you see like this, cluster A has got five-way points. And cluster B is similar. But any node in cluster B, if you're asking what's the distance between B and A, you would just use this lookup table. So it would be 13. Regardless of whether it's this node, or that node, or that node, versus any of these nodes. So it always select the 13. So there's no variation there. This is very efficient. There's no calculations that are necessary to apply. >> So here we have the outdoors and we have two heuristics compared. This is Euclidean for the left side again, this is outdoor area with barely any obstacles, very open area going from one corner to the other corner. So lots of nodes unexplored, which is desirable, that means less processing was necessary. Then the null heuristic, we see. That is where we are not using a heuristic at all, where the heuristic is always returning 0, and therefore it's Dykstra's algorithm. In this case, every single node is explored. We can then compare different heuristics with A*, with the scenario we looked at before, with the different rooms. So with the cluster heuristic, we have clusters that are associated with each of the little rectangular room looking areas. So each of these is a cluster. And you can see that we have much better performance than Euclidean. In fact, Euclidean is just barely better than the null heuristic in this case. You often hear when someone describes a star to you though, they'll often say, well, you should use Euclidean because it's admissible and it works. But if you start digging into the details, and especially in the context of video game type scenarios where you would need path planning, the type of game you have really is going to dictate what is the best heuristic to use. And there's a huge payoff in this case, if you had a room that consisted of lots of connected rooms, while the cluster heuristic, you just need probably just a handful of rooms in that lookup table like we just looked at. It hardly takes up any space. You're avoiding any runtime calculations with square roots. And it has great performance with rooms. But if you had a big outdoors type area, then Euclidean distance would probably make sense. So you really need to consider what the scenario is and if the performance is important, which it usually is in your typical runtime video game when you're trying to maintain a high frame rate, then yes, you want to look at the heuristic. So performance of A* in terms of completeness, it is if want finite spaces, it is optimal if the heuristic is admissible. But that's not always a big deal. We don't necessarily need optimal, we just need pretty good in your typical video game use case. Time is the effective branching factor which is influenced by the heuristics. This a little bit different than the other performance analysis that we've looked at. And I will say that the analysis of A*'s performance does get pretty complicated. I'm kind of keeping things simplified a bit in this discussion. But yes, the effective branching factor is not necessarily the branching factor of your graph nodes. It's influenced by the heuristic and there's kind of complicated analysis that goes into determining how much the branching factor might be reduced to end up with this effective branching factor. And then the shallowest depth for the goal node is supplied as an exponent. So that is our time estimate, and then space is roughly the same as Dykstra, if step costs equal and so again, this is simplifying things a bit. But it gives you an idea at least of how A* performs. So in practice, the issue of memory is going to be an issue before time is in most cases. So we might still desire to constrain A* in some ways and certainly the heuristic is going to have a big impact because of the effect on the effective branching factor. So just to conclude, A* is very popular to use in video games, does use a lot of memory, it also has some other issues like, it doesn't work well with dynamic environments. I don't mention it here, but the issue of the heuristic, if you have environments that vary a lot, you might have heuristics that work well in certain contexts but less well in others. So there's a bit of an art in deciding what's the appropriate heuristic. And depending on the game, you may find that you need to investigate variants such as iterative deepening A*, or just limit the depth, or look at other possibilities such as higher hierarchical path planning. And so just saying that A* is always the choice, isn't really something that you can safely say. You might actually find that depending on the game, if you have really big expansive environments that have particular needs for path planning that you can't get around, yes, you might have to try some more complicated solutions. But this, I think our look at the various ways we might go about performing path planning, gives us a good starting point, and of course, all of this is also heavily influenced by our discretized representation of the game world. At this point, we've only really closely taken a look at the grid lattice, which is a bit dense in terms of the number of graph nodes and edges in relationship to the game world space, so we'll take a look. We're going to revisit discretized spaces and so now, trying to make more efficient use of space in the graph size, knowing limitations of A*. For instance, the impact of memory. We want to allow for A* to be as efficient as possible by not having an overly high number of nodes and edges to consider. So we'll stop there and look out for further discussion on discretized spaces for path planning.
