>> Hello. In this lecture, we are going to look at finite state machines. Finite state machines are a very popular strategy for implementing reactive decision-making AI agents especially in games. First off, we'll look at some of the basics of the structure of a finite state machine. We have components in the form of states. These are often visualized in these flowcharts that show the states and then how you get from one state to another. The way that we get from one to the other is through a transition. We can find these formerly as sets for the states, and then a transition function that defines how you go from one state to the next. The transition function acts on an input vocabulary. And in relation to an actual problem, the input vocabulary, it would be like the information about the state of the world or the problem space. In this case, this would be like the game world state that we're talking about. One of the states within our set of states is going to be the start state. They'll have a final state, like a classic or conventional for the finite state machine. But in a video game, you often will have a finite state machine that never ends, it just the agent. As long as it persists, we'll just continue to move through states and might have some idle state that it will stay in. Structurally, finite state machine is not very complicated. There's a few other rules such as you can not only be in one state at any moment in time as we'll see, we might break that rule on occasion, especially with a hierarchical state machines that we'll look at in a bit. You can make transitions from one state to another, or you can cause some action to be taken according to the state your in. There's are a couple different ways that we can formalize the action taking, which we'll look at in a bit. Like our game application, each state in our state machine, it's going to be associated with the behavior of the agent that will be performed. The agent is going to respond to the changing world state that's like our inputs to the transition function. There will be some conditinal logic that gets evaluated. We will grab information from the world state, apply some comparison there and there might be some preprocessing necessary in the form of metrics that we might calculate a distance or a visibility test, depending on the nature of the behavior that we're modeling and the decisions that need to be made to support that. A very simple example shown here. We think of it is as these different mental states that we're modeling as if this was a human and we just have this abstract notion of different behaviors that the agent is taking. We might have say, the mental state for gathering treasure or fleeing and fighting and then these different world events or world state that arises through course of the simulation. Suddenly a monster is insight. The agent was gathering treasure, but now the monsters is insight. It leaves the gathered treasure state enters flee and will perform the flee behavior until there's an opportunity to transition out. Maybe the monster is no longer insight because the agent ran away, so we can now have the agent go back to gathering treasure. Perhaps the agent gets cornered as they're fleeing, the monster chases and corners, forcing the agent to have to fight. We could recognize this. You'll notice that the agent is only able to perform activities that are represented in the finite state machine. If there's not a behavior there already, it can't perform it. Furthermore, it can't perform a particular behavior unless it transitions there. In terms of authoring a finite state machine, you have to be aware of all the different scenarios in which the transition can occur or should occur. Here's another example. This would be like one of the townsfolk and say Warcraft 2, chopping wood and taking it to a depot to drop off. It's a very simple state machine, but this would be a great scenario in which to implement a state machine, just simple activity and we can organize the different behaviors that are involved in this chopping wood, collecting the wood and taking it back using a state machine. We can tie our different states to many of the behaviors that we've seen before and especially related to character movement is also quite common to associate different states. The behavior is performed with a state with animation systems so that each state is coupled with animation. That is something that gets a little tricky and we will revisit that as well. Transitions that would possibly occur, of course events in the game, which is a change in world state from the previous frame to the current. We have some logic that recognizes that change. It is marked as an event and acted upon. Completing an action. These could be things that maybe is internally tract with the implementation say of this little towns folk person chopping wood. We just know that there's a certain amount of time that they have to perform the action and built-in into the game. They perform this chopping long enough, and when they're done, they have the resource and they take it back. >> I mentioned before exactly how we go about the actions being executed varies with implementation. So there's two primary ways of doing so. There is a Mealy and Moore. And so with both strategies you have your states and you have your transitions. But with Mealy, your transitions have an associated output. So there is an input of recognizing an event has occurred, and then an action is performed as part of the transition. So transitioning from one state to the next performs the action. And you would often see Mealy implementations where you have a loop back to the same state. So each frame, you reassess the current state of the world and you might have an input event that keeps occurring over and over. So you just stay in the same state looping back and then that the act of following the transition back to itself triggers the behavior or whatever the action is. But with Moore, which I think is more typical. And that is where the action or whatever response the agent is taking, it's just whatever the current state is, decides that so there's no input requirement to executing a behavior. Is just if you're in that state, the agent will continue to perform that state. So if you think in the context of a game event loop every time the agent stays in a state, they keep performing that same behavior. So it might be repeating it over and over or just continuing the behavior. So if it's, let's say walking on a patrol, the agent would just keep doing the steering behavior for the patrol uninterrupted. So it's a little bit different approach. You see, Mealy, I'd say is I think it originated in electronics design where you have a state machine, say for the buttons on a microwave or something like that. But there are some situations that we'll see you in a bit where Mealy might make sense for some designs. And if you did have actions you want to perform primarily in response to different events occurring, it could actually make sense to use that strategy. But again, I think the Moore approach is much more common. One thing that comes up as you're building a finite state machine is that they're very simple at first. And it seems like this is a great way to organize my strategies for my agent design but things can snowball very quickly and we'll see more examples of this. But I wanted to go ahead and mention a strategy that can be used to help reduce the explosive growth of your finite state machine. And that is to support global transitions. And so this is an example. This is actually from unities animation system which uses a state machine. So this is not an AI example, but I think it gives a good idea of how this might work. So here I've got a picture of visualization of the state machine designer for the animation system is called mechanism. And you'll see a number of states. So there's this idle state, which is the initial state and that you can tell it's the initial state because there is a transition from entry into idle turn. And so that tells us that idle turn is the initial state. And there's different ways that this could be denoted other than the transition line from entry. So not every finite state machine is going to have exactly the same layout. But the one that is interesting is this any state. So you can see that there isn't any state that goes into following. So what that means when you see the any state is that it's a wildcard. If you didn't have the any state, we would need to have a line going from blend tree forward to falling and also from blend tree backward to falling and also from idle turn to falling. So that would add several additional transitions that would have to be drawn on the screen. That would also be getting in the way of other things maybe overlapping. Basically making a big spaghetti mess. And in this case for the scenario here is that you're the following animation, as you might imagine, it involves a character that begins to fall. So it plays a special animation for falling. But you can have an agent that starts to fall from any of these different scenarios, whether they're walking forward, walking backwards, standing in place, and maybe the floor or falls out from underneath them. All of those are valid scenarios where you could begin falling. If you have a finite state machine that allows you to just do this wildcard, it really simplifies things. In case you're wondering it is possible that you're already falling and then the any state would match with following. So in fact, unity has, if you select the transition, you can choose whether to allow a transition from the same state. Otherwise you override it and in this case is overridden. So the any state is not applied. So if you're already in falling, and then the next frame you detect your falling, it'll ignore the wildcard in that situation. >> Let's consider a little scenario. And you might want to consider the scenario and just pause the video before moving on. Just maybe think about how you might build a finite state machine and I would suggest that you draw it out as a flowchart with states and you represent it with a circle or a box or something and then draw the transition lines according to the different conditions that would lead to the transition. So imagine this scenario where we have a security guard that's patrolling a school after hours and maybe the player controls a student that is breaking into the school and causing mischief of some sort. So we want the agent to chase after the player and if the security guard catches up to the player, then they will have to sit there and wait for a lecture to finish. So it's going to point his finger in the kid's face and talk for a while and slow the kid down from doing whatever, and then eventually the player can slip away. So that will, of course, chase if he sees the student, the security guard will chase if he sees, and then if he catches, they'll do the lecture. Otherwise, with not seeing the student will just switch between idle and patrol. So not a very complicated behavior, so clearly we've got four states, idle, patrol, seek, and lecture, and so you got to figure out what are the transitions and what is the information that you're acting upon? So if you're going to try to figure this out by yourself, be a good time to pause and finish thinking it through. But otherwise, I will switch to the next slide now. So here we have just a simple implementation for the security guard. So we have our state idle. And so actually, I haven't shown the initial state here, but we'll assume that will start in either seek or idle. It doesn't really matter here. Then we've got patrol and lecture, but you can see all the different transitions that we have. So one from idle to patrol is based on a five-second wait, and patrol is also a five-second wait, perhaps we could have maybe a different amount of time to do the patrol. I guess it depends on how fit the security guard is. Then the patrol, we've got transition out of patrol, the seesPlayer and that will go to seek. And then from seek, it's close, if we get close enough, then it'll initiate the lecture. Otherwise, we'll keep seeking as long as we see the player, but as soon as the player is no longer seen, the trend triggers the transition back to idle. So we want to make sure that any state that we transitioned into that we can transition back out, and again, it doesn't matter if this will go on forever, we don't need a terminal state. We just need an initial state and ideally not get stuck in a state. So it's pretty straightforward to implement. Now, it is one thing to work with a visual representation or thinking things through, and of course, there are editors that you will find with various tools for implementing a finite state machine, but another common way to implement one is with a state transition table, and so a state transition table just list all the different possible transition. So it's like a representation of our transition function as a lookup table. And so it's based on what's the current state and then any transition you have, you have a different line. So you might see multiple lines with the current states such as patrol here. And basically, the table just tells you what the condition is, and then what the current state is that it has to be matched with and then where is it going to transition to in turn, so it just tells you how you're performing a transition. So this is an efficient way to represent the different states and transitions that might be occurring. So finite state machines have various problems with them. One is that they're very predictable. Sometimes that can be a good thing, and we've discussed before how agents don't necessarily always have to be very capable. Sometimes the predictability is desirable, but if it's not desirable, we can introduce some probabilistic nature where maybe the transitions that are occurring are not strictly deterministic where we're going to roll the dice. We've seen that approach used before with decision trees. Now, in the case of a finite state machine, if you fail rolling the dice to decide whether to transition in addition to whatever other the criteria are for the decision, so if we fail to say roll a number higher than a threshold, then you stay in the state. And one thing you got to watch out for in this scenario is that as often as you update your finite state machine could vary, and your frame rate of your simulation varies. And so I believe we talked about this a little bit before with the frame rate varies and the impact it can have, unlike character movement. So you always want to have things related to the amount of time elapsed from the previous frame. So this is definitely a situation where this comes up. You've got your frame rates varying when you're updating your finite state machine, then you would definitely want to make this probability be time-based. So the likelihood of the transition occurring is going to be proportional to the amount of time elapsed rather than just always some fixed value. And the problem you could run into is, let's say you have one implementation of the game but you have one game player playing on a very powerful computer and they're getting, say, 60 frames a second. And then you have someone else runs it and they can barely get 20 frames a second. The opportunity for the agent to make a probabilistic decision is just going to be more opportunities at the higher frame rate if you don't compensate for the elapsed time. So the player with the lower frame rate, each tick that gets updated, the probability should basically be higher that the transition occurs compared to the 60. And that if the frame rate rises and falls, then the threshold needs to follow as well. So it's something to keep in mind. I'll probably bring that up again in the future just because it is such an important issue. Another thing is that finite state machines tend to be very simplistic and it's difficult to model really elaborate behaviors, we will consider the use of a hierarchical finite state machine as also finite state machines stacks. Both of those can allow you to model much more complicated behavior and avoid some of the challenges that are created when you try to build a very complicated state machine. >> Next step, we've got some more difficulties here. So the complexity I just mentioned about the state machines getting too many states and too many transitions. So you're going to address that with a hierarchical or a stack approach. But if you don't do that, what can happen is basically you have a combinatorial explosion. So as you try to deal with more and more contingencies like exceptions to normal behavior for your agent. Then the way that you address that, with just a normal state machine is well, you have to add more transitions and more states. So if you have some contingency, you got to leave the current behavior, go do something else and then maybe come back again, maybe try to continue on whatever behavior it was before. But what if it was a partially completed task? That means more states and transitions to try to track that. That gets really difficult to deal with. Basically you have this problem of a combinatorial explosion. So there's a point like a tipping point, I would say, it's like a finite state machine starts off great. Very capable for simple things. But then you can get a bit of a feature creep like, oh, I'd be nice if the agent can do just a little bit more. And then you start to add that and you realize, oh, I got to add a lot more logic to deal with this. And if you miss one little thing, you can have the agent gets stuck in a degenerate behavior, maybe switching, flip-flopping back and forth between two states. So that can be difficult to deal with. Also, one thing you can have trouble with with finite state machines is they don't really work well if let's say you have a sequence of steps to perform, your agent needs to do say, step 1, step 2, step 3, and so on. You can have difficulties there. And again, this is especially a problem if performing this plan can be interruptible, like dealing with a contingency and then needing to remember where you are and come back to it. That is a really difficult thing to do with the finite state machine. Advantages of the state machines, of course, they're very popular is probably my go-to solution anytime I'm implementing an AI agent for a video game or a virtual environment, something like that. First thing I will probably implement will be a finite state machine. Just personally I'm familiar with them. They're easy to implement. There's a number of different ways I will implement them. I've built myself pretty, I guess, complete implementations with a number of different features, but I don't necessarily always use that. I will often just whip up a procedural implementation. We'll look at some pseudocode for one in a second. So there's not very much development overhead. And if I can just start writing one from scratch without needing to go import a library then they are that easy to deal with. There often can be easy to visualize and debug. We can see the flowchart implementation. Debugging, it depends on how complicated your state machine is as what you're going to be dealing with. But there are ways, of course, also visualize the debugging of the state machines. If you don't have an overly complicated meaning number of states and transitions. If you're not to that point yet, they're usually pretty easy to deal with. You can't even have sometimes state machines that with a visual programming and premade states that you can just drop in that are already implemented. You'll occasionally find visual programming that are designed, so non-programmers can think in a finite state machine design and be able to come up with effective agent behaviors that way. There's very low cost in terms of computation for your finite state machines. Since you're only in one state, you only have to consider the transitions for that state. And as long as any metrics that are being calculated for each of these transitions isn't high, then it's going to be a low cost. It's barely going to add whatever is required to maintain the given behavior of the current state and evaluating those transitions. Also they're very intuitive as well, just understanding I'm going to stay, that's equates to some behavior that's being performed over time that may be transitioned out of for various reasons. I saw some code here, this is a procedural implementation. And so really all you need in order to get up and running with a simple finite state machine is just an enumerated type and you don't have to have an enum. For instance, it can even just be an integer. And maybe you have some constants. You just list out a number of constants at the top of your source code. And you just be named whatever the different behaviors are. For your agents of patrol go to ammo depot and so on. And of course, you need to have a variable that will store this enum or integer value. And then part of your update loop is going to be called every tick of your update cycle for your simulation. You're just going to maybe go through a switch statement, for instance, so you're going to say run a switch on the current state value for your state variable and then you will list cases for each of the different possible states. You'll have logic associated with maintaining the behavior or transitioning. So you check all your transitions and if none of those execute, then you just perform whatever behavior. So like a steering behavior, perhaps and that's it. You just wait till the next update and continue. Now if you do have a transition on what you're doing is you're just assigning a new value to your state variable and you just go ahead and break and you wait until the next update and then now you're on a new state variable value, which means a new state. And you'll execute a different block of the switch statement, a different case. So conceptually, the concept of a finite state machine is very simple and it doesn't take a lot to implement. Now this procedural implementation, this is great for just when you're prototyping something or just have something very simple, very small self-contained program. Great for that, making little examples that you're trying to figure something out. Otherwise, you probably want to go to something with a lot more structure for a more complicated problem. And so common strategy would be to use some object-oriented design where you can encapsulate your different behaviors and the transitions like a class. So you define a class for a certain state, and you'll have common behavior of each state that you'll need. So you'll build to enter the state, and then once the state's entered, you'll have future frame updates of your simulation where you would call execute. And so that will be met to run in a very brief amount of time making decisions about transitions or performing the behavior and then you'll exit. >> The exit can be optional, but say execute decides to transition, for instance, then whatever the finite state machine manager that would be calling and selecting between the different states, it would call it exit right before it transitions to the next state. So you'll often have those three. And you see some variations, so sometimes the execute is really it's just performing the behavior or the action, and any transitions, they're evaluated separately. So you might see, say, a third public method that is common in the object-oriented sense. So you might have inner execute, evaluate transitions, and exit. So there's some variations in the implementation, but having this object oriented structure can be helpful. And especially it helps to organize a few other things that I've found useful in finite state machines. So one of those is parameterized transitions. So quite often you'll see implementations that don't bother with any parameterization. But it is typical that you have states in your finite state machine that need information on which to act. And normally, you just say, well, all the information you need is in the state of the game world and you can just go there to get it. But as finite state machines get more complicated, you might have scenarios where there's some information needed in order for whatever state you're transitioning in to work effectively. So it might need to say, a target if you're transitioning into a state to attack a target. So it'd be nice if that target is provided. And so one way that you can deal with this problem and then back up a bit. So one thing you can have happen when you run into trouble is you implement something and you come back to it later. So you have a state and at the time you wrote it, you knew exactly what it needed, say it needed a target and needed a few different things tweaked or configured. And later when you're going back to the code, you add some new states and you realize you need to build a transition into that particular state and you forgot all the things that need it, so you do the transition there. And then you run your code and there's a bag that you encounter, maybe a null reference or the agent just gets stuck not doing anything because of what you didn't assign a target, so it has nothing to do. So if you explicitly enforced through the design of your finite state machine framework that a given state, it requires a parameter to be passed, then you can't call it later, not knowing what the contract is for executing it by having the parameter and you can only be entered with the parameter, then when you go to use it or someone else works with your code and extends it, they were like, I cannot call attack enemy until I provide a enemy target. So that is something that can be a really nice feature for a finite state machine, is to have these parameters. Now of course, this can get tricky with a finite state machine because with it like an object oriented design, you've got variable number of parameters that would be possible. One state in a state machine we might not need any parameters. Another might need one parameter, another might need two or three and so on. So this tends to really push, at least, in terms of language features. It pushes the need for either generics are templates depending on which language we're talking about. So you need these more advanced object oriented features in order to be able to flexibly define how many parameters that there are going to be. If you ever see, like I've got in the prison dodgeball example, you can create states that take variable number of parameters or you can have none, or one or two and so on. And so you have to be familiar with the generics feature of C# in order to understand how to define or declare classes that are parameterized transitions. Now, another thing that can come up that another software engineering challenge with finite state machines, that is related to when the transitions occur. Now, I like to have transitions that occur from the execute or the update part of the finite state machine. I don't like to decouple the transitions from the update logic, because sometimes I think to be the most flexible, you keep the two together, because sometimes as you're making the decisions about performing the behavior, you discover the situation that leads to the transition. Now, when that happens, you could return that the transition is going to occur. You could move, perform the update and say assign a new new state. But then you're in an odd situation where exactly what happens when you assign the new state, if you call and enter a new state, but you don't return from the current code that's executing, and run code after that. So you have to be really clear. If you're calling interstate, does that mean that it's executing the entering of the new state of the other state? Or is it just denoting that this will occur in the future? So in order to be as precise as possible and as clear to the programmer as possible, I like to have a deferred state change in the form of a return value. You could do this and otherwise, you could just call, say, a method that sets the deferred transition at anytime and maybe it could be overridden at anytime as well, but it doesn't get executed until the return happens. But I actually do that as a return, so it's a return value. But as long as you're clear about it that the insuring of the next state will not happen until after returning from the current update of the current state, I think you're good. So you could have some flexibility in how this is implemented. But it does create a little bit of a challenge if you do have deferred state changes, whether it's by return value or just by rule like you call some method that sets up a parameter. In either case, like the previous slide, we're talking about transitions that are parameterized, meaning that the state you're entering requires some information. So that adds some complexity as well. So if you have a deferred state chain changed, then not only is it being deferred, but also you have to provide the data for the parameter. So whatever the parameter is, has to be passed as part of this deferral requests. So like in my implementation with the prison dodgeball, it's you are basically saying, what state you want to go to? And then if it requires parameters, they have to also be passed. And that relies internally on the generics features of C#. >> So another thing that is a software engineering issue with finite state machines, I call it the inaction problem. And so if you have a finite state machine, say a state that makes a decision but it doesn't actually perform any action itself and then transitions to a state that is going to perform the action. Well, you've got this problem if you think about in terms of the update loop. So you have the update loop runs whatever the current state is, it recalls the update or the execute whatever the name is for it. It calls what's meant to occur for just a single tick for that state. It does its thing and then stays in the same state. Well then wait for the loop to go around again and it'll call execute again. And it just continues that process. So one state gets executed every tick. After you have a transition, you would execute the state. It identifies a transition, and then that transition will be entered and executed the next frame perhaps. And so that would mean that anytime there's a transition, nothing happens until the next frame. So this is especially a problem if you have a state that doesn't perform any action if it's just acting like a function call. So you enter a state, it makes a decision, and then it immediately decides to enter a new state. So you've wasted a frame there. Maybe that's not a big deal, that's just a fraction of a second but that also means that it was a period of time the agent is just not doing anything. And as your state machines get more complicated, you can run into long chains of the occurring. So you now have to watch out for it. One thing that I like to implement, which is a little bit dangerous because you might create an infinite loop, but I think it is useful often enough to use it very sparingly and that is when you identify a transition, there's an optional parameter to mark that transition as immediate. And that means that in the same frame, it'll call exit for the current state, it'll call enter for the next state, and it'll call execute for the next state as well. And so that means that if you did have a state that ended up having no action performed, at least the next state will quickly be called and be allowed to perform an action. Now the danger here is, well, what if the next state does the same thing and it decides, well, I couldn't do anything. I'm going to call a transition also with an immediate execute. The problem there is that each update cycle in our game simulation needs to finish very quickly. We only have just a fraction of a second to do everything that needs to be done. And so if we keep executing code that never returns, of course, we're never going to get to the next frame where the game is just stuck locked up. So you have to be very careful about allowing immediate transitions. You could impose some safeguard, maybe counting how many immediate transitions occurred and then just forcing one of them eventually to stop just as a little safeguard. You might do some other analysis to detect if a loop is possible depending on a static analysis type approach. But usually, I don't have any problems with the infinite loops, I do if I'm going to use this, it tends to be very sparingly. Also, I avoid ever writing a finite state machine state that all it does is make a decision is far better to realize you've got that scenario. And instead of writing a state to make a decision for you that has no purpose other than being a dispatch to other states, it's far better to just write a method that does this. And then other states can reuse that code through a method call. If they need some common logic to be performed, a method is called that returns what I need. And rather than sending off to a separate state to make the decision. So probably the most useful of this whole issue is just to be aware that a state machine is meant to model actions that are performed by your agent. It's not just decisions that are being made. So make sure that each state has an associated action. Usually, when I run into this problem, it is related to some exceptional case where I went into the state, there ended up being nothing I could do because something in the game world changed. Nothing that I could do in that state. And just for the sake of efficiency or performance, I want to immediately transition and execute a new state. Next step, debugging finite state machines. So there's some different strategies that we can use. So of course, we can perform offline debugging, which is typical of lots of computer science and programming, tasks and logging verbosity levels, and so on. So I'm sure you're all already familiar. We can also perform online or interactive debugging. And this is something that I think is especially important with finite state machines for video games. So having graphical representation of your AI state. And in fact, you can see this in the prison dodge ball. I have text that's written above each of the agents to tell what the current state is. You might even add additional supplementary information according to each state like print out some extra stuff. So I think that is really helpful because you can detect issues like getting flip-flopping back and forth between two states and never doing anything. You can see exactly what the two states are. You can also maybe have some interactive controls, either through pre-programmed keypresses or a control panel so that you can tweak the behavior, or maybe forced transitions to occur can be helpful. Creating little test world type scenarios where you can force the agent into situations or perhaps in Unity, you can also create play mode tests where you can instantiate a game world, maybe a little specialized dedicated game world, where you isolate the scenario in a way that you can focus on debugging one part of the agent behavior. >> There's some other testing strategies that aren't really specific just for finite state machines, but I figured I've mentioned them here. And so in AI, it is common to use what's called ablation testing. And this is the ablation just means removing. So you remove apart and temporarily you don't want to lose your code but you disable some part of your agent and you can study it with that remove. So of course, the removal processes you needed, the end result needs to be compiled code. But you see what parts of your finite state machine are critical so you remove a few states and the accompanying transitions. And then you can see what the agent does in response to different conditions. And that can be useful for testing, it can be useful for making, say if you have an enemy scenario where you have agents pitted against one another, it can be useful for the testing purposes that the opponent that your agent is facing is one that where stuff has been removed or disabled. You can also do AB testing. I found this useful. If I'm trying to make an agent that's better and better at something, I will often test against the previous version of the same code, say in the prison dodgeball. If I'm making a better opponent, then I want to certainly see improvement against my previous implementation. So if I would say implementing some new feature in my agent, I would pit that agent with a new feature against the old agent that didn't yet have that feature. And I would expect to see after a number of runs, maybe a higher win percentage of the new versus the old. So doing this testing is useful but you got to watch out though because you can sometimes dig a hole for yourself where you've gone off on a tangent where you're specialized only in strategies against yourself and that aren't really applicable in a general case or the most likely scenario that you might run into. So it is good to have other implementations as well, just like a sanity check. Next step, I want to look at a scenario with a state machine for an agent that has behavior to perform related to, say, foraging and eating food. But there is this potential to be interrupted by a predator and so you can see here that all these states that the agent could be unrelated to finding and eating food. They can all be interrupted by the predator and so this is a situation that we looked at previously with the wildcard transition where maybe we could simplify this with a wildcard. But clearly the introduction of the predator creates all this extra complexity with all these transitions and of course, a new state. And so in addition to the wildcard concept, which really there's only so far you can go with that and gain benefits from it. But an alternative, more powerful approach is to introduce hierarchical structure. And so we could consider how would the previous state machine look if we were addressing the design of the state machine with this hierarchy. So we could have, say a high-level strategy for finding food with a very simple state machine. And then we could think about entering and exiting that high-level strategy based on different transition requirements for instance, the predator. Now we don't have to think about the predator transition from every one of the smaller or the lower-level states. Instead, we only have to think about in terms of transitioning to or from this high level strategy. And so you can see there's this big potential gain here and you can start to get some idea of more capable implementation. There's more that we could do with a hierarchy as compared to just the one-off strategy with the wildcard. So the wildcard is we only have one level of depth that can be applied, but we might be able to divide and sub-divide as appropriate to arbitrary depth, mixing and matching lots of high level behaviors into more complicated behaviors. That's clearly something that the wildcard solution alone could not solve. So we can generalize this scenario that we just saw with the pray that we can refer to as the alarm state problem. The alarm state problem basically, it is any event that can occur in your game world that can interrupt at any point with whatever activity that the agent is performing. So another scenario we can consider is that we have a cleaning robot on a space station in our game. And it could have a very simple state machine related to picking up trash and disposing of it. So you can imagine this would be a very straightforward thing to implement. But the complexity can easily snowball as soon as we start to introduce alarm states. So one that we might encounter with the cleaning robot is that it could run low on power. And if it runs low on power, well, that could happen at anytime, meaning any of the states that it could be in so we have all these transitions where we would maybe desire some wildcard way of isolating that alarm state. >> In the hierarchical approach, we could just have a high-level cleanup strategy that is a self-contained state machine. And then we could just say, well, there's a transition to and from the cleanup state related to getting power. That's a pretty simple concept. We could even now introduce other alarmed states. So maybe there's something related to get power. Maybe there's another space pirates come on board the space station than maybe the robot needs to go hide. We'd have other alarms states for other things and be fairly straightforward. Now that could all be potentially addressed by the wildcard as previously discussed. But we start to also have complexity introduced. If we think about, well, what if certain low-level states within a high-level strategy have transitions. And those transitions go out of the scope of the current behavior. So for instance, the search state, within the cleanup strategy for the robot. There could be a transition if there's no trash found that, well, this would be a good time to go opportunistically have the robot charge, even if it's not on the lowest power threshold that normally would trigger this top off the battery instead. That would be a more efficient behavior, but it adds a bit of a bit of complexity here to our state machine. Now this can further be compounded by, what if we wanted to build an even higher level behavior that encapsulates other high-level behaviors. So we have this nesting in our hierarchy. So hierarchical finance state machine is equivalent to regular finite state machines, but we're adding this recursive multi-level evaluation. So this makes things a lot easier to think about encapsulation and abstract software design strategy. So each of our high level hierarchical states, they're still going to have the same features that we've seen before of states like in an object oriented design where we have our update, and exit. And this will exist for every state, at every level, whether it's a high-level state or like at the very lowest level though, all have this pattern. But how do we deal with that scenario we saw before where the transition from a lower state to another. And so it gets really tricky to implement the engine. The actual evaluation of the finite state machine that would be built in this way. So changes in the world state are our input vocabulary that'll be used for transitions at any level in the hierarchy. So we still have the same events that are going to be triggering transitions. And so if we have, say, a low-level state and it does not handle a potential transition event, then it will likely be handled, say at a higher level. You just, you can address that with the evaluation at the higher level. And so that's basically allowing the designer of the finite state machine to avoid duplicating transition. So it's got this wildcard feature to it. To do exactly that. You don't have to deal with all those transitions at the lower level. You just let the higher-level catch it and deal with it. So you can still have this issue of dealing with the transition from the lower-level states out of the balance of the what it's encapsulated in. So what do you end up with is a recursive algorithm that is really pretty tricky to follow. I'm not going to try to fully explain it here. And you're not expected to memorize it, but I do encourage you to check it out in Millinewtons game AI book. He has a very detailed description along with pseudocode. Very detailed pseudocode that explains I think is just one of those things that in terms of the design, it probably took a lot of tweaking and really thinking carefully about how this would work in order to get it to evaluate just right. But some of the key features of the algorithm, so the highest level transitions are always honored and they'll bypass the lower-level updates. So you won't even update the lower-level states if the higher-level transition occurs. And then the hierarchical states, they remember what child state there. And so this is one really nice feature that you get out of this particular hierarchical implementation. And that is when you go back to a high-level state, it remembers where it was before. So it's got this memory to it. And so that can be really great feature when you do have say, sequences that are like multiple steps in a plan that are being executed. Say, if you go back to the guy chopping wood, if he's interrupted, say by an ogre. Then assuming he survives the encounter, maybe rescued by some knights, he can go back to work and remember where he was before and continue the activity. Next up, all the actions, whether they're associated with entry into a state or update or exit, all of them are deferred. And so all of these different wherever the end result execution is noted, but not actually done yet. So it's just noted that this needs to happen. So those are all collated in the order of the recursive evaluation and only executed once the entire hierarchy has been evaluated. And so this has to be deferred because the act of parsing, like you don't know yet whether you're going to have a transition at a higher level state as you're parsing. So you have to defer the execution so that you can figure this all out. Then furthermore, transitions that change levels in the hierarchy are deferred when transitioning up and then recursively chained when going down. And so this is one of the really tricky things that probably isn't going to make any sense until you actually walk through the examples in the book. And so this is probably one of the more complicated concepts that is in the Wellington book that it goes into in detail. And I would say that if you were, say, building a production game where you're using finite state machines, that the hierarchical approach would probably be worth the effort. But for smaller design tasks like maybe where you're just making a game as a hobbyist or small self-contained problem, probably you don't need the hierarchical approach. >> If you expected a game to develop a lot of complexity would probably be worth the effort. One other thing I wanted to mention about the hierarchical finite state machines is that going back to the Mealy and Moore designs, you can get something that is somewhat hierarchical from Mealy, just one level deep in that, when you have this loopback transitions in the same state, those can describe a number of different behaviors. So it's almost like by having all these different loopbacks, you can create a state machine within a state machine in that fashion. So that might be a reason why one would want to consider it over more. But with the Moore strategy, I personally find that the global transition state is pretty powerful. And in fact, rather than just using the global transition state exclusively for transitions, like say in my prison dodgeball state machine., so that state is actually not only is it a wildcard transition manager, but it's also a simultaneous state. So you can think of it as a bit like an encapsulating hierarchical state. Because there's nothing to stop you from making other calls with side effects. These things within the global state they have side effects. Now you have to be very cautious about doing so because these are going to be layered on top of the other, whatever the current state is. It coexists, is on top, effectively in parallel the execution. So you do have to be careful there, but I found it useful to perform actions within the global state. So again, for simple things like the complexity of the dodgeball opponent, you don't really need the hierarchical approach for that. There's quite a bit you can accomplish without, just the global state is sufficient, I think. Another common strategy for adding a little bit more capability to the finite state machine is to use a stack. With a stack, the idea is that stacks are pushed and popped and so you don't have transitions the same way. It's effectively, the same but the transitions involve stack operations. So pushing a new state onto the stack can be like a transition or there's like an atomic operation that you'll often see where it's a popping immediate push. So from the perspective of if you were a state, you can say, remove me and replace me with this new state. So that is shown on the animated figure here on the left, the pop itself and push new. Or you can just pop itself and return to the previous state. So that's a bit like deferring to in a hierarchical sense. When one state finishes, it goes back to the calling state. So that allows for this hierarchical management. And if say you have a high level state that has more low-level states to maintain, then it will push new. So it's interesting features that can allow fairly complicated behavior similar to the hierarchical state machine and then the implementation is arguably easier. But you could also say that while the implementation might be easier, you open up more opportunities to shoot yourself in the foot. There are ways that things can go badly pretty quickly with a state machine stack. So we've got basically like a memory leak potential. So imagine you mess up somehow and you end up in a vicious cycle of keep pushing onto the stack, like somewhere your logic was wrong, so of course, you're going to run out of memory if you do that. So things you can do that'll help with the problem, the pop and push new is certainly something that can help because it minimizes the height that the stack could ever grow. And you may need some other sorts of restrictions that are imposed on the use of the stack. So you might have a rule of it, perhaps enforced by an assertion or just a thrown exception or an error of some sort would be, you can't have two of the same state on the stack at the same time. Or maybe you impose a restriction that's based on two states from the same hierarchy family. You would really depend on your particular needs, how you might go about implementing this and whether it's just a soft warning or some other enforcement. You could also potentially have a requirement that a pop and push new is always required for when states change among siblings states. So if one sibling state goes to another state, like in a hierarchical sense, if one state within the same hierarchy is transitioning to siblings state. So there's a few different things that we might do to try to make it less likely that you introduce horrible bugs in your state machine. So next up, I don't want to show, this is actually an Xbox 360 commercial. Is a well-received commercial, just because it's funny and entertaining, but there's little thing that happens right at the end I want you to look out for with the cab driver. I'll let it play here. [MUSIC]. [BACKGROUND] [OVERLAPPING] [NOISE] [MUSIC] Boom. >> [MUSIC] So in the commercial, it was very much like you would see in a video game but, of course, you had all the human actors just acting out as if it was what would happen in a game. But then the part with the cab driver, you'll notice that he was in the middle of a phone call. So he's performing a behavior that couldn't be interrupted. He couldn't transition to the appropriate responsive pretending like he had been shot. And so that is not unlike the very problems that you can run into with any decision-making framework. So not just the problem with finite state machines, this is really more of a fundamental problem in games, is that you might be modeling complex behavior, perhaps through an animation system. And then separate from that, you've got decision-making going on and there's decisions being made that perhaps can't be made or can't be acted upon because there are dependencies with other systems or subsystems of the game. And one of the most common situations is animation and the time constraints imposed by animation. An animation, it takes time to play and complete and so on. And so that restricts when and how a finite state machine can react. And so we've got this tight coupling issue with the animation system. But it's not just the animation system, there can be other constraints as well that are dictated by other parts of the aim. And so say, in a hierarchical finite state machine. So if you have an interruption of a behavior, which might be a low-level behavior that's being executed, but you have a high level interruption, there could be cleanup associated with that interruption. So you can't just say, well, it's a high-level decision, I'm going to transition now. Well, the low-level stuff that's happening right now, it could be tightly coupled with the animation system or other parts of the game. So a lot of complexity can be behind the scenes related to what might seem trivialized in at least how we've presented things so far. So you might have strategies of whatever behavior was being performed, say like an animation. Part of the cleanup would be to transition to a neutral state. And so that might be say, standing in place, the character would stand in place. But that can be awkward. If you have a character that's seated and something happens and they need to stand up in order for the whatever to happen. Rather, part of this is it implemented or not. Maybe it's just an issue of lack of resources. As a game developer, you can't build, say, animations or graphics for every possible scenario. Now some of these things related to animation you can deal with, maybe through blending or interpolating animations or perhaps using physics-based simulation. So maybe you turn off animation for a bit. So if it's like violence-related, this is often actually a good strategy. Say your characters in the middle of doing something complicated animation, you don't have to wait till the end of the animation before they can finally be killed. You can just immediately pause the animation, turn off the animation system actually and then switch to a rag doll simulation where it's physically simulated. But that's a special case. A lot of games do involve death and so on. But if you have a game that's maybe something a little bit more atypical of violent gameplay, then you're not just going to be able to quickly transition to rag doll all the time. You probably going to have to weigh or have something a little bit more sophisticated to deal with well, when the new decisions are made by your finite state machine, how you deal with it. What if you have an agent that is interacting with an artifact, for instance? So if something comes up and they're currently holding a live grenade, if you're going to transition out of the current state, which was maybe to throw the grenade to something new like runaway, well, they need to still get rid of that grenade before they start running away. So those are the problems that you can run into. Again, this doesn't apply just to finite state machines. They can come up with other reactive decision-making scenarios as well. So the takeaway here is that you're probably going to need some additional support for transitions with a time delay, like multi-frame thing where your decision-making framework like your state machine, will have identified that it wants to do a transition, but there's a synchronization that occurs with other resources in the game. Maybe it's deferred or blocks the transition. The transition is not allowed to occur right now. In fact, we will see that in behavior trees that's formalized with behavior trees in the form of a semaphore. So if a particular behavior tree transition is not possible is blocked, so you might need similar things implemented for whether it's decision trees or finite state machines or rule-based systems. You maybe need similar synchronization. >> So maybe an attack animation needs to finish before you have your transition, so you have some delay imposed or maybe the agent is going to enter a town and interrupt a conversation with a friendly NPC, the sword needs to be sheathed, in fact you'd see this pretty commonly like Legend of Zelda, Link always puts the sword away before he interacts with an NPC. Yes, that's definitely something that in a real game, this thing has to be considered. I mentioned before that we might want to try to compensate for the highly predictable nature of state machine behavior in agents and so we could add probabilistic transitions. So this is just extra criteria as part of a transition. So there is some condition for our transition, like enemy being inside. But on top of that, we would also have random number check. So previously we focused on the frame rate issue. But there's some other things we can consider with this probabilistic approach, and we can do some interesting things. We can have different personalities for our agents. And in fact, this is really powerful feature for finite state machines, but it can also be applied to other reactive decision making, and that is the threshold, whatever the say we're generating a random number between zero and one, we might have a threshold of some amount for say, a very aggressive agent. So you have to roll above 50.5 to decide to attack perhaps. But a very passive agent, you might have to roll above 0.95. So you only have that 5% chance of attack with the passive agent. And so we have a whole vector of features, like a feature vector, and the vector is full of thresholds associated with those features. So different behaviors like attack, evade, whatever the different activities are. And so nice thing here is we have one state machine implementation. And the single state machine implementation can be applied to multiple agents. So based on capabilities, based on personalities. So you're only debugging this one state machine, the only thing that's changing are the thresholds for the likelihood of different things to occur. Of course, we could use zero or 100% thresholds as well. So this would be maybe say if you have an agent that can, I don't know, one that can jump and one that cannot jump, you could just treat it as an on or an off, of course you would skip over doing the random number generation if you're doing that. So having this configurability that includes probabilistic as well as features or capabilities of the agents can be very powerful. In fact, these can even be dynamic within the same agent. An agent that has been damaged, say low health, you could have a very aggressive agent that becomes very passive when they are badly hurt. So again, lot less debugging to do. You still have all the same states as state transitions. You're just changing the likelihood of entering and exiting states. So it looked like a very simple case. It looks something like this. So we have an opportunity that say, an agent is currently firing at the enemy, if the enemy gets too close, we might have some probability of running out of range and trying to get far enough again to start firing so maybe it's an archer. The archer would try to quickly get far enough away to shoot arrows again. Or it might decide the agent would have a 50% chance so decided to just run away completely, abandon the battle. So this is very straightforward to implement. It's just adding a little bit of extra specialized conditional logic that includes a built-in random number generation. And again, you will want to compensate for the frequency of the updates if that is variable in your game which it very likely would be. On Unity, you might have it in a fixed update cycle, which is meant to be a guaranteed update cycle but quite often you are hit. In implementing a game, you would need to be able to deal with variations there. Just to wrap things up, there's other aspects that you could use the framework of probabilistic state machine. Say for perception, you can have probability of having seen or noticed something like maybe there's a character hiding in the shadows, like the human player hiding in the shadows, if there's movement there, it's like Dungeons & Dragons, dice roll, like what's the chance that it was perceived. So it can be applied to all things. And this can add a lot of capability to the finite state machine. So that wraps up our look at finite state machines, they are of course very capable, very popular, but they are limited in reactive decision-making. So there's no learning taking place but it works pretty well. There's this danger of combinatorial explosion, in which case if you're getting into situations where you have particularly high amount of complexity that is being formed necessarily for whatever your agent needs to do, you might want to switch to a hierarchical approach or maybe just consider a much more capable strategy altogether.
