>> Hello. In this lecture we're going to introduce path planning and in particular, we're going to take a closer look at using a grid lattice for representing a navigable space or path planning. So our motivation for path planning is, now that we know a little bit about moving our agent around, we want to be able to support the agent reaching a goal. We already have the seek behavior. But what if something's in the way? The scenario that we originally considered when our agent was seeking the target was that it could just form a relative position vector and then that would be used to define a direction vector, and then with that we could multiply it by the agent speed, or the maximum speed or target speed and then that would allow us to set a velocity and then move towards our target. That's assuming that there's nothing in the way. If there is something in the way, what do you do? Well, in some cases, you might be able to just slide around the objects. So you can think of it as a gradient descent. And you could do this as just part of the characters or the agents frame to frame movement, or steering decisions. It could be that if an obstacle is detected, you pick either to the left or the right from the perspective of the agent to go in. We haven't discussed a particular algorithm for that, but there are some strategies for that, that we'll see in the discussion of steering behaviors. That could be effective. You could also, in this case and in this picture here we have a grid representation of a world. And if you move from one grid spot to the next in this scenarios, with the starting location and the goal that's defined, there's always a cell that you can move to that decreases the distance between the ball and the goal. Provided that, that scenario exist, it's pretty easy to write an algorithm of the different directions you could go. So like up, down, left or right, which of those decreases the distance to the goal the most. And then you move to that spot and then the next opportunity to make a movement decision you apply the same logic. And you can keep applying that over and over. And as long as there is a cell that the ball can move to, that decreases from the current distance to the ball. The current ball position that's a known distance to the goal. And then you can pick up, down, left or right. And as long as that is an improvement on your last position and you pick the best of the four, then you can sometimes get to the target. The problem though, is that your agent can easily get stuck. So here, depending on how you frame the problem, the ball is either getting stuck in a local minima or maxima. This again, could be a problem. Whether we come up with a simple algorithm, that I just described moving from title to tile , or very similarly, if we have continuous movement, and we just have a character movement, process or steering behavior perhaps, where we're trying to steer away from an obstacle while at the same time move towards our goal. So we need some way to keep track of path choices that the agent's making and explore possibilities until an acceptable solution is found. And ideally, you'd want to explore the possibilities without actually committing to them. Imagine thinking about what you're going to do, what's the best course of action, rather than actually going out and performing everything that you're considering. Planning is what I'm suggesting. So in order to facilitate this process for the path planning, we need a data structure that allows us to represent the different possibilities for moving around in the environment, and understanding where obstacles are. And so a graph is a very suitable data structure for this purpose. So we can have a graph that's formed of nodes. And these nodes are connected by edges and there are many different configurations we can make of our graph, different information that we can associate with the different components of the graph. So for instance, the nodes we might associate with a 2D position. So each node would have like an X and Y position, that's associated with maybe a game world and then each of the edges are valid paths that exist. So from one node to the next, maybe we have a line of sight path that we can go from one to the next. The edges can also have additional information associated as well. This might be the length of the path or the cost of traversing the path, which might involve more than just the length. You could consider some paths could be more difficult or less difficult. And that might be related to the surface that you're agent's walking on, maybe a slippery surface, or uphill or downhill. Another thing is that our edges may have a bidirectional element to them. So there is only a path in one direction and then you might have an opposing path that may or may not exist depending on whatever the constraints of movement are in your game. >> With this fundamental structure we can configure in different ways. And you're probably familiar with different types of graphs already from previous computer science classes that you have taken. So we might have a directed acyclic graph that has no loops, directed cyclic graph, undirected graph. You've probably worked with tree structures before, which are themselves a type of graph, a digraph, and so on. And graphs are important in many games. Certainly for path planning as we will see, but you will often find other examples of graphs as well. For instance, in the board game, Risk, the board and the different positions where pieces can be placed on various countries, that is a graph structure. So that the relationships and the different actions that you can perform as part of the gameplay are related to the traversal of this graph structure. So the picture on the right, you can see the board, it just looks like a map, but then the places where you can stick the pieces are overlaid with the countries, and then they have certain connectivity that forms the graph you see on the left. You also find graphs occasionally in strategy games that involve building or advancing civilization. In the game civilization there are certain things that you can research. So you can have the country that you're leading, you can set as an objective to research certain areas. And then if you do so, opens up opportunities to obtain new technologies or new abilities. So this concept is pretty common in many games. You can also find graph structure that's just inherent from the way the game itself is built. In this you can see in tile-based games, especially early 2D games, were built with tiles. So each graphic element on the screen is maybe some fixed size, and you can select between different types of tiles and build out a scene. So in this case we have a Legend of Zelda, and there are different tile images. So the level designer and artists work to figure out what's the artwork that goes in each tile. And these also have some gameplay properties, like being traversable or not, or perhaps objects that you can pick up. And so this is a case where we already have some graph structure, and the graph maybe isn't immediately obvious, but you can think of each grid as being a node, and then the adjacency with other grid cells define the edges. So we might define a graph for the purpose of path planning that would be all the traversable grid cells. Those would be the nodes that we would consider for finding a path. And then of course the adjacency to other traversable cells would define edges and overall we would have a graph that we could work with. So you might be wondering about other types of games that have more unique geometry, how we might define a graph. And that's a lot less straightforward than the case of like the Zelda game we just saw. We might have different rooms with pretty complicated structure. And so how could we possibly represent those? So it's possible we could consider each room is assigned a node, and then we connect rooms that are adjacent to other rooms with edges. So this could be a useful approach to creating a grid that would support our path planning. So let's consider a little bit more about this act of planning. So part of intelligence is the ability to plan. And when we're talking about planning, this is the means of considering possibilities that haven't actually occurred yet, and see if there is some course of action that leads to a goal. And so if we can represent the world as a set of states, then we can figure out, well what can we do to manipulate the current state of the world such that we achieve a goal? So each possibility is a new configuration of the state or states that they were using to represent our world. And then the changes that are applied are called operators. ANd in the case of path planning, our operators would be the movements taken. So this could be like go north, south, east, or west, perhaps if we're talking about movement on a grid. But we could also have other operators that we consider for other types of planning. And so this will be something that we will look at in more detail when we get to some other game AI topics. But you might imagine, say in the case of civilization, you might come up with a plan to research and develop a certain technology that you recognize that you need for successor, or your agent if you have an AI opponent. So let's say that there's an AI playing against you and the AI recognizes that you have a certain technology that gives you an advantage, then perhaps the agent would identify a goal of a counter technology, and then could perform planning on the dependency graph that we saw before in civilization. So this notion of planning isn't just for path planning. >> But in the case of path planning, we have our states, which include the location of our agent or NPC in the space, also our goal location. And then coordinating that information with a discretized representation of the game world or the space. And this is important, because if you think about the typical game world, especially in a continuous movement game, we have a lot of possibilities for different obstacles and details and the character can move in arbitrary amounts or placements of the goal or the agent. Near infinite possibilities there. So we'd like to find some way to simplify the representation in the world, but not so simple that it gives us bad information back if we use it, like apply some algorithm to find a path. We want just the right amount of detail in our discretized representation. But ultimately this discretized representation. It would be nice if we can map that to a graph structure because in computer science, graphs are well understood and well-suited to the problem of planning. It's really going to vary how do we go about discretizing our game world. It's going to depend on the game and what goals we're trying to support for the agent. In a game that's already tile based, we already have something that is inherently discrete, the tiles. Even if you have some degree of continuous movement, like in the case of Zelda, the tiles that you get from the layout of the level would be suitable to just work with directly as a discretized representation. You might also have floor locations in 3D or 2D where you have different waypoints. We could, if a game, for the purpose of the game play, we need to consider 3D relative locations. We might use voxels. So think of it as like the equivalent of a grid, but now in 3D where we have some tube-like structure that we're using. And we could also possibly have what's called a navmesh and that is a data structure we will learn about in a future lecture. But the basic idea with the Navmesh is to represent different navigable areas with convex polygons that are connected to one another to form a graph structure. Our operators are just notion of moving from one discrete location to the next. So this allows us to simplify or abstract away a lot of the issues of movement. So it's important that if in the process of discretizing a state, we say that it's a node is adjacent or connected by an edge to another node, then the agent should be able to easily move from node A to node B across the connecting edge between the two. We don't want that to be something that's like an 80% chance that the agent will be successful. We want to make it a certainty that the agent is able to move. And so there are certain things that we might consider such that if the agent is located at a node and there's some associated geometry with that node like a grid cell or a polygon of a navmesh. If the continuous movement agent is located at any point within that associated area, then it shouldn't matter where they are within it. The agent should be able to easily get to the next adjacent area. Again, the node A and node B of our graph associated with these two areas. These are the things that are important to consider. But ultimately, if you create a discretized space, effectively, and have this well aligned with the capabilities of your agent. Then you can facilitate path planning just through analysis of the resulting graph structure. So the basic strategy that we're defining for this process is, well first we want to create a data structure that facilitates the path planning. And so this is the discretization of the game world if necessary, or leveraging and existing discrete representation like a tile based game. Next, we need to quantize the agent and goal locations to the graph if they are continuous positions. So the act of quantizing is basically just identifying of our discretized space or this graph structure. What is the correct node to assign for the agent's current position? Same thing with the goal. Then we want to perform or execute an algorithm that will create a path for us that if the agent follows, we'll get to the goal location. This isn't actually doing the walking around in the environment. If your agent is on foot, this is just like the agent thinking about it. And the result is you get back a path that then the agent would need to follow. Now once you get that path, assuming that there is a valid path, at that point, you need to localize the path back to the game world. This means leveraging the relationship between your discretized space and the real-world. So maybe you have a position associated with each node or some area. And you send that information back. Now before the agent acts actually executes on that. And you might need to do some cleanup that the path might not look appropriate or it'll be unnatural in some way. Have some artifacts that are a result of the way in which you discretize the space. And so this is where you may need to clean up your path to look more natural. Once you get to the point that you have a path you ready for the agent to follow. Then finally, you can initiate some agent movement, especially if this is continuous movement model for your agent, then you would start to make moment-to-moment decisions as part of the game update loop or your agent would. These would be based on the movement algorithms that we've looked at so far, or perhaps some more advanced approach. Now, when we're performing the analysis of our discretized space and the associated graph. And we know where our agent is and where our goal is. We said the quantization at that point, we're going to need some algorithm to facilitate this. And there's lots of different algorithms that we might consider for analyzing our graph. And basically exploring all the different possible operators that could be applied to the current state defined by where the agent is and where the goal is and the structure of the game world. There are certain aspects to the computation that we're wanting to perform that we should consider. For instance, there is the issue of completeness. Will our algorithm find an answer if at least one exists? Then there's the issue of time complexity. So how long will the algorithm take? Usually this is defined as a function of how big our graph is. How many nodes there are, for instance. Same with space complexity. We want to know as it relates to the size of our map, how much memory will be required to perform any calculations or storing caching of data? Then lastly, there's optimality. As you might imagine, there can be a lot of different ways to get from point A to point B, but we want to find the best one in many cases. This is the issue of optimality. >> In a separate lecture, we're going to look more closely at these search algorithms. But I do want to just briefly discuss just to set up some of the discussion for this lecture. So you could analyze the graph in such a way that you make no assumptions about the structure that led to the graph. So you're not considering any metadata associated. All you would be considering are the nodes and the edges and perhaps, the weights of the edges, but no additional information. So that would be a blind search. Alternatively, you could have a heuristic search and this is where you are leveraging domain knowledge. So we're going from a general understanding of graphs to something that is more specific in how the graph is being applied. So in the case of F-planning, especially in video games, we know a lot about the game world that the graph structure arises from. So for instance, we can perform distance calculations against known positions for each node of the graph. So this allows us to define heuristic rules. So these rules we could possibly consider as part of an algorithm. And this could drive low-level decisions as we're going through this planning process, exploring different possible paths. And the end result is that we might be able to improve on some of the metrics related to the performance of our search algorithm. So of course, we're going to want the best possible algorithm for our needs. If you think about what those needs might be for a video game, well, we want to probably have efficient use of memory and processing time because there's a lot of other things going on outside of artificial intelligence. We want the game to be responsive. We want the agents to appear to build and figure out what they're doing, where they're going very quickly and not get stalled as the computer is trying to figure out what it is to do. So it's really an important consideration to try to make any path planning to be as efficient as possible. And that means that we do desire to take advantage of all the information we have access to. So heuristic searches will probably work best. So we're not going to cover heuristic searches today, but I just want to get you thinking about that. I do want to briefly consider two of the blind searches. First of all, the depth-first search. You've probably, as part of your computer science curriculum have explored this especially with searching through trees. So performing a depth-first search on a tree is really pretty straightforward. Because you can keep track of where you are in the tree pretty easily just based on the nature of a tree structure. You don't have to worry about getting caught in loops for instance, as your algorithm is going through analysis and you can leverage recursion. But the basic idea with the depth-first search is that whichever node that you consider first, you just expand upon that further and further until you run out of choices and then work your way back considering other possibilities. So you can apply depth-first search to graphs other than trees. And for instance, on a grid, you could consider moving up, down, left or right, and then wherever the first direction you go, you could just continue to expand that node until you exhaust all possibilities. So I've got a little video here from the software that is the foundation for many of the homeworks in the game at AI class. So here is the depth-first search and you can see here the results of that algorithm generating a path. And one thing you'll probably notice is that this path does not look anywhere near optimum. So the two circles that you see, where the ball started from, of course that's the starting position. And then we're going to the goal and then the pinkish purple line is the path and you can see the ball following along. So there's lots of backtracking. And just in general, heading in the wrong direction, right from the get-go. So this probably will indicate that your depth-first search is not really the right algorithm to be using for path planning. Next step of our blind searches is breadth-first search. This differs from the depth-first-search in that we're going to consider all of the children of our starting point before we move to the next level, which would be like the grandchildren from our starting point and so on. This approach can work really well for returning result because if you think about it, you're going to be expanding such that you're never going to return a path that is longer than the shortest chain. Now this can have issues though if you have a weighted graph. So meaning edges with different weights. Because the sum along any sequence starting from your starting point towards the goal that can add up differently. So just because you have a short number of edges in the sequence that ultimately lead to the goal, doesn't mean that that's the shortest path if edge weights vary. Now in the case of a grid like we just looked at, all of the distances with four-way connectivity will always be the same. Unless for some reason in your game you have modified the weights. So breath-first search can give you the best result, at least for searching a grid, but not necessarily is that the case with other types of graphs and some that you might see in a game, like if we considered having waypoints connecting a different rooms like on a previous slide that we were looking at, is possible that breadth-first search could end up returning a result that is not optimal. So here is a video of breadth-first search in action on a grid. You can see the resulting path. And this is an optimal answer. Again, this is because we have a grid with square cells and its four-way connected all the distances that are associated with each of the edges in the graph. They are always the equal length, whether you go north, south, east or west, you're always adding a constant amount. So that works really well. Next up, I want to look at some examples from actual video games. Games involving path planning as part of the game play. And we're going to see many scenarios where the path planning fails. So I can tell you that all these games will have some discretized representation that the agents can leverage. So in this case, we see an agent, I believe an enemy trying to reach the player. Here's another example. This robot is having trouble with just a small ledge, maybe hard to see, but there's about a six inch ledge relative to the robot there, and it can't get over it and it's getting stuck. Here's another funny one. There's a Panther or similar kind of cat. And it has trouble again with ledge. So the discretized representation of the world is such that it might not reflect the physical capabilities. So for instance, the cat may have been able to jump. This one is really comical. The model here is of a flying creature shouldn't even be getting stuck on a ledge. But clearly, the game was implemented in a way that the geometry of that flying creature was on the ground sliding around. They just had the graphical model floating above. >> So a common theme of the problems we're seeing is some disconnect either the character, the agent, the physical capabilities, does not align with the discretized space, or perhaps the discretized space is not complete. So maybe the creature is capable of jumping or easily stepping over but they've never developed a plan to tell them to do so so they never attempted and therefore do things that seem rather silly. Here's another example. And by the way, if you're interested in watching the rest of that video, I do have links in the lecture notes, so you can check out the entirety if you like. So this is a Sim City example. We can see the path planning performed by the Sim. So the little people that are part of your citizens of your city. And here, the person who made this video on YouTube, this person made two roadways, one curved such that it's slightly longer. So the one on the left is a nice highway. It looks like maybe multiple lanes but it's slightly longer. And then the road on the right is shorter but it's a dirt road and it's more difficult to traverse and the Sim seemed to be completely unaware that there would be much better off taking the multi-lane highway that this's a tiny bit longer. So that's the case where the path planning this being performed is only considering the length but not any proper waiting. So in this case, you would want to consider more than the length you might want to say consider well, what's the maximum speed that you can go and then convert everything to an amount of time that it would take, or the amount of wear and tear on the car, or whatever other metrics are stimulated as part of the game. So the Sims just are not considering that as part of the path planning. Another example, this is from Half-Life 2. We have a combined soldier and of course, trying to attack the player but only coming halfway down the stairs and not going any further. So you can see that the soldier just keeps trying to find another route. So this is a case where there is, for whatever reason, an incomplete discretized representation of the game world. So the search is working correctly, is taking the soldier as close as they can get to the player but they're not able to complete the path planning. Here's another sample I'll share a little bit of. So this is theHunter: Call of the Wild. And they have some interesting examples of some of the critters you're hunting getting stuck. So in this case the physics engine cause that maybe it's a buffalo to get stuck. Here is an example, I believe, of another that has identified some path to go on, but it's unable to complete that effort because going uphill is too difficult. So again, the discretized space is representing this hill but the analysis, the search is not considering the angle is too steep to make any progress up. And here is another problem related to the water and not being able to go any further. Here is a deer getting stuck. I don't believe you can tell what it's stuck on. But I think you get the idea that there's lots of possible problems that you can run into if you do a poor job of creating the discretized space and coordinating simulated space with the environment but also the AI agent entity. So whatever the physical capabilities are of the agent. So that can lead to the problems that we just saw several examples of. So tile-based games again are nice from a path planning perspective because we have this inherent structure already. Immediately we have a straightforward way of defining our graph structure and from that, be able to immediately leverage that for path planning, so a lot of tile-based games will have discrete movement of agents. You see this especially often in strategy games, either turn-based or some of the early real-time strategy games. I had this. And even if it looked like you might have continuous movement just from the animations you're observing on the screen, say in some of the RTS games, you might notice that the characters or the vehicles would maybe animate between one cell to the next, but you couldn't have a partial position between the two perhaps. So this creates a nice situation for just keeping track of where you can go or not go. If there's an obstacle occupying a cell that's just marked as not being traversable and therefore, you don't have edges of your graph that connect from a traversable cell into the untraversable cell. You can also track agents, in general, occupy spaces in the grid and so you can have a dynamics of map just depending on when agents are occupying a spot or not, those spots or those cells become marked as untraversable. So there's different ways that we might represent our world, of course, a typical 2D tile is common with a square structure. And we could consider different connectivity. Meaning how we define our edges connecting our different nodes of the graph. So you'll often see a four-way connectivity, meaning up, down, left, or right. But you can also have eight-way connectivity where you allow diagonal connections. And that's interesting because if you do allow agents or even player-controlled objects to move in the eight-way connectivity, of course, the diagonals are longer than up, down, left, or right. And sometimes that has implications on gameplay and certainly on path planning. If you're trying to determine the shortest path locations, you would want to measure correctly diagonals versus the up, down, left, right. One potential solution to dealing with the difference in the distance traveled across adjacent edges of our cells would be to switch to a hexagonal board with six-way connectivity. Though this introduces problems with just the complexity of implementing a hex board but also now you have a lot of zigging and zagging. Whereas with the squares, it's easier sometimes to have mostly up and down and left and right movement to have the squares. So there's trade-offs and going with those two different approaches. So if you have a fully discretized gameplay where the agents move in discrete movements from one cell to the next, this is really the simplest possible scenario you can have for path planning and your artwork often will be perfectly aligned with the structure as well. So it's just a trivial thing to analyze what type of tile you have. So if you say place a tree in one of the tiles then you might have just a list of integers that are associated with the contents of each cell. And you just have a look-up table and you say, "Well, this is number 17, that's a tree, therefore that's untraversable." And there's not really any further consideration that needs to be made, it's really straightforward and it avoids the complexity that we'll find with other approaches. Now if you have a continuous space and you want to discretize, the really challenging part is to figure out, well how are you going to generate your discretized space? What's the most appropriate representation? Then there's issues of validity which we will define in a bit. The quantization, so going from the continuous space, the game world, into our discretized representation. And then going back out again, back from discretized space to the continuous game row spaces , the localization problem. There's the issue of agent movement relative to the planning and the quantization localization process. And then also the search efficiency, the implications of any choices we make about discretization could have on our search efficiency. >> So in terms of generation of a continuous space, you're going to need to consider the boundaries and terrain types. So in some cases, you might have, even if it's complicated, a well-defined delineation between what's traversable or not, such as a polygonal structure maybe that would define an obstacle, and then you could use that for any geometric test or analysis to say this is definitely traversable in this one area, but not in another. But in other cases, you have a gradient or possibilities that maybe depend on perspective. So for instance, you might have hills. Well, in that case, you might even have scenarios where an agent could go downhill, but they are not able to get traction to go uphill, maybe just according to the physics' engine configuration that would not be possible. So you'd want to be able to capture that hopefully when you're creating your discretized space so you don't end up with situations like we saw before with the buffalo that couldn't get up the hill. So those are the challenges that you might face. We're not going to consider all of these just yet. First, I want to look at using a grid lattice. But for situations where we don't have the easy scenario of cells, like image tiles that just perfectly fill each cell. Instead, we're going to consider this possibility that we have geometry that is arbitrary shape or structure, perhaps complex polygon shapes, different orientations and scales, and so on, relative to our grid lattice cells. So to perform our discretization, it's pretty straightforward to, of course, just define a grid, it's just a 2D array. And so there's two things involved, one is to size our grid lattice according to our world boundary. So that's like maybe the perimeter of our world. And if we assume that's rectangular, we can just take the dimensions like the x and y dimensions. This is assuming that we are aligned with our coordinate system. But if we have that scenario, we could just say take the width of our game world and divide by whatever grid size we've identified, so what's the width of a single grid cell? So we can divide by that and then take the floor of the resulting value then being an integer. So that is the largest grid that we can fit inside of our game world. So here, this particular image shows an example where the cell size is not a perfect multiple of the dimensions, and so you can see that there's a little bit of overhang of the game world. So in this case, our agent is just not able to traverse into that little bit of overhang. As for obstacles which you can see from the stone material, those rectangular shapes, and then there's also a star shape. Those polygonal shapes are obstacles that are what we can find where there are intersections of the obstacles with the grid cells. Grid cells that have any amount of intersection get marked as untraversable and that is denoted with the blue x's. And so some of those are obscured behind the objects, but those that are not shown in the interior of the obstacle should also be marked as not traversable. So we need some geometric process to make these determinations of intersection. So definitely we want to check out the computational geometry lecture where some of the issues are discussed. This scenario is wanting to determine how to discretize our space. You definitely want to consider using integer representation to avoid some of the problems that you might run into if you stick with floating point. But here let's consider some different scenarios we can have if we have a variety of possibilities that we could encounter. So in this case, we're considering polygons that are concave or convex, but aren't degenerate, do not have holes in them, and have consistent winding and no self-intersections. So in those scenarios, we can come up with a few different conditions that we maybe look for that would define an intersection with a cell. And if we have identified an intersection with one of our grid cells, we can stop there and immediately mark it as untraversable. Otherwise, we would maybe want to go through exhaustively every possible test just to make sure we catch everything. So first of all, we maybe want to confirm that our world boundaries don't go through grid lines. If you generate the grid correctly and you have the world boundaries aligned with your coordinate system at axis, then that's not really a concern. But if you did have other more complicated boundaries, you might need to go through steps similar to what we're doing with the obstacles here. But one thing we want to do; verify no obstacle point is within a grid cell or vice versa, where a grid cell point or vertex is inside of the obstacle. This is for 2D, by the way. So we can see this visualized. Down to the left, we have the grid cell in black and the obstacles in orange. And then points that fail the test or rather confirm the untraversable aspect of the tests are marked in red. So we see the triangle and one of the rectangles both have a corner inside the cell. So if you can imagine iterating through all obstacles and testing all points of all obstacles, we can see that all the triangles got a point that is tested as being inside the grid cell same with one of the rectangles, but you'll notice that all the other vertices did not trigger these tests for this particular grid cell. However, we might need to consider the reverse, which is of the four vertices of the grid cell. We can test these against all polygons, and we'll see that, in fact, three of them, test is being inside, and so in either of those cases that identifies an intersection. And therefore we can mark the cell as untraversable. Now keep in mind the logic that we're going through and that this exhaustive iterative process that we probably need to go through of iterating through all grid cells and all polygons. We don't want to make every possible comparison unless none of them test as an intersection. In order to minimize the amount of work being done, we want to quit as soon as we find the first intersection. All we need to do is prove that the grid cell is untraversable. As soon as we know it's untraversable, there's no point in doing any further work; we can move on to the next grid cell. Rather than partial intersections, we could have, say, a giant polygon where you'd never have any edge intersections. It would be all the points inside. You can also have the reverse where you have an obstacle so tiny that, again, no edge intersections, but it's still within the cell. Now, you can, of course, have edge intersections as well, but it's probably less expensive to test for the points versus the edges. And then you work your way up progressively to more expensive test. >> So basically, in order to correctly discretize a world, you're going to need to go through exhaustively making these comparisons. There are probably opportunities to simplify things and maybe if you have complex polygons, you could create a convex hole or a bounding box and do a hierarchical test and that work could be done to avoid, as expensive attests like iterating through every single edge of a very complicated polygon if cells are clearly well away. And again, you could do that with a convex hole or a bounding box around the more complicated polygon. Now one thing that in doing this process so far, we just considered marking the entire grid cell as an traversable in being done. But it might be useful to if you have a game with continuous movement, it might be worth also marking each edge of the cell as being traversable or not. So the cell itself may be occupied or un traversable, but you mark edges as being traversable or not and this could facilitate some more complicated analysis. Depending on the game, you maybe you have small enough agents could still go into a partially blocked cell. This is an issue of validity, which again, we will define that in a couple of slides here, but I just wanted you to keep that in mind as part of the algorithm, that might be something that you would optionally need to do. Now in terms of performing point containment on a grid cell, you might think, well, just treat the grid cell as a polygon and if you already have a robust point containment tests for polygons, you could just use that algorithm. However, we have some standardized structure that we can take advantage of, so assuming that we've got access axis aligned dimensions of our grid, which would tend to be the case. Meaning that the edges of our grid cell are aligned with the axis of our space or 2D vector space, then we can just perform range checks for the x and y dimension when we do our tests, which simplifies things. So you could just do if you want to know if anything is inside, you could just come up with the appropriate less than and greater than testing or for a given test point, the x and y test it against the minimum and maximum x and y of your grid cell and that could be used to determine if this point is inside the cell. If you also want to allow for points being on the edges as well, you could do less than or equal and greater than or equal the otherwise the same tests and that would be effective. Now if you're using an integer representation, as discussed in the computational geometry lecture, then you could also potentially just subtract one. So you know that all positions are integers. So int vector two, an x and y would be integer values. You could just subtract a single unit from the size of your grid. So either adding one to the minimum values or subtracting one from the maximum values, we define a new grid cell. This just slightly smaller and that would allow you to continue to use the less than or equal tests, but effectively only checking for the interior. And so I mentioned that now because there is a reason why you might want to do that, which we'll apparent in the next couple of slides here. So next, I want to consider some of the problematic cases and then this is something that might come up if you were actually using a grid lattice discretization for the purpose of path planning in your game, but the game involved continuous movement and was not a tile day scheme. So you do not use an graphic tiles but geometry like this, you may have issues with geometry that is perfectly aligned with edges of your grid cells. And so I've got this picture here, which hopefully demonstrates what I'm talking about. So the red lines shown is the boundary of the polygon. We see the blue x's, which to show the traversable area and then I've marked with the translucent orange around the perimeter of the polygon. This shows where we don't want there to be any x's, however, depending on how we set up our intersection test, that could easily be triggered. So all of those adjacent cells to the polygon, but on the outside, they do share a common. One of the edges of the cell overlaps is coincident with one of the edges of the obstacle polygon. So we'd like to avoid that as [NOISE] something that would cause more of the map to be marked as an traversable. And it's not, if you did have this particular game scenario, it would be unreasonable that your level designers might want to have some geometry perfectly aligned with the edges of the grid cell, [NOISE] just because it might allow for some more realistic movement such as your AI agents can walk really close to walls for instance, which could look better than if they're always offset by some large amount. So this is something I think is reasonably plausible. So we could test only for certain types of intersection, I've got a visual demonstration here showing the distinction between proper and improper line segment intersection. So a proper line intersection from a computational geometry standpoint, is one where you have two lines that are not parallel to one another that intersect somewhere other than an endpoint. And so that would be your ideal line intersection that you might expect, but improper intersections either involve endpoints, one against an interior part of another edge, one endpoint on interior other edge, or two endpoints aligning or perhaps just two parallel lines that have some amount of overlap, including a single point which I don't have that example shown, but any of those would be improper. And so this would be a way that we could avoid if we use a test only for proper intersection, we could avoid this. But if we did so that would create a scenario where if we were iterating through each edge of a polygon and then testing that against each grid cell. What if we had a polygon that was exactly the same size as a grid cell? In that case, you would fail to mark the interior of the overlapping grid cell as being untraversable. So an easy fix here is to go back to what I referred to previously, the point test for the interior of a grid cell just using the range check. This notion of shrinking by one, this is something that is easy to perform when we are using an integer representation. Again, we can just do this, shrinking by one unit and once you've done that, this now means that we will get the one we do the point test against the polygon, we will catch the one or all four, in this case, all four of the vertices of the cell with the shrunk cell would be inside. And so this would still allow us to effectively catch that it should be untraversable. >> That I think addresses most of the issues to consider in 2D. So next up, I want to discuss validity. So I mentioned before that as you're identifying each grid cell as being traversable or not, you may also wish to identify individual edges. And so validity has to do with the guarantee that an agent can move from one graph node to the next or, whatever navigable area is associated with a graph node that the agent can safely navigate from one node to the next adjacent node. And so this picture from the Millinewton book demonstrates this. So you can see these two point positions, and they're in adjacent cells. In this case, none of the grid cells are marked as traversable or untraversable here. We're just considering obstacles that might intrude upon the space of each cell. So on the left, this is considered cells that are partially blocked, but the blocking is valid. At least from the context of considering traversing from one of the partial cells to the other partial cell, and you'll notice that the way that the partial blockage occurs leaves two convex polygon shapes. So once a grid cell is now a different polygon shape, but it's still convex. However, on the right you'll see that the way that the intersection with an obstacle occurs leaves the two adjacent grid cells, or one of the two, rather is concave. The other is convex but one is concave. And so if you consider convex geometry, any convex shape, you can go from any point along the perimeter to any other point on the perimeter, or from any interior point to any edge of the convex polygon. So any interior point you can see the entirety of the area of the polygon in the perimeter. But a concave polygon that is not guaranteed. So when you're thinking in the context of agent movement and being able to safely move from one to the other, well, the safest thing to consider is just if straight line movement is possible. Because then we can use a very simple algorithm like the Seek Movement algorithm previously presented. And so if we have two convex areas that's easy to support. So we can consider, more certainly two adjacent convex shapes, like for our grid that we can easily define those as valid. You could potentially define validity directionally. Even in a case where you do have a concave grid cell, let's say, you might be able to move not up and down, but left and right. So I don't know if you can see my mouse cursor captured well in this video, but this cell here, we do have a concave shape to it. But the agent can be anywhere in that cell and travel to the left. But up and down, that's not a guarantee. You can easily find positions. If you consider moving up and down that would be blocked or cause trouble. So validity is something you might consider when it comes to creating a discretize space because it allows you to use more of the map. One practical concern to consider with any discretized space really, is including a grid cell, is what to do if your agent is outside of the navigable space or outside of a navigable cell. And they're not supposed to be like. So what do you do? So this is a fairly common problem even with your best efforts, somehow the enemy gets where they're not supposed to be. Maybe the agent got bumped into in some weird way, the collision detection failed, maybe there is an explosion from an attack and it knocked the enemy where they shouldn't be, so what do you do in those cases? Well, this is really going to depend on your game, but one thing you might consider is to switch strategies. Recognize that your agent is not on a cell, perhaps they can just perform local character movement with seeking, for instance, may be using re-cast to identify if there's obstacles in the way, some straight line movement, maybe you temporarily turn off collision detection for the enemy until they get back onto the nearest cell. You could perhaps benefit from keeping track of validity data. So even if a cell is marked as being untraversable, you could at least know well which edges lead to traversable cells. You could have agents just move around randomly and hopes that they eventually get into position, or you could do prior, what's one of the most common approaches is to just teleport the enemy to be back on the board or just recognize her off grid. And if they're not an important agent, like just some anonymous enemy, just have them immediately destroyed. If it's an important NPC, maybe an escort mission where you don't want the agent to just be disappearing, then the teleporting would work well. And you can use tricks like wait until the player is not looking and then teleport them or send them off map and then have them walk back onto the map. >> Next step, I want to just briefly consider how you deal with the resulting path. And so when we looked at the basics of character movement, there was some discussion of how we might have an agent follow multiple waypoints. And so that's the strategy you could use to have your agent follow a path. You just take the path and convert it back to your game world, and use those coordinates as waypoints and then your agent will follow along. The issue though, is that you will often have a path to follow that looks very artificial, it's very blocky looking movement, especially it would be the case with a grid lattice. But similar sorts of issues exist with really all types of discretized space representations. So this is where the idea of post-process cleanup, often referred to as string pulling comes from. So there's different algorithms, and again, it'll depend on what your discretized space is. So for instance, there might be a particular algorithm that works well for a grid lattice and then maybe one that works well for a NavMesh, for instance. So let's consider what would be an ideal path for this scenario shown here in this figure. So we've got an agent that's shown with the gold colored oval and we have a pot of gold, which is the goal or the objective, what the agent is trying to seek. The path finding algorithm will find a path identified in the figure there. And you'll notice that starting point is actually not exactly where the agent is, so we have to quantize the agent position. Basically figure out what cell the agent's currently in. This is assuming continuous movement for the agent. Then we've got the pot of gold. Similar situation, it's not located exactly in the center of the cell. So we have to remember that bit of information to then attach that at this little tails to the resulting path that the path search returns. So you can see that we have go down two, and then over to the right three and that will get to the correct cell. Again, we need to detach these little tails to get to the true locations for the starting point for the agent and the pot of gold. And that's clearly a very awkward path. Induced by the quantisation is this backtracking that you see here. So having to go in the wrong direction before heading along the path. And then the path that we see is very blocky. So the idea of string pulling is that you can imagine that there's a string that's located at the the agent and at the goal, and then lay the string down over top of the mat, keep this string held at each of those points but tighten the string. So keep pulling the string and pulling the string, and it should get tight against the obstacles. And so that resulting tightened string is going to be a much better path because the string pulling is going to identify inflection points and those inflection points are the ideal positions to turn. Now this doesn't take into consideration the physical properties of the agent movement if there is a complex physics-based model, the agent at their ideal speed might not be able to make certain turns, or maybe it would be able to go faster if they, say rounded the corner more rather than turning right at the inflection point. Now, the case of the grid lattice, we could consider each cell as being an obstacle or not, and so the orange line depicts that possibility. The actual curve here doesn't look quite right because I was limited by the PowerPoint capabilities for drawing the lines. But I think you get the idea where the bottom-left corner of one of the cells marked as untraversable is an inflection point. However, in the actual game world, you'll notice that the big boulder only is blocking just a small portion of the cell that's marked untraversable, shown in the red. So the yellow line depicts what you may be able to even further improve the quality of the path for the continuous space by maybe testing against the actual game objects that are present. So maybe you could perform tests by maybe ray casting or some other means against more complicated geometry. Of course, that could increase the computational cost to do so, to perform the string pulling. Another approach you can take is rather than do this post-processing all in one fell swoop to do the string pulling, you could instead have a steering behavior. This is basically a more complicated character movement where there is an analysis done of the path looking ahead greedily to see what's the furthest along the path that can be seen in a straight line distance. Rather than following the path religiously, instead just uses greedy approach to cut off the corners. That will often give results that are similar to the string pulling. So we have some different possibilities that we could consider here. Here's some other examples of string pulling, a couple from the Ellington book shown here. So we have the original path as returned from the path planning aligned with the discretized space. And then we have the smooth path using some particular algorithm. And then in comparison to maybe what would be the ideal path. There's considerations to take, such as the size of the agent. So maybe the agent takes up a certain amount of space and you don't want to have the agent run into the corner at the inflection points, so inflection point near an obstacle. So you need to consider some offset to impose. We'll look at those details more in another lecture. >> I have in the same slide here, another picture, this is from an actual game. Now, this, rather than using a uniform grid Lattice, this is from Star Trek Armada, where they used a quadtree, this is more like a hierarchical grid, but they faced the challenge of needing to perform string-pulling for the movements of spaceships on their 2D maps. The gameplay was this overhead view. They demonstrate how to do string-pulling in a quadtree. So it's a unique situation that they faced dealing with the quadtree string Next up, I want to consider the search efficiency with a grid Lattice. With the grid Lattice, the search algorithm that you use is going to need to visit a lot of nodes and that's because the search space grows very quickly with a grid Lattice. This is especially in case if you pick a higher resolution grid or a bigger space. So for instance, if you have an n by n grid, this will again be a function of both your cell size and your overall world size that you're trying to discretize. So with an n by n grid, you have n-squared nodes and you will also have quite a lot of edges as well. So if you have four-way connectivity, you're going to have n minus 1 times n then two different dimensions for x and y direction, and then bi-directional connectivity. Then if you're also adding the extra eight-way edges, those extra edges will be n minus 1 times n minus 1. Then you've got two different angles that you can go up to the left or up to the right and then times two bi-directional. So you have to add those to the four-way edge account for the total amount of edges. That said, whatever grid you end up with, you don't actually have to create all these nodes and edges. Your grid itself is sufficient. You can write query methods that just analyze the grid and just on-demand interpret to figure out where nodes and edges and paths that you might take. So the operators that are acting on the state information. You don't have to actually allocate additional memory for that. But because your grid Lattice can end up so dense, there're especially a poor match for cases where you have a sparse environment. You can imagine if you have large open areas and you're wanting to perform path planning, all large areas that you might be discretizing will be filled, represented with potentially lots and lots of cells. So there's really no benefit to your path planning to have all those cells. Ideally, you would want to represent large open areas with this little graph representation as possible. So in summary of look at the grid Lattice structure. One thing that's nice about them is they're easy to implement, especially so if we have an inherently tile-based game with discrete movement. In those cases with both tile-based level assets and discrete movement, it really simplifies things. Also if you have that situation it works nicely with temporary or dynamic obstacles. So when you have other units that are moving in the world, it's easy to, with very simple logic, make a Boolean determination of whether the cell is occupied or not and therefore whether it is traversable or not. This is good for multiple unit movement. If you have a real-time strategy game, for instance, is something that can help the complexity of group movement is more manageable in this case. As we discussed already the fact that our grid structure is sufficient to analyze on the fly, to make determinations of where nodes and edges are or what they are as we're performing our operations as part of our path planning. The downsides though to the grid lattices, it's not great for continuous environments, especially because of not being able to represent arbitrary areas. So you end up perhaps having too many cells representing a large expanse. Especially in comparison to other approaches you might be able to scale the size of the graph appropriately with your game world. So this is a burden on search efficiency to have all this extra resolution that you may not need as part of your game. Lastly, the path quality can be poor. So the resultant path that is returned will likely need some string-pulling to make it look better unless you have discrete movement in your game anyway. It's not really a concern at that point, but if you do have continuous movement, you will probably have to spend some effort to clean up the resultant paths. So that concludes our introduction to path planning, but also looking at the grid Lattice as a means of creating a discretized space.
